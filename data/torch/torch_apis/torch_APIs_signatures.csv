API,Description,Example1,Example2,,
"
 torch. sparse_coo_tensor ( indices ,  values ,  size ,  * ,  dtype ,  device ,  requires_grad )   → ¶","Constructs a  sparse tensor in COO(rdinate) format  with specified values at the given
 indices . 
 Note 
 This function returns an  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> i=torch.tensor([[0,1,1],
... [2,0,2]])
>>> v=torch.tensor([3,4,5],dtype=torch.float32)
>>> torch.sparse_coo_tensor(i,v,[2,4])
tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3., 4., 5.]),
       size=(2, 4), nnz=3, layout=torch.sparse_coo)>>> torch.sparse_coo_tensor(i,v)# Shape inference
tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3., 4., 5.]),
       size=(2, 3), nnz=3, layout=torch.sparse_coo)>>> torch.sparse_coo_tensor(i,v,[2,4],
... dtype=torch.float64,
... device=torch.device('cuda:0'))
tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3., 4., 5.]),
       device='cuda:0', size=(2, 4), nnz=3, dtype=torch.float64,
       layout=torch.sparse_coo)# Create an empty sparse tensor with the following invariants:
#   1. sparse_dim + dense_dim = len(SparseTensor.shape)
#   2. SparseTensor._indices().shape = (sparse_dim, nnz)
#   3. SparseTensor._values().shape = (nnz, SparseTensor.shape[sparse_dim:])
#
# For instance, to create an empty sparse tensor with nnz = 0, dense_dim = 0 and
# sparse_dim = 1 (hence indices is a 2D tensor of shape = (1, 0))
>>> S=torch.sparse_coo_tensor(torch.empty([1,0]),[],[1])
tensor(indices=tensor([], size=(1, 0)),
       values=tensor([], size=(0,)),
       size=(1,), nnz=0, layout=torch.sparse_coo)# and to create an empty sparse tensor with nnz = 0, dense_dim = 1 and
# sparse_dim = 1
>>> S=torch.sparse_coo_tensor(torch.empty([1,0]),torch.empty([0,2]),[1,2])
tensor(indices=tensor([], size=(1, 0)),
       values=tensor([], size=(0, 2)),
       size=(1, 2), nnz=0, layout=torch.sparse_coo)
",,,
"
 torch. is_tensor ( obj ) [source] ¶","Returns True if  obj  is a PyTorch tensor. Note that this function is simply doing  isinstance(obj, .
Using that  isinstance  check is better for typechecking with mypy,
and more explicit - so it’s recommended to use that instead of
 is_tensor . 
 Parameters 
 obj 
 Example: 
",">>> x=torch.tensor([1,2,3])
>>> torch.is_tensor(x)
True
",,,
"
 torch. is_storage ( obj ) [source] ¶","Returns True if  obj  is a PyTorch storage object. 
 Parameters 
 obj 
",,,,
"
 torch. is_complex ( input ) ¶","Returns True if the data type of  input  is a complex data type i.e.,
one of  torch.complex64 , and  torch.complex128 . 
 Parameters 
 input 
",,,,
"
 torch. is_conj ( input ) ¶","Returns True if the  input  is a conjugated tensor, i.e. its conjugate bit is set to  True . 
 Parameters 
 input 
",,,,
"
 torch. is_floating_point ( input ) ¶","Returns True if the data type of  input  is a floating point data type i.e.,
one of  torch.float64 ,  torch.float32 ,  torch.float16 , and  torch.bfloat16 . 
 Parameters 
 input 
",,,,
"
 torch. is_nonzero ( input ) ¶","Returns True if the  input  is a single element tensor which is not equal to zero
after type conversions.
i.e. not equal to  torch.tensor([0.])  or  torch.tensor([0])  or
 torch.tensor([False]) .
Throws a  RuntimeError  if  torch.numel()  (even in case
of sparse tensors). 
 Parameters 
 input 
 Examples: 
",">>> torch.is_nonzero(torch.tensor([0.]))
False
>>> torch.is_nonzero(torch.tensor([1.5]))
True
>>> torch.is_nonzero(torch.tensor([False]))
False
>>> torch.is_nonzero(torch.tensor([3]))
True
>>> torch.is_nonzero(torch.tensor([1,3,5]))
Traceback (most recent call last):
...
RuntimeErrorbool value of Tensor with more than one value is ambiguous
>>> torch.is_nonzero(torch.tensor([]))
Traceback (most recent call last):
...
RuntimeErrorbool value of Tensor with no values is ambiguous
",,,
"
 torch. set_default_dtype ( d ) [source] ¶","Sets the default floating point dtype to  d . Supports torch.float32
and torch.float64 as inputs. Other dtypes may be accepted without complaint
but are not supported and are unlikely to work as expected. When PyTorch is initialized its default floating point dtype is torch.float32,
and the intent of set_default_dtype(torch.float64) is to facilitate NumPy-like
type inference. The default floating point dtype is used to: 
 Implicitly determine the default complex dtype. When the default floating point
type is float32 the default complex dtype is complex64, and when the default
floating point type is float64 the default complex type is complex128. 
 Infer the dtype for tensors constructed using Python floats or complex Python
numbers. See examples below. 
 Determine the result of type promotion between bool and integer tensors and
Python floats and complex Python numbers. 
 
 Parameters 
 d 
 Example 
 
 
",,,,
"
 torch. get_default_dtype ( )   → ¶","Get the current default floating point  torch.dtype . Example: 
",">>> torch.get_default_dtype()# initial default for floating point is torch.float32
torch.float32
>>> torch.set_default_dtype(torch.float64)
>>> torch.get_default_dtype()# default is now changed to torch.float64
torch.float64
>>> torch.set_default_tensor_type(torch.FloatTensor)# setting tensor type also affects this
>>> torch.get_default_dtype()# changed to torch.float32, the dtype for torch.FloatTensor
torch.float32
",,,
"
 torch. set_default_tensor_type ( t ) [source] ¶","Sets the default  torch.Tensor  type to floating point tensor type
 t . This type will also be used as default floating point type for
type inference in  torch.tensor() . The default floating point tensor type is initially  torch.FloatTensor . 
 Parameters 
 t 
 Example: 
",">>> torch.tensor([1.2,3]).dtype# initial default for floating point is torch.float32
torch.float32
>>> torch.set_default_tensor_type(torch.DoubleTensor)
>>> torch.tensor([1.2,3]).dtype# a new floating point tensor
torch.float64
",,,
"
 torch. numel ( input )   → ¶","Returns the total number of elements in the  input  tensor. 
 Parameters 
 input 
 Example: 
",">>> a=torch.randn(1,2,3,4,5)
>>> torch.numel(a)
120
>>> a=torch.zeros(4,4)
>>> torch.numel(a)
16
",,,
"
 torch. set_printoptions ( precision ,  threshold ,  edgeitems ,  linewidth ,  profile ,  sci_mode ) [source] ¶","Set options for printing. Items shamelessly taken from NumPy 
 Parameters 
 
 
 Example: 
",">>> # Limit the precision of elements
>>> torch.set_printoptions(precision=2)
>>> torch.tensor([1.12345])
tensor([1.12])
>>> # Limit the number of elements shown
>>> torch.set_printoptions(threshold=5)
>>> torch.arange(10)
tensor([0, 1, 2, ..., 7, 8, 9])
>>> # Restore defaults
>>> torch.set_printoptions(profile='default')
>>> torch.tensor([1.12345])
tensor([1.1235])
>>> torch.arange(10)
tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
",,,
"
 torch. set_flush_denormal ( mode )   → ¶","Disables denormal floating numbers on CPU. Returns  True  if your system supports flushing denormal numbers and it
successfully configures flush denormal mode.   set_flush_denormal() 
is only supported on x86 architectures supporting SSE3. 
 Parameters 
 mode 
 Example: 
",">>> torch.set_flush_denormal(True)
True
>>> torch.tensor([1e-323],dtype=torch.float64)
tensor([ 0.], dtype=torch.float64)
>>> torch.set_flush_denormal(False)
True
>>> torch.tensor([1e-323],dtype=torch.float64)
tensor(9.88131e-324 *
       [ 1.0000], dtype=torch.float64)
",,,
"
 torch. rand ( *size ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False ,  pin_memory=False )   → ¶","Returns a tensor filled with random numbers from a uniform distribution
on the interval  [ The shape of the tensor is defined by the variable argument  size . 
 Parameters 
 size 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.rand(4)
tensor([ 0.5204,  0.2503,  0.3525,  0.5673])
>>> torch.rand(2,3)
tensor([[ 0.8237,  0.5781,  0.6879],
        [ 0.3816,  0.7249,  0.0998]])
",,,
"
 torch. rand_like ( input ,  * ,  dtype ,  layout ,  device ,  requires_grad ,  memory_format )   → ¶","Returns a tensor with the same size as  input  that is filled with
random numbers from a uniform distribution on the interval  [ .
 torch.rand_like(input)  is equivalent to
 torch.rand(input.size(), . 
 Parameters 
 input 
 Keyword Arguments 
 
 
",,,,
"
 torch. randn ( *size ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False ,  pin_memory=False )   → ¶","Returns a tensor filled with random numbers from a normal distribution
with mean  0  and variance  1  (also called the standard normal
distribution). 
 out The shape of the tensor is defined by the variable argument  size . 
 Parameters 
 size 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.randn(4)
tensor([-2.1436,  0.9966,  2.3426, -0.6366])
>>> torch.randn(2,3)
tensor([[ 1.5954,  2.8929, -1.0923],
        [ 1.1719, -0.4709, -0.1996]])
",,,
"
 torch. randn_like ( input ,  * ,  dtype ,  layout ,  device ,  requires_grad ,  memory_format )   → ¶","Returns a tensor with the same size as  input  that is filled with
random numbers from a normal distribution with mean 0 and variance 1.
 torch.randn_like(input)  is equivalent to
 torch.randn(input.size(), . 
 Parameters 
 input 
 Keyword Arguments 
 
 
",,,,
"
 torch. randint ( low=0 ,  high ,  size ,  \* ,  generator=None ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False )   → ¶","Returns a tensor filled with random integers generated uniformly
between  low  (inclusive) and  high  (exclusive). The shape of the tensor is defined by the variable argument  size . 
 Note 
 With the global dtype default ( 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.randint(3,5,(3,))
tensor([4, 3, 4])>>> torch.randint(10,(2,2))
tensor([[0, 2],
        [5, 5]])>>> torch.randint(3,10,(2,2))
tensor([[4, 5],
        [6, 7]])
",,,
"
 torch. randint_like ( input ,  low=0 ,  high ,  \* ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False ,  memory_format=torch.preserve_format )   → ¶","Returns a tensor with the same shape as Tensor  input  filled with
random integers generated uniformly between  low  (inclusive) and
 high  (exclusive). 
 Parameters 
 
 
 Keyword Arguments 
 
 
",,,,
"
 torch. randperm ( n ,  * ,  generator ,  out ,  dtype ,  layout ,  device ,  requires_grad ,  pin_memory )   → ¶","Returns a random permutation of integers from  0  to  n . 
 Parameters 
 n 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.randperm(4)
tensor([2, 1, 0, 3])
",,,
"
 torch. empty ( *size ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False ,  pin_memory=False ,  memory_format=torch.contiguous_format )   → ¶","Returns a tensor filled with uninitialized data. The shape of the tensor is
defined by the variable argument  size . 
 Parameters 
 size 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.empty((2,3),dtype=torch.int64)
tensor([[ 9.4064e+13,  2.8000e+01,  9.3493e+13],
        [ 7.5751e+18,  7.1428e+18,  7.5955e+18]])
",,,
"
 torch. tensor ( data ,  * ,  dtype ,  device ,  requires_grad ,  pin_memory )   → ¶","Constructs a tensor with no autograd history (also known as a “leaf tensor”, see  Autograd mechanics ) by copying  data . 
 Warning 
 When working with tensors prefer using  
 
 See also 
 torch.as_tensor() 
 
 Parameters 
 data 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.tensor([[0.1,1.2],[2.2,3.1],[4.9,5.2]])
tensor([[ 0.1000,  1.2000],
        [ 2.2000,  3.1000],
        [ 4.9000,  5.2000]])>>> torch.tensor([0,1])# Type inference on data
tensor([ 0,  1])>>> torch.tensor([[0.11111,0.222222,0.3333333]],
... dtype=torch.float64,
... device=torch.device('cuda:0'))# creates a double tensor on a CUDA device
tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')>>> torch.tensor(3.14159)# Create a zero-dimensional (scalar) tensor
tensor(3.1416)>>> torch.tensor([])# Create an empty tensor (of size (0,))
tensor([])
",,,
"
 torch. sparse_coo_tensor ( indices ,  values ,  size ,  * ,  dtype ,  device ,  requires_grad )   → ¶","Constructs a  sparse tensor in COO(rdinate) format  with specified values at the given
 indices . 
 Note 
 This function returns an  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> i=torch.tensor([[0,1,1],
... [2,0,2]])
>>> v=torch.tensor([3,4,5],dtype=torch.float32)
>>> torch.sparse_coo_tensor(i,v,[2,4])
tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3., 4., 5.]),
       size=(2, 4), nnz=3, layout=torch.sparse_coo)>>> torch.sparse_coo_tensor(i,v)# Shape inference
tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3., 4., 5.]),
       size=(2, 3), nnz=3, layout=torch.sparse_coo)>>> torch.sparse_coo_tensor(i,v,[2,4],
... dtype=torch.float64,
... device=torch.device('cuda:0'))
tensor(indices=tensor([[0, 1, 1],
                       [2, 0, 2]]),
       values=tensor([3., 4., 5.]),
       device='cuda:0', size=(2, 4), nnz=3, dtype=torch.float64,
       layout=torch.sparse_coo)# Create an empty sparse tensor with the following invariants:
#   1. sparse_dim + dense_dim = len(SparseTensor.shape)
#   2. SparseTensor._indices().shape = (sparse_dim, nnz)
#   3. SparseTensor._values().shape = (nnz, SparseTensor.shape[sparse_dim:])
#
# For instance, to create an empty sparse tensor with nnz = 0, dense_dim = 0 and
# sparse_dim = 1 (hence indices is a 2D tensor of shape = (1, 0))
>>> S=torch.sparse_coo_tensor(torch.empty([1,0]),[],[1])
tensor(indices=tensor([], size=(1, 0)),
       values=tensor([], size=(0,)),
       size=(1,), nnz=0, layout=torch.sparse_coo)# and to create an empty sparse tensor with nnz = 0, dense_dim = 1 and
# sparse_dim = 1
>>> S=torch.sparse_coo_tensor(torch.empty([1,0]),torch.empty([0,2]),[1,2])
tensor(indices=tensor([], size=(1, 0)),
       values=tensor([], size=(0, 2)),
       size=(1, 2), nnz=0, layout=torch.sparse_coo)
",,,
"
 torch. asarray ( obj ,  * ,  dtype ,  device ,  copy ,  requires_grad )   → ¶","Converts  obj  to a tensor. obj  can be one of: 
 a tensor 
 a NumPy array 
 a DLPack capsule 
 an object that implements Python’s buffer protocol 
 a scalar 
 a sequence of scalars 
 When  obj  is a tensor, NumPy array, or DLPack capsule the returned tensor will,
by default, not require a gradient, have the same datatype as  obj , be on the
same device, and share memory with it. These properties can be controlled with the
 dtype ,  device ,  copy , and  requires_grad  keyword arguments.
If the returned tensor is of a different datatype, on a different device, or a copy is
requested then it will not share its memory with  obj . If  requires_grad 
is  True  then the returned tensor will require a gradient, and if  obj  is
also a tensor with an autograd history then the returned tensor will have the same history. When  obj  is not a tensor, NumPy Array, or DLPack capsule but implements Python’s
buffer protocol then the buffer is interpreted as an array of bytes grouped according to
the size of the datatype passed to the  dtype  keyword argument. (If no datatype is
passed then the default floating point datatype is used, instead.) The returned tensor
will have the specified datatype (or default floating point datatype if none is specified)
and, by default, be on the CPU device and share memory with the buffer. When  obj  is none of the above but a scalar or sequence of scalars then the
returned tensor will, by default, infer its datatype from the scalar values, be on the
CPU device, and not share its memory. 
 See also 
 torch.tensor() 
 
 Parameters 
 obj 
 Keyword Arguments 
 
 
 Example: 
",">>> a=torch.tensor([1,2,3])
>>> # Shares memory with tensor 'a'
>>> b=torch.asarray(a)
>>> a.data_ptr()==b.data_ptr()
True
>>> # Forces memory copy
>>> c=torch.asarray(a,copy=True)
>>> a.data_ptr()==c.data_ptr()
False>>> a=torch.tensor([1,2,3],requires_grad=True).float()
>>> b=a+2
>>> b
tensor([1., 2., 3.], grad_fn=<AddBackward0>)
>>> # Shares memory with tensor 'b', with no grad
>>> c=torch.asarray(b)
>>> c
tensor([1., 2., 3.])
>>> # Shares memory with tensor 'b', retaining autograd history
>>> d=torch.asarray(b,requires_grad=True)
>>> d
tensor([1., 2., 3.], grad_fn=<AddBackward0>)>>> array=numpy.array([1,2,3])
>>> # Shares memory with array 'array'
>>> t1=torch.asarray(array)
>>> array.__array_interface__['data'][0]==t1.data_ptr()
True
>>> # Copies memory due to dtype mismatch
>>> t2=torch.asarray(array,dtype=torch.float32)
>>> array.__array_interface__['data'][0]==t1.data_ptr()
False
",,,
"
 torch. as_tensor ( data ,  dtype ,  device )   → ¶","Converts data into a tensor, sharing data and preserving autograd
history if possible. If data is already a tensor with the requested dtype and device
then data itself is returned, but if data is a
tensor with a different dtype or device then it’s copied as if using
 data.to(dtype=dtype, device=device) . If data is a NumPy array (an ndarray) with the same dtype and device then a
tensor is constructed using  torch.from_numpy() . 
 See also 
 torch.tensor() 
 
 Parameters 
 
 
 Example: 
",">>> a=numpy.array([1,2,3])
>>> t=torch.as_tensor(a)
>>> t
tensor([ 1,  2,  3])
>>> t[0]=-1
>>> a
array([-1,  2,  3])>>> a=numpy.array([1,2,3])
>>> t=torch.as_tensor(a,device=torch.device('cuda'))
>>> t
tensor([ 1,  2,  3])
>>> t[0]=-1
>>> a
array([1,  2,  3])
",,,
"
 torch. as_strided ( input ,  size ,  stride ,  storage_offset )   → ¶","Create a view of an existing  torch.Tensor   input  with specified
 size ,  stride  and  storage_offset . 
 Warning 
 Prefer using other view functions, like  
 
 Parameters 
 
 
 Example: 
",">>> x=torch.randn(3,3)
>>> x
tensor([[ 0.9039,  0.6291,  1.0795],
        [ 0.1586,  2.1939, -0.4900],
        [-0.1909, -0.7503,  1.9355]])
>>> t=torch.as_strided(x,(2,2),(1,2))
>>> t
tensor([[0.9039, 1.0795],
        [0.6291, 0.1586]])
>>> t=torch.as_strided(x,(2,2),(1,2),1)
tensor([[0.6291, 0.1586],
        [1.0795, 2.1939]])
",,,
"
 torch. from_numpy ( ndarray )   → ¶","Creates a  Tensor  from a  numpy.ndarray . The returned tensor and  ndarray  share the same memory. Modifications to
the tensor will be reflected in the  ndarray  and vice versa. The returned
tensor is not resizable. It currently accepts  ndarray  with dtypes of  numpy.float64 ,
 numpy.float32 ,  numpy.float16 ,  numpy.complex64 ,  numpy.complex128 ,
 numpy.int64 ,  numpy.int32 ,  numpy.int16 ,  numpy.int8 ,  numpy.uint8 ,
and  numpy.bool . 
 Warning 
 Writing to a tensor created from a read-only NumPy array is not supported and will result in undefined behavior. 
 Example: 
",">>> a=numpy.array([1,2,3])
>>> t=torch.from_numpy(a)
>>> t
tensor([ 1,  2,  3])
>>> t[0]=-1
>>> a
array([-1,  2,  3])
",,,
"
 torch. from_dlpack ( ext_tensor )   → [source] ¶","Converts a tensor from an external library into a  torch.Tensor . The returned PyTorch tensor will share the memory with the input tensor
(which may have come from another library). Note that in-place operations
will therefore also affect the data of the input tensor. This may lead to
unexpected issues (e.g., other libraries may have read-only flags or
immutable data structures), so the user should only do this if they know
for sure that this is fine. 
 Parameters 
 ext_tensor 
 Return type 
 Tensor 
 Examples: 
",">>> importtorch.utils.dlpack
>>> t=torch.arange(4)# Convert a tensor directly (supported in PyTorch >= 1.10)
>>> t2=torch.from_dlpack(t)
>>> t2[:2]=-1# show that memory is shared
>>> t2
tensor([-1, -1,  2,  3])
>>> t
tensor([-1, -1,  2,  3])# The old-style DLPack usage, with an intermediate capsule object
>>> capsule=torch.utils.dlpack.to_dlpack(t)
>>> capsule
<capsule object ""dltensor"" at ...>
>>> t3=torch.from_dlpack(capsule)
>>> t3
tensor([-1, -1,  2,  3])
>>> t3[0]=-9# now we're sharing memory between 3 tensors
>>> t3
tensor([-9, -1,  2,  3])
>>> t2
tensor([-9, -1,  2,  3])
>>> t
tensor([-9, -1,  2,  3])
",,,
"
 torch. frombuffer ( buffer ,  * ,  dtype ,  count ,  offset ,  requires_grad )   → ¶","Creates a 1-dimensional  Tensor  from an object that implements
the Python buffer protocol. Skips the first  offset  bytes in the buffer, and interprets the rest of
the raw bytes as a 1-dimensional tensor of type  dtype  with  count 
elements. Note that either of the following must be true: 1.  count  is a positive non-zero number, and the total number of bytes
in the buffer is less than  offset  plus  count  times the size
(in bytes) of  dtype . 2.  count  is negative, and the length (number of bytes) of the buffer
subtracted by the  offset  is a multiple of the size (in bytes) of
 dtype . The returned tensor and buffer share the same memory. Modifications to
the tensor will be reflected in the buffer and vice versa. The returned
tensor is not resizable. 
 Note 
 This function increments the reference count for the object that
owns the shared memory. Therefore, such memory will not be deallocated
before the returned tensor goes out of scope. 
 
 Warning 
 This function’s behavior is undefined when passed an object implementing
the buffer protocol whose data is not on the CPU. Doing so is likely to
cause a segmentation fault. 
 
 Warning 
 This function does not try to infer the  
 
 Parameters 
 buffer 
 Keyword Arguments 
 
 
 Example: 
",">>> importarray
>>> a=array.array('i',[1,2,3])
>>> t=torch.frombuffer(a,dtype=torch.int32)
>>> t
tensor([ 1,  2,  3])
>>> t[0]=-1
>>> a
array([-1,  2,  3])>>> # Interprets the signed char bytes as 32-bit integers.
>>> # Each 4 signed char elements will be interpreted as
>>> # 1 signed 32-bit integer.
>>> importarray
>>> a=array.array('b',[-1,0,0,0])
>>> torch.frombuffer(a,dtype=torch.int32)
tensor([255], dtype=torch.int32)
",,,
"
 torch. zeros ( *size ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False )   → ¶","Returns a tensor filled with the scalar value  0 , with the shape defined
by the variable argument  size . 
 Parameters 
 size 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.zeros(2,3)
tensor([[ 0.,  0.,  0.],
        [ 0.,  0.,  0.]])>>> torch.zeros(5)
tensor([ 0.,  0.,  0.,  0.,  0.])
",,,
"
 torch. zeros_like ( input ,  * ,  dtype ,  layout ,  device ,  requires_grad ,  memory_format )   → ¶","Returns a tensor filled with the scalar value  0 , with the same size as
 input .  torch.zeros_like(input)  is equivalent to
 torch.zeros(input.size(), . 
 Warning 
 As of 0.4, this function does not support an  
 
 Parameters 
 input 
 Keyword Arguments 
 
 
 Example: 
",">>> input=torch.empty(2,3)
>>> torch.zeros_like(input)
tensor([[ 0.,  0.,  0.],
        [ 0.,  0.,  0.]])
",,,
"
 torch. ones ( *size ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False )   → ¶","Returns a tensor filled with the scalar value  1 , with the shape defined
by the variable argument  size . 
 Parameters 
 size 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.ones(2,3)
tensor([[ 1.,  1.,  1.],
        [ 1.,  1.,  1.]])>>> torch.ones(5)
tensor([ 1.,  1.,  1.,  1.,  1.])
",,,
"
 torch. ones_like ( input ,  * ,  dtype ,  layout ,  device ,  requires_grad ,  memory_format )   → ¶","Returns a tensor filled with the scalar value  1 , with the same size as
 input .  torch.ones_like(input)  is equivalent to
 torch.ones(input.size(), . 
 Warning 
 As of 0.4, this function does not support an  
 
 Parameters 
 input 
 Keyword Arguments 
 
 
 Example: 
",">>> input=torch.empty(2,3)
>>> torch.ones_like(input)
tensor([[ 1.,  1.,  1.],
        [ 1.,  1.,  1.]])
",,,
"
 torch. arange ( start=0 ,  end ,  step=1 ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False )   → ¶","Returns a 1-D tensor of size  ⌈ 
with values from the interval  [start,  taken with common difference
 step  beginning from  start . Note that non-integer  step  is subject to floating point rounding errors when
comparing against  end ; to avoid inconsistency, we advise adding a small epsilon to  end 
in such cases. 
 out 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.arange(5)
tensor([ 0,  1,  2,  3,  4])
>>> torch.arange(1,4)
tensor([ 1,  2,  3])
>>> torch.arange(1,2.5,0.5)
tensor([ 1.0000,  1.5000,  2.0000])
",,,
"
 torch. range ( start=0 ,  end ,  step=1 ,  * ,  out=None ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False )   → ¶","Returns a 1-D tensor of size  ⌊ 
with values from  start  to  end  with step  step . Step is
the gap between two values in the tensor. 
 out 
 Warning 
 This function is deprecated and will be removed in a future release because its behavior is inconsistent with
Python’s range builtin. Instead, use  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.range(1,4)
tensor([ 1.,  2.,  3.,  4.])
>>> torch.range(1,4,0.5)
tensor([ 1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000])
",,,
"
 torch. linspace ( start ,  end ,  steps ,  * ,  out ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Creates a one-dimensional tensor of size  steps  whose values are evenly
spaced from  start  to  end , inclusive. That is, the value are: 
 ( From PyTorch 1.11 linspace requires the steps argument. Use steps=100 to restore the previous behavior. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.linspace(3,10,steps=5)
tensor([  3.0000,   4.7500,   6.5000,   8.2500,  10.0000])
>>> torch.linspace(-10,10,steps=5)
tensor([-10.,  -5.,   0.,   5.,  10.])
>>> torch.linspace(start=-10,end=10,steps=5)
tensor([-10.,  -5.,   0.,   5.,  10.])
>>> torch.linspace(start=-10,end=10,steps=1)
tensor([-10.])
",,,
"
 torch. logspace ( start ,  end ,  steps ,  base ,  * ,  out ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Creates a one-dimensional tensor of size  steps  whose values are evenly
spaced from  base  to
 base , inclusive, on a logarithmic scale
with base  base . That is, the values are: 
 ( From PyTorch 1.11 logspace requires the steps argument. Use steps=100 to restore the previous behavior. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.logspace(start=-10,end=10,steps=5)
tensor([ 1.0000e-10,  1.0000e-05,  1.0000e+00,  1.0000e+05,  1.0000e+10])
>>> torch.logspace(start=0.1,end=1.0,steps=5)
tensor([  1.2589,   2.1135,   3.5481,   5.9566,  10.0000])
>>> torch.logspace(start=0.1,end=1.0,steps=1)
tensor([1.2589])
>>> torch.logspace(start=2,end=2,steps=1,base=2)
tensor([4.0])
",,,
"
 torch. eye ( n ,  m ,  * ,  out ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Returns a 2-D tensor with ones on the diagonal and zeros elsewhere. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A 2-D tensor with ones on the diagonal and zeros elsewhere 
 Return type 
 Tensor 
 Example: 
",">>> torch.eye(3)
tensor([[ 1.,  0.,  0.],
        [ 0.,  1.,  0.],
        [ 0.,  0.,  1.]])
",,,
"
 torch. empty_like ( input ,  * ,  dtype ,  layout ,  device ,  requires_grad ,  memory_format )   → ¶","Returns an uninitialized tensor with the same size as  input .
 torch.empty_like(input)  is equivalent to
 torch.empty(input.size(), . 
 Parameters 
 input 
 Keyword Arguments 
 
 
 Example: 
",">>> a=torch.empty((2,3),dtype=torch.int32,device='cuda')
>>> torch.empty_like(a)
tensor([[0, 0, 0],
        [0, 0, 0]], device='cuda:0', dtype=torch.int32)
",,,
"
 torch. empty_strided ( size ,  stride ,  * ,  dtype ,  layout ,  device ,  requires_grad ,  pin_memory )   → ¶","Creates a tensor with the specified  size  and  stride  and filled with undefined data. 
 Warning 
 If the constructed tensor is “overlapped” (with multiple indices referring to the same element
in memory) its behavior is undefined. 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> a=torch.empty_strided((2,3),(1,2))
>>> a
tensor([[8.9683e-44, 4.4842e-44, 5.1239e+07],
        [0.0000e+00, 0.0000e+00, 3.0705e-41]])
>>> a.stride()
(1, 2)
>>> a.size()
torch.Size([2, 3])
",,,
"
 torch. full ( size ,  fill_value ,  * ,  out ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Creates a tensor of size  size  filled with  fill_value . The
tensor’s dtype is inferred from  fill_value . 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> torch.full((2,3),3.141592)
tensor([[ 3.1416,  3.1416,  3.1416],
        [ 3.1416,  3.1416,  3.1416]])
",,,
"
 torch. full_like ( input ,  fill_value ,  \* ,  dtype=None ,  layout=torch.strided ,  device=None ,  requires_grad=False ,  memory_format=torch.preserve_format )   → ¶","Returns a tensor with the same size as  input  filled with  fill_value .
 torch.full_like(input,  is equivalent to
 torch.full(input.size(), . 
 Parameters 
 
 
 Keyword Arguments 
 
 
",,,,
"
 torch. quantize_per_tensor ( input ,  scale ,  zero_point ,  dtype )   → ¶","Converts a float tensor to a quantized tensor with given scale and zero point. 
 Parameters 
 
 
 Returns 
 A newly quantized tensor or list of quantized tensors. 
 Return type 
 Tensor 
 Example: 
",">>> torch.quantize_per_tensor(torch.tensor([-1.0,0.0,1.0,2.0]),0.1,10,torch.quint8)
tensor([-1.,  0.,  1.,  2.], size=(4,), dtype=torch.quint8,
       quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10)
>>> torch.quantize_per_tensor(torch.tensor([-1.0,0.0,1.0,2.0]),0.1,10,torch.quint8).int_repr()
tensor([ 0, 10, 20, 30], dtype=torch.uint8)
>>> torch.quantize_per_tensor([torch.tensor([-1.0,0.0]),torch.tensor([-2.0,2.0])],
>>> torch.tensor([0.1,0.2]),torch.tensor([10,20]),torch.quint8)
(tensor([-1.,  0.], size=(2,), dtype=torch.quint8,
    quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10),
    tensor([-2.,  2.], size=(2,), dtype=torch.quint8,
    quantization_scheme=torch.per_tensor_affine, scale=0.2, zero_point=20))
>>> torch.quantize_per_tensor(torch.tensor([-1.0,0.0,1.0,2.0]),torch.tensor(0.1),torch.tensor(10),torch.quint8)
tensor([-1.,  0.,  1.,  2.], size=(4,), dtype=torch.quint8,
   quantization_scheme=torch.per_tensor_affine, scale=0.10, zero_point=10)
",,,
"
 torch. quantize_per_channel ( input ,  scales ,  zero_points ,  axis ,  dtype )   → ¶","Converts a float tensor to a per-channel quantized tensor with given scales and zero points. 
 Parameters 
 
 
 Returns 
 A newly quantized tensor 
 Return type 
 Tensor 
 Example: 
",">>> x=torch.tensor([[-1.0,0.0],[1.0,2.0]])
>>> torch.quantize_per_channel(x,torch.tensor([0.1,0.01]),torch.tensor([10,0]),0,torch.quint8)
tensor([[-1.,  0.],
        [ 1.,  2.]], size=(2, 2), dtype=torch.quint8,
       quantization_scheme=torch.per_channel_affine,
       scale=tensor([0.1000, 0.0100], dtype=torch.float64),
       zero_point=tensor([10,  0]), axis=0)
>>> torch.quantize_per_channel(x,torch.tensor([0.1,0.01]),torch.tensor([10,0]),0,torch.quint8).int_repr()
tensor([[  0,  10],
        [100, 200]], dtype=torch.uint8)
",,,
"
 torch. dequantize ( tensor )   → ¶","Returns an fp32 Tensor by dequantizing a quantized Tensor 
 Parameters 
 tensor 
 
 
 
 Given a list of quantized Tensors, dequantize them and return a list of fp32 Tensors 
 Parameters 
 tensors 
",,,,
"
 torch. complex ( real ,  imag ,  * ,  out )   → ¶","Constructs a complex tensor with its real part equal to  real  and its
imaginary part equal to  imag . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> real=torch.tensor([1,2],dtype=torch.float32)
>>> imag=torch.tensor([3,4],dtype=torch.float32)
>>> z=torch.complex(real,imag)
>>> z
tensor([(1.+3.j), (2.+4.j)])
>>> z.dtype
torch.complex64
",,,
"
 torch. real ( input )   → ¶","Returns a new tensor containing real values of the  self  tensor.
The returned tensor and  self  share the same underlying storage. 
 Parameters 
 input 
 Example: 
",">>> x=torch.randn(4,dtype=torch.cfloat)
>>> x
tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])
>>> x.real
tensor([ 0.3100, -0.5445, -1.6492, -0.0638])
",,,
"
 torch. imag ( input )   → ¶","Returns a new tensor containing imaginary values of the  self  tensor.
The returned tensor and  self  share the same underlying storage. 
 Warning 
 imag() 
 
 Parameters 
 input 
 Example: 
",">>> x=torch.randn(4,dtype=torch.cfloat)
>>> x
tensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])
>>> x.imag
tensor([ 0.3553, -0.7896, -0.0633, -0.8119])
",,,
"
 torch. polar ( abs ,  angle ,  * ,  out )   → ¶","Constructs a complex tensor whose elements are Cartesian coordinates
corresponding to the polar coordinates with absolute value  abs  and angle
 angle . 
 out 
 Note 
 torch.polar 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> importnumpyasnp
>>> abs=torch.tensor([1,2],dtype=torch.float64)
>>> angle=torch.tensor([np.pi/2,5*np.pi/4],dtype=torch.float64)
>>> z=torch.polar(abs,angle)
>>> z
tensor([(0.0000+1.0000j), (-1.4142-1.4142j)], dtype=torch.complex128)
",,,
"
 torch. abs ( input ,  * ,  out )   → ¶","Computes the absolute value of each element in  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.abs(torch.tensor([-1,-2,3]))
tensor([ 1,  2,  3])
",,,
"
 torch. angle ( input ,  * ,  out )   → ¶","Computes the element-wise angle (in radians) of the given  input  tensor. 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 
 Note 
 Starting in PyTorch 1.8, angle returns pi for negative real numbers,
zero for non-negative real numbers, and propagates NaNs. Previously
the function would return zero for all real numbers and not propagate
floating-point NaNs. 
 Example: 
",">>> torch.angle(torch.tensor([-1+1j,-2+2j,3-3j]))*180/3.14159
tensor([ 135.,  135,  -45])
",,,
"
 torch. heaviside ( input ,  values ,  * ,  out )   → ¶","Computes the Heaviside step function for each element in  input .
The Heaviside step function is defined as: 
 heaviside 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> input=torch.tensor([-1.5,0,2.0])
>>> values=torch.tensor([0.5])
>>> torch.heaviside(input,values)
tensor([0.0000, 0.5000, 1.0000])
>>> values=torch.tensor([1.2,-2.0,3.5])
>>> torch.heaviside(input,values)
tensor([0., -2., 1.])
",,,
"
 torch. adjoint ( Tensor )   → ¶","Returns a view of the tensor conjugated and with the last two dimensions transposed. x.adjoint()  is equivalent to  x.transpose(-2,  for complex tensors and
to  x.transpose(-2,  for real tensors. 
 Example:: 
",,,,
"
 torch. argwhere ( input )   → ¶","Returns a tensor containing the indices of all non-zero elements of
 input .  Each row in the result contains the indices of a non-zero
element in  input . The result is sorted lexicographically, with
the last index changing the fastest (C-style). If  input  has  n  dimensions, then the resulting indices tensor
 out  is of size  ( , where  z  is the total number of
non-zero elements in the  input  tensor. 
 Note 
 This function is similar to NumPy’s  
 When  
 
 Parameters 
 {input} 
 Example: 
",">>> t=torch.tensor([1,0,1])
>>> torch.argwhere(t)
tensor([[0],
        [2]])
>>> t=torch.tensor([[1,0,1],[0,1,1]])
>>> torch.argwhere(t)
tensor([[0, 0],
        [0, 2],
        [1, 1],
        [1, 2]])
",,,
"
 torch. cat ( tensors ,  dim ,  * ,  out )   → ¶","Concatenates the given sequence of  seq  tensors in the given dimension.
All tensors must either have the same shape (except in the concatenating
dimension) or be empty. torch.cat()  can be seen as an inverse operation for  torch.split() 
and  torch.chunk() . torch.cat()  can be best understood via examples. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> x=torch.randn(2,3)
>>> x
tensor([[ 0.6580, -1.0969, -0.4614],
        [-0.1034, -0.5790,  0.1497]])
>>> torch.cat((x,x,x),0)
tensor([[ 0.6580, -1.0969, -0.4614],
        [-0.1034, -0.5790,  0.1497],
        [ 0.6580, -1.0969, -0.4614],
        [-0.1034, -0.5790,  0.1497],
        [ 0.6580, -1.0969, -0.4614],
        [-0.1034, -0.5790,  0.1497]])
>>> torch.cat((x,x,x),1)
tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,
         -1.0969, -0.4614],
        [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,
         -0.5790,  0.1497]])
",,,
"
 torch. concat ( tensors ,  dim ,  * ,  out )   → ¶",Alias of  torch.cat() .,,,,
"
 torch. concatenate ( tensors ,  axis ,  out )   → ¶",Alias of  torch.cat() .,,,,
"
 torch. conj ( input )   → ¶","Returns a view of  input  with a flipped conjugate bit. If  input  has a non-complex dtype,
this function just returns  input . 
 Note 
 torch.conj() 
 
 Warning 
 In the future,  
 
 Parameters 
 input 
 Example: 
",">>> x=torch.tensor([-1+1j,-2+2j,3-3j])
>>> x.is_conj()
False
>>> y=torch.conj(x)
>>> y.is_conj()
True
",,,
"
 torch. chunk ( input ,  chunks ,  dim )   → ¶","Attempts to split a tensor into the specified number of chunks. Each chunk is a view of
the input tensor. 
 Note 
 This function may return less then the specified number of chunks! 
 
 See also 
 torch.tensor_split() 
 If the tensor size along the given dimesion  dim  is divisible by  chunks ,
all returned chunks will be the same size.
If the tensor size along the given dimension  dim  is not divisible by  chunks ,
all returned chunks will be the same size, except the last one.
If such division is not possible, this function may return less
than the specified number of chunks. 
 Parameters 
 
 
 
 Example:: 
",,,,
"
 torch. dsplit ( input ,  indices_or_sections )   → ¶","Splits  input , a tensor with three or more dimensions, into multiple tensors
depthwise according to  indices_or_sections . Each split is a view of
 input . This is equivalent to calling torch.tensor_split(input, indices_or_sections, dim=2)
(the split dimension is 2), except that if  indices_or_sections  is an integer
it must evenly divide the split dimension or a runtime error will be thrown. This function is based on NumPy’s  numpy.dsplit() . 
 Parameters 
 
 
 
 Example:: 
",,,,
"
 torch. column_stack ( tensors ,  * ,  out )   → ¶","Creates a new tensor by horizontally stacking the tensors in  tensors . Equivalent to  torch.hstack(tensors) , except each zero or one dimensional tensor  t 
in  tensors  is first reshaped into a  (t.numel(),  column before being stacked horizontally. 
 Parameters 
 tensors 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([1,2,3])
>>> b=torch.tensor([4,5,6])
>>> torch.column_stack((a,b))
tensor([[1, 4],
    [2, 5],
    [3, 6]])
>>> a=torch.arange(5)
>>> b=torch.arange(10).reshape(5,2)
>>> torch.column_stack((a,b,b))
tensor([[0, 0, 1, 0, 1],
        [1, 2, 3, 2, 3],
        [2, 4, 5, 4, 5],
        [3, 6, 7, 6, 7],
        [4, 8, 9, 8, 9]])
",,,
"
 torch. dstack ( tensors ,  * ,  out )   → ¶","Stack tensors in sequence depthwise (along third axis). This is equivalent to concatenation along the third axis after 1-D and 2-D tensors have been reshaped by  torch.atleast_3d() . 
 Parameters 
 tensors 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([1,2,3])
>>> b=torch.tensor([4,5,6])
>>> torch.dstack((a,b))
tensor([[[1, 4],
         [2, 5],
         [3, 6]]])
>>> a=torch.tensor([[1],[2],[3]])
>>> b=torch.tensor([[4],[5],[6]])
>>> torch.dstack((a,b))
tensor([[[1, 4]],
        [[2, 5]],
        [[3, 6]]])
",,,
"
 torch. gather ( input ,  dim ,  index ,  * ,  sparse_grad ,  out )   → ¶","Gathers values along an axis specified by  dim . For a 3-D tensor the output is specified by: 
 input  and  index  must have the same number of dimensions.
It is also required that  index.size(d)  for all
dimensions  d .   out  will have the same shape as  index .
Note that  input  and  index  do not broadcast against each other. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> t=torch.tensor([[1,2],[3,4]])
>>> torch.gather(t,1,torch.tensor([[0,0],[1,0]]))
tensor([[ 1,  1],
        [ 4,  3]])
",,,
"
 torch. hsplit ( input ,  indices_or_sections )   → ¶","Splits  input , a tensor with one or more dimensions, into multiple tensors
horizontally according to  indices_or_sections . Each split is a view of
 input . If  input  is one dimensional this is equivalent to calling
torch.tensor_split(input, indices_or_sections, dim=0) (the split dimension is
zero), and if  input  has two or more dimensions it’s equivalent to calling
torch.tensor_split(input, indices_or_sections, dim=1) (the split dimension is 1),
except that if  indices_or_sections  is an integer it must evenly divide
the split dimension or a runtime error will be thrown. This function is based on NumPy’s  numpy.hsplit() . 
 Parameters 
 
 
 
 Example:: 
",,,,
"
 torch. hstack ( tensors ,  * ,  out )   → ¶","Stack tensors in sequence horizontally (column wise). This is equivalent to concatenation along the first axis for 1-D tensors, and along the second axis for all other tensors. 
 Parameters 
 tensors 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([1,2,3])
>>> b=torch.tensor([4,5,6])
>>> torch.hstack((a,b))
tensor([1, 2, 3, 4, 5, 6])
>>> a=torch.tensor([[1],[2],[3]])
>>> b=torch.tensor([[4],[5],[6]])
>>> torch.hstack((a,b))
tensor([[1, 4],
        [2, 5],
        [3, 6]])
",,,
"
 torch. index_add ( input ,  dim ,  index ,  source ,  * ,  alpha ,  out )   → ¶",See  index_add_()  for function description.,,,,
"
 Tensor. index_add_ ( dim ,  index ,  source ,  * ,  alpha )   → ¶","Accumulate the elements of  alpha  times  source  into the  self 
tensor by adding to the indices in the order given in  index . For example,
if  dim ,  index[i] , and  alpha=-1 , then the  i th row of
 source  is subtracted from the  j th row of  self . The  dim th dimension of  source  must have the same size as the
length of  index  (which must be a vector), and all other dimensions must
match  self , or an error will be raised. For a 3-D tensor the output is given as: 
 
 Note 
 This operation may behave nondeterministically when given tensors on a CUDA device. See  
 
 Parameters 
 
 
 Keyword Arguments 
 alpha 
 Example: 
",">>> x=torch.ones(5,3)
>>> t=torch.tensor([[1,2,3],[4,5,6],[7,8,9]],dtype=torch.float)
>>> index=torch.tensor([0,4,2])
>>> x.index_add_(0,index,t)
tensor([[  2.,   3.,   4.],
        [  1.,   1.,   1.],
        [  8.,   9.,  10.],
        [  1.,   1.,   1.],
        [  5.,   6.,   7.]])
>>> x.index_add_(0,index,t,alpha=-1)
tensor([[  1.,   1.,   1.],
        [  1.,   1.,   1.],
        [  1.,   1.,   1.],
        [  1.,   1.,   1.],
        [  1.,   1.,   1.]])
",,,
"
 torch. index_copy ( input ,  dim ,  index ,  source ,  * ,  out )   → ¶",See  index_add_()  for function description.,,,,
"
 torch. index_reduce ( input ,  dim ,  index ,  source ,  reduce ,  * ,  include_self ,  out )   → ¶",See  index_reduce_()  for function description.,,,,
"
 Tensor. index_reduce_ ( dim ,  index ,  source ,  reduce ,  * ,  include_self )   → ¶","Accumulate the elements of  source  into the  self 
tensor by accumulating to the indices in the order given in  index 
using the reduction given by the  reduce  argument. For example, if  dim ,
 index[i] ,  reduce  and  include_self  then the  i th
row of  source  is multiplied by the  j th row of  self . If
 include_self=""True"" , the values in the  self  tensor are included
in the reduction, otherwise, rows in the  self  tensor that are accumulated
to are treated as if they were filled with the reduction identites. The  dim th dimension of  source  must have the same size as the
length of  index  (which must be a vector), and all other dimensions must
match  self , or an error will be raised. For a 3-D tensor with  reduce=""prod""  and  include_self=True  the
output is given as: 
 
 Note 
 This operation may behave nondeterministically when given tensors on a CUDA device. See  
 
 Note 
 This function only supports floating point tensors. 
 
 Warning 
 This function is in beta and may change in the near future. 
 
 Parameters 
 
 
 Keyword Arguments 
 include_self 
 Example: 
",">>> x=torch.empty(5,3).fill_(2)
>>> t=torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]],dtype=torch.float)
>>> index=torch.tensor([0,4,2,0])
>>> x.index_reduce_(0,index,t,'prod')
tensor([[20., 44., 72.],
        [ 2.,  2.,  2.],
        [14., 16., 18.],
        [ 2.,  2.,  2.],
        [ 8., 10., 12.]])
>>> x=torch.empty(5,3).fill_(2)
>>> x.index_reduce_(0,index,t,'prod',include_self=False)
tensor([[10., 22., 36.],
        [ 2.,  2.,  2.],
        [ 7.,  8.,  9.],
        [ 2.,  2.,  2.],
        [ 4.,  5.,  6.]])
",,,
"
 torch. index_select ( input ,  dim ,  index ,  * ,  out )   → ¶","Returns a new tensor which indexes the  input  tensor along dimension
 dim  using the entries in  index  which is a  LongTensor . The returned tensor has the same number of dimensions as the original tensor
( input ).  The  dim th dimension has the same size as the length
of  index ; other dimensions have the same size as in the original tensor. 
 Note 
 The returned tensor does  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> x=torch.randn(3,4)
>>> x
tensor([[ 0.1427,  0.0231, -0.5414, -1.0009],
        [-0.4664,  0.2647, -0.1228, -1.1068],
        [-1.1734, -0.6571,  0.7230, -0.6004]])
>>> indices=torch.tensor([0,2])
>>> torch.index_select(x,0,indices)
tensor([[ 0.1427,  0.0231, -0.5414, -1.0009],
        [-1.1734, -0.6571,  0.7230, -0.6004]])
>>> torch.index_select(x,1,indices)
tensor([[ 0.1427, -0.5414],
        [-0.4664, -0.1228],
        [-1.1734,  0.7230]])
",,,
"
 torch. masked_select ( input ,  mask ,  * ,  out )   → ¶","Returns a new 1-D tensor which indexes the  input  tensor according to
the boolean mask  mask  which is a  BoolTensor . The shapes of the  mask  tensor and the  input  tensor don’t need
to match, but they must be  broadcastable . 
 Note 
 The returned tensor does  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> x=torch.randn(3,4)
>>> x
tensor([[ 0.3552, -2.3825, -0.8297,  0.3477],
        [-1.2035,  1.2252,  0.5002,  0.6248],
        [ 0.1307, -2.0608,  0.1244,  2.0139]])
>>> mask=x.ge(0.5)
>>> mask
tensor([[False, False, False, False],
        [False, True, True, True],
        [False, False, False, True]])
>>> torch.masked_select(x,mask)
tensor([ 1.2252,  0.5002,  0.6248,  2.0139])
",,,
"
 torch. movedim ( input ,  source ,  destination )   → ¶","Moves the dimension(s) of  input  at the position(s) in  source 
to the position(s) in  destination . Other dimensions of  input  that are not explicitly moved remain in
their original order and appear at the positions not specified in  destination . 
 Parameters 
 
 
 Examples: 
",">>> t=torch.randn(3,2,1)
>>> t
tensor([[[-0.3362],
        [-0.8437]],        [[-0.9627],
        [ 0.1727]],        [[ 0.5173],
        [-0.1398]]])
>>> torch.movedim(t,1,0).shape
torch.Size([2, 3, 1])
>>> torch.movedim(t,1,0)
tensor([[[-0.3362],
        [-0.9627],
        [ 0.5173]],        [[-0.8437],
        [ 0.1727],
        [-0.1398]]])
>>> torch.movedim(t,(1,2),(0,1)).shape
torch.Size([2, 1, 3])
>>> torch.movedim(t,(1,2),(0,1))
tensor([[[-0.3362, -0.9627,  0.5173]],        [[-0.8437,  0.1727, -0.1398]]])
",,,
"
 torch. moveaxis ( input ,  source ,  destination )   → ¶","Alias for  torch.movedim() . This function is equivalent to NumPy’s moveaxis function. Examples: 
",">>> t=torch.randn(3,2,1)
>>> t
tensor([[[-0.3362],
        [-0.8437]],        [[-0.9627],
        [ 0.1727]],        [[ 0.5173],
        [-0.1398]]])
>>> torch.moveaxis(t,1,0).shape
torch.Size([2, 3, 1])
>>> torch.moveaxis(t,1,0)
tensor([[[-0.3362],
        [-0.9627],
        [ 0.5173]],        [[-0.8437],
        [ 0.1727],
        [-0.1398]]])
>>> torch.moveaxis(t,(1,2),(0,1)).shape
torch.Size([2, 1, 3])
>>> torch.moveaxis(t,(1,2),(0,1))
tensor([[[-0.3362, -0.9627,  0.5173]],        [[-0.8437,  0.1727, -0.1398]]])
",,,
"
 torch. narrow ( input ,  dim ,  start ,  length )   → ¶","Returns a new tensor that is a narrowed version of  input  tensor. The
dimension  dim  is input from  start  to  start . The
returned tensor and  input  tensor share the same underlying storage. 
 Parameters 
 
 
 Example: 
",">>> x=torch.tensor([[1,2,3],[4,5,6],[7,8,9]])
>>> torch.narrow(x,0,0,2)
tensor([[ 1,  2,  3],
        [ 4,  5,  6]])
>>> torch.narrow(x,1,1,2)
tensor([[ 2,  3],
        [ 5,  6],
        [ 8,  9]])
",,,
"
 torch. nonzero ( input ,  * ,  out ,  as_tuple )   → ¶","
 Note 
 torch.nonzero(..., 
 torch.nonzero(..., 
 See below for more details on the two behaviors. 
 When  
 When   as_tuple   is   False   (default) : Returns a tensor containing the indices of all non-zero elements of
 input .  Each row in the result contains the indices of a non-zero
element in  input . The result is sorted lexicographically, with
the last index changing the fastest (C-style). If  input  has  n  dimensions, then the resulting indices tensor
 out  is of size  ( , where  z  is the total number of
non-zero elements in the  input  tensor. When   as_tuple   is   True : Returns a tuple of 1-D tensors, one for each dimension in  input ,
each containing the indices (in that dimension) of all non-zero elements of
 input  . If  input  has  n  dimensions, then the resulting tuple contains  n 
tensors of size  z , where  z  is the total number of
non-zero elements in the  input  tensor. As a special case, when  input  has zero dimensions and a nonzero scalar
value, it is treated as a one-dimensional tensor with one element. 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Returns 
 If  
 Return type 
 LongTensor or tuple of LongTensor 
 Example: 
",">>> torch.nonzero(torch.tensor([1,1,1,0,1]))
tensor([[ 0],
        [ 1],
        [ 2],
        [ 4]])
>>> torch.nonzero(torch.tensor([[0.6,0.0,0.0,0.0],
... [0.0,0.4,0.0,0.0],
... [0.0,0.0,1.2,0.0],
... [0.0,0.0,0.0,-0.4]]))
tensor([[ 0,  0],
        [ 1,  1],
        [ 2,  2],
        [ 3,  3]])
>>> torch.nonzero(torch.tensor([1,1,1,0,1]),as_tuple=True)
(tensor([0, 1, 2, 4]),)
>>> torch.nonzero(torch.tensor([[0.6,0.0,0.0,0.0],
... [0.0,0.4,0.0,0.0],
... [0.0,0.0,1.2,0.0],
... [0.0,0.0,0.0,-0.4]]),as_tuple=True)
(tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3]))
>>> torch.nonzero(torch.tensor(5),as_tuple=True)
(tensor([0]),)
",,,
"
 torch. permute ( input ,  dims )   → ¶","Returns a view of the original tensor  input  with its dimensions permuted. 
 Parameters 
 
 
 Example 
",,,,
"
 torch. reshape ( input ,  shape )   → ¶","Returns a tensor with the same data and number of elements as  input ,
but with the specified shape. When possible, the returned tensor will be a view
of  input . Otherwise, it will be a copy. Contiguous inputs and inputs
with compatible strides can be reshaped without copying, but you should not
depend on the copying vs. viewing behavior. See  torch.Tensor.view()  on when it is possible to return a view. A single dimension may be -1, in which case it’s inferred from the remaining
dimensions and the number of elements in  input . 
 Parameters 
 
 
 Example: 
",">>> a=torch.arange(4.)
>>> torch.reshape(a,(2,2))
tensor([[ 0.,  1.],
        [ 2.,  3.]])
>>> b=torch.tensor([[0,1],[2,3]])
>>> torch.reshape(b,(-1,))
tensor([ 0,  1,  2,  3])
",,,
"
 torch. row_stack ( tensors ,  * ,  out )   → ¶",Alias of  torch.vstack() .,,,,
"
 torch. vstack ( tensors ,  * ,  out )   → ¶","Stack tensors in sequence vertically (row wise). This is equivalent to concatenation along the first axis after all 1-D tensors have been reshaped by  torch.atleast_2d() . 
 Parameters 
 tensors 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([1,2,3])
>>> b=torch.tensor([4,5,6])
>>> torch.vstack((a,b))
tensor([[1, 2, 3],
        [4, 5, 6]])
>>> a=torch.tensor([[1],[2],[3]])
>>> b=torch.tensor([[4],[5],[6]])
>>> torch.vstack((a,b))
tensor([[1],
        [2],
        [3],
        [4],
        [5],
        [6]])
",,,
"
 torch. select ( input ,  dim ,  index )   → ¶","Slices the  input  tensor along the selected dimension at the given index.
This function returns a view of the original tensor with the given dimension removed. 
 Parameters 
 
 
 
 Note 
 select() 
",,,,
"
 torch. scatter ( input ,  dim ,  index ,  src )   → ¶",Out-of-place version of  torch.Tensor.scatter_(),,,,
"
 Tensor. scatter_ ( dim ,  index ,  src ,  reduce )   → ¶","Writes all values from the tensor  src  into  self  at the indices
specified in the  index  tensor. For each value in  src , its output
index is specified by its index in  src  for  dimension  and by
the corresponding value in  index  for  dimension . For a 3-D tensor,  self  is updated as: 
 This is the reverse operation of the manner described in  gather() . self ,  index  and  src  (if it is a Tensor) should all have
the same number of dimensions. It is also required that
 index.size(d)  for all dimensions  d , and that
 index.size(d)  for all dimensions  d .
Note that  index  and  src  do not broadcast. Moreover, as for  gather() , the values of  index  must be
between  0  and  self.size(dim)  inclusive. 
 Warning 
 When indices are not unique, the behavior is non-deterministic (one of the
values from  
 
 Note 
 The backward pass is implemented only for  
 Additionally accepts an optional  reduce  argument that allows
specification of an optional reduction operation, which is applied to all
values in the tensor  src  into  self  at the indicies
specified in the  index . For each value in  src , the reduction
operation is applied to an index in  self  which is specified by
its index in  src  for  dimension  and by the corresponding
value in  index  for  dimension . Given a 3-D tensor and reduction using the multiplication operation,  self 
is updated as: 
 Reducing with the addition operation is the same as using
 scatter_add_() . 
 Parameters 
 
 
 Example: 
",">>> src=torch.arange(1,11).reshape((2,5))
>>> src
tensor([[ 1,  2,  3,  4,  5],
        [ 6,  7,  8,  9, 10]])
>>> index=torch.tensor([[0,1,2,0]])
>>> torch.zeros(3,5,dtype=src.dtype).scatter_(0,index,src)
tensor([[1, 0, 0, 4, 0],
        [0, 2, 0, 0, 0],
        [0, 0, 3, 0, 0]])
>>> index=torch.tensor([[0,1,2],[0,1,4]])
>>> torch.zeros(3,5,dtype=src.dtype).scatter_(1,index,src)
tensor([[1, 2, 3, 0, 0],
        [6, 7, 0, 0, 8],
        [0, 0, 0, 0, 0]])>>> torch.full((2,4),2.).scatter_(1,torch.tensor([[2],[3]]),
... 1.23,reduce='multiply')
tensor([[2.0000, 2.0000, 2.4600, 2.0000],
        [2.0000, 2.0000, 2.0000, 2.4600]])
>>> torch.full((2,4),2.).scatter_(1,torch.tensor([[2],[3]]),
... 1.23,reduce='add')
tensor([[2.0000, 2.0000, 3.2300, 2.0000],
        [2.0000, 2.0000, 2.0000, 3.2300]])
",,,
"
 torch. diagonal_scatter ( input ,  src ,  offset ,  dim1 ,  dim2 )   → ¶","Embeds the values of the  src  tensor into  input  along
the diagonal elements of  input , with respect to  dim1 
and  dim2 . This function returns a tensor with fresh storage; it does not
return a view. The argument  offset  controls which diagonal to consider: 
 If  
 If  
 If  
 
 Parameters 
 
 
 
 Note 
 src 
 Examples: 
",">>> a=torch.zeros(3,3)
>>> a
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])>>> torch.diagonal_scatter(a,torch.ones(3),0)
tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]])>>> torch.diagonal_scatter(a,torch.ones(2),1)
tensor([[0., 1., 0.],
        [0., 0., 1.],
        [0., 0., 0.]])
",,,
"
 torch. select_scatter ( input ,  src ,  dim ,  index )   → ¶","Embeds the values of the  src  tensor into  input  at the given index.
This function returns a tensor with fresh storage; it does not create a view. 
 Parameters 
 
 
 
 Note 
 src 
 Example: 
",">>> a=torch.zeros(2,2)
>>> b=torch.ones(2)
>>> a.select_scatter(b,0,0)
tensor([[1., 1.],
        [0., 0.]])
",,,
"
 torch. slice_scatter ( input ,  src ,  dim ,  start ,  end ,  step )   → ¶","Embeds the values of the  src  tensor into  input  at the given
dimension.
This function returns a tensor with fresh storage; it does not create a view. 
 Parameters 
 
 
 Example: 
",">>> a=torch.zeros(8,8)
>>> b=torch.ones(8)
>>> a.slice_scatter(b,start=6)
tensor([[0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0.],
        [1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.]])>>> b=torch.ones(2)
>>> a.slice_scatter(b,dim=1,start=2,end=6,step=2)
tensor([[0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 1., 0., 0., 0.]])
",,,
"
 torch. scatter_add ( input ,  dim ,  index ,  src )   → ¶",Out-of-place version of  torch.Tensor.scatter_add_(),,,,
"
 Tensor. scatter_add_ ( dim ,  index ,  src )   → ¶","Adds all values from the tensor  src  into  self  at the indices
specified in the  index  tensor in a similar fashion as
 scatter_() . For each value in  src , it is added to
an index in  self  which is specified by its index in  src 
for  dimension  and by the corresponding value in  index  for
 dimension . For a 3-D tensor,  self  is updated as: 
 self ,  index  and  src  should have same number of
dimensions. It is also required that  index.size(d)  for all
dimensions  d , and that  index.size(d)  for all dimensions
 d . Note that  index  and  src  do not broadcast. 
 Note 
 This operation may behave nondeterministically when given tensors on a CUDA device. See  
 
 Note 
 The backward pass is implemented only for  
 
 Parameters 
 
 
 Example: 
",">>> src=torch.ones((2,5))
>>> index=torch.tensor([[0,1,2,0,0]])
>>> torch.zeros(3,5,dtype=src.dtype).scatter_add_(0,index,src)
tensor([[1., 0., 0., 1., 1.],
        [0., 1., 0., 0., 0.],
        [0., 0., 1., 0., 0.]])
>>> index=torch.tensor([[0,1,2,0,0],[0,1,2,2,2]])
>>> torch.zeros(3,5,dtype=src.dtype).scatter_add_(0,index,src)
tensor([[2., 0., 0., 1., 1.],
        [0., 2., 0., 0., 0.],
        [0., 0., 2., 1., 1.]])
",,,
"
 torch. scatter_reduce ( input ,  dim ,  index ,  src ,  reduce ,  * ,  include_self )   → ¶",Out-of-place version of  torch.Tensor.scatter_reduce_(),,,,
"
 Tensor. scatter_reduce_ ( dim ,  index ,  src ,  reduce ,  * ,  include_self )   → ¶","Reduces all values from the  src  tensor to the indices specified in
the  index  tensor in the  self  tensor using the applied reduction
defined via the  reduce  argument ( ""sum"" ,  ""prod"" ,  ""mean"" ,
 ""amax"" ,  ""amin"" ). For each value in  src , it is reduced to an
index in  self  which is specified by its index in  src  for
 dimension  and by the corresponding value in  index  for
 dimension . If  include_self=""True"" , the values in the  self 
tensor are included in the reduction. self ,  index  and  src  should all have
the same number of dimensions. It is also required that
 index.size(d)  for all dimensions  d , and that
 index.size(d)  for all dimensions  d .
Note that  index  and  src  do not broadcast. For a 3-D tensor with  reduce=""sum""  and  include_self=True  the
output is given as: 
 
 Note 
 This operation may behave nondeterministically when given tensors on a CUDA device. See  
 
 Note 
 The backward pass is implemented only for  
 
 Warning 
 This function is in beta and may change in the near future. 
 
 Parameters 
 
 
 Example: 
",">>> src=torch.tensor([1.,2.,3.,4.,5.,6.])
>>> index=torch.tensor([0,1,0,1,2,1])
>>> input=torch.tensor([1.,2.,3.,4.])
>>> input.scatter_reduce(0,index,src,reduce=""sum"")
tensor([5., 14., 8., 4.])
>>> input.scatter_reduce(0,index,src,reduce=""sum"",include_self=False)
tensor([4., 12., 5., 4.])
>>> input2=torch.tensor([5.,4.,3.,2.])
>>> input2.scatter_reduce(0,index,src,reduce=""amax"")
tensor([5., 6., 5., 2.])
>>> input2.scatter_reduce(0,index,src,reduce=""amax"",include_self=False)
tensor([3., 6., 5., 2.])
",,,
"
 torch. split ( tensor ,  split_size_or_sections ,  dim ) [source] ¶","Splits the tensor into chunks. Each chunk is a view of the original tensor. If  split_size_or_sections  is an integer type, then  tensor  will
be split into equally sized chunks (if possible). Last chunk will be smaller if
the tensor size along the given dimension  dim  is not divisible by
 split_size . If  split_size_or_sections  is a list, then  tensor  will be split
into  len(split_size_or_sections)  chunks with sizes in  dim  according
to  split_size_or_sections . 
 Parameters 
 
 
 Return type 
 List 
 Example: 
",">>> a=torch.arange(10).reshape(5,2)
>>> a
tensor([[0, 1],
        [2, 3],
        [4, 5],
        [6, 7],
        [8, 9]])
>>> torch.split(a,2)
(tensor([[0, 1],
         [2, 3]]),
 tensor([[4, 5],
         [6, 7]]),
 tensor([[8, 9]]))
>>> torch.split(a,[1,4])
(tensor([[0, 1]]),
 tensor([[2, 3],
         [4, 5],
         [6, 7],
         [8, 9]]))
",,,
"
 torch. squeeze ( input ,  dim )   → ¶","Returns a tensor with all the dimensions of  input  of size  1  removed. For example, if  input  is of shape:
 (  then the  out  tensor
will be of shape:  ( . When  dim  is given, a squeeze operation is done only in the given
dimension. If  input  is of shape:  ( ,
 squeeze(input,  leaves the tensor unchanged, but  squeeze(input, 
will squeeze the tensor to the shape  ( . 
 Note 
 The returned tensor shares the storage with the input tensor,
so changing the contents of one will change the contents of the other. 
 
 Warning 
 If the tensor has a batch dimension of size 1, then  
 
 Parameters 
 
 
 Example: 
",">>> x=torch.zeros(2,1,2,1,2)
>>> x.size()
torch.Size([2, 1, 2, 1, 2])
>>> y=torch.squeeze(x)
>>> y.size()
torch.Size([2, 2, 2])
>>> y=torch.squeeze(x,0)
>>> y.size()
torch.Size([2, 1, 2, 1, 2])
>>> y=torch.squeeze(x,1)
>>> y.size()
torch.Size([2, 2, 1, 2])
",,,
"
 torch. stack ( tensors ,  dim ,  * ,  out )   → ¶","Concatenates a sequence of tensors along a new dimension. All tensors need to be of the same size. 
 Parameters 
 
 
 Keyword Arguments 
 out 
",,,,
"
 torch. swapaxes ( input ,  axis0 ,  axis1 )   → ¶","Alias for  torch.transpose() . This function is equivalent to NumPy’s swapaxes function. Examples: 
",">>> x=torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])
>>> x
tensor([[[0, 1],
        [2, 3]],        [[4, 5],
        [6, 7]]])
>>> torch.swapaxes(x,0,1)
tensor([[[0, 1],
        [4, 5]],        [[2, 3],
        [6, 7]]])
>>> torch.swapaxes(x,0,2)
tensor([[[0, 4],
        [2, 6]],        [[1, 5],
        [3, 7]]])
",,,
"
 torch. transpose ( input ,  dim0 ,  dim1 )   → ¶","Returns a tensor that is a transposed version of  input .
The given dimensions  dim0  and  dim1  are swapped. If  input  is a strided tensor then the resulting  out 
tensor shares its underlying storage with the  input  tensor, so
changing the content of one would change the content of the other. If  input  is a  sparse tensor  then the
resulting  out  tensor  does not  share the underlying storage
with the  input  tensor. If  input  is a  sparse tensor  with compressed
layout (SparseCSR, SparseBSR, SparseCSC or SparseBSC) the arguments
 dim0  and  dim1  must be both batch dimensions, or must
both be sparse dimensions. The batch dimensions of a sparse tensor are the
dimensions preceding the sparse dimensions. 
 Note 
 Transpositions which interchange the sparse dimensions of a  
 
 Parameters 
 
 
 Example: 
 See also  torch.t() .",">>> x=torch.randn(2,3)
>>> x
tensor([[ 1.0028, -0.9893,  0.5809],
        [-0.1669,  0.7299,  0.4942]])
>>> torch.transpose(x,0,1)
tensor([[ 1.0028, -0.1669],
        [-0.9893,  0.7299],
        [ 0.5809,  0.4942]])
",,,
"
 torch. swapdims ( input ,  dim0 ,  dim1 )   → ¶","Alias for  torch.transpose() . This function is equivalent to NumPy’s swapaxes function. Examples: 
",">>> x=torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])
>>> x
tensor([[[0, 1],
        [2, 3]],        [[4, 5],
        [6, 7]]])
>>> torch.swapdims(x,0,1)
tensor([[[0, 1],
        [4, 5]],        [[2, 3],
        [6, 7]]])
>>> torch.swapdims(x,0,2)
tensor([[[0, 4],
        [2, 6]],        [[1, 5],
        [3, 7]]])
",,,
"
 torch. t ( input )   → ¶","Expects  input  to be <= 2-D tensor and transposes dimensions 0
and 1. 0-D and 1-D tensors are returned as is. When input is a 2-D tensor this
is equivalent to  transpose(input, . 
 Parameters 
 input 
 Example: 
 See also  torch.transpose() .",">>> x=torch.randn(())
>>> x
tensor(0.1995)
>>> torch.t(x)
tensor(0.1995)
>>> x=torch.randn(3)
>>> x
tensor([ 2.4320, -0.4608,  0.7702])
>>> torch.t(x)
tensor([ 2.4320, -0.4608,  0.7702])
>>> x=torch.randn(2,3)
>>> x
tensor([[ 0.4875,  0.9158, -0.5872],
        [ 0.3938, -0.6929,  0.6932]])
>>> torch.t(x)
tensor([[ 0.4875,  0.3938],
        [ 0.9158, -0.6929],
        [-0.5872,  0.6932]])
",,,
"
 torch. take ( input ,  index )   → ¶","Returns a new tensor with the elements of  input  at the given indices.
The input tensor is treated as if it were viewed as a 1-D tensor. The result
takes the same shape as the indices. 
 Parameters 
 
 
 Example: 
",">>> src=torch.tensor([[4,3,5],
... [6,7,8]])
>>> torch.take(src,torch.tensor([0,2,5]))
tensor([ 4,  5,  8])
",,,
"
 torch. take_along_dim ( input ,  indices ,  dim ,  * ,  out )   → ¶","Selects values from  input  at the 1-dimensional indices from  indices  along the given  dim . Functions that return indices along a dimension, like  torch.argmax()  and  torch.argsort() ,
are designed to work with this function. See the examples below. 
 Note 
 This function is similar to NumPy’s  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> t=torch.tensor([[10,30,20],[60,40,50]])
>>> max_idx=torch.argmax(t)
>>> torch.take_along_dim(t,max_idx)
tensor([60])
>>> sorted_idx=torch.argsort(t,dim=1)
>>> torch.take_along_dim(t,sorted_idx,dim=1)
tensor([[10, 20, 30],
        [40, 50, 60]])
",,,
"
 torch. tensor_split ( input ,  indices_or_sections ,  dim )   → ¶","Splits a tensor into multiple sub-tensors, all of which are views of  input ,
along dimension  dim  according to the indices or number of sections specified
by  indices_or_sections . This function is based on NumPy’s
 numpy.array_split() . 
 Parameters 
 
 
 Example: 
",">>> x=torch.arange(8)
>>> torch.tensor_split(x,3)
(tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7]))>>> x=torch.arange(7)
>>> torch.tensor_split(x,3)
(tensor([0, 1, 2]), tensor([3, 4]), tensor([5, 6]))
>>> torch.tensor_split(x,(1,6))
(tensor([0]), tensor([1, 2, 3, 4, 5]), tensor([6]))>>> x=torch.arange(14).reshape(2,7)
>>> x
tensor([[ 0,  1,  2,  3,  4,  5,  6],
        [ 7,  8,  9, 10, 11, 12, 13]])
>>> torch.tensor_split(x,3,dim=1)
(tensor([[0, 1, 2],
        [7, 8, 9]]),
 tensor([[ 3,  4],
        [10, 11]]),
 tensor([[ 5,  6],
        [12, 13]]))
>>> torch.tensor_split(x,(1,6),dim=1)
(tensor([[0],
        [7]]),
 tensor([[ 1,  2,  3,  4,  5],
        [ 8,  9, 10, 11, 12]]),
 tensor([[ 6],
        [13]]))
",,,
"
 torch. tile ( input ,  dims )   → ¶","Constructs a tensor by repeating the elements of  input .
The  dims  argument specifies the number of repetitions
in each dimension. If  dims  specifies fewer dimensions than  input  has, then
ones are prepended to  dims  until all dimensions are specified.
For example, if  input  has shape (8, 6, 4, 2) and  dims 
is (2, 2), then  dims  is treated as (1, 1, 2, 2). Analogously, if  input  has fewer dimensions than  dims 
specifies, then  input  is treated as if it were unsqueezed at
dimension zero until it has as many dimensions as  dims  specifies.
For example, if  input  has shape (4, 2) and  dims 
is (3, 3, 2, 2), then  input  is treated as if it had the
shape (1, 1, 4, 2). 
 Note 
 This function is similar to NumPy’s tile function. 
 
 Parameters 
 
 
 Example: 
",">>> x=torch.tensor([1,2,3])
>>> x.tile((2,))
tensor([1, 2, 3, 1, 2, 3])
>>> y=torch.tensor([[1,2],[3,4]])
>>> torch.tile(y,(2,2))
tensor([[1, 2, 1, 2],
        [3, 4, 3, 4],
        [1, 2, 1, 2],
        [3, 4, 3, 4]])
",,,
"
 torch. unbind ( input ,  dim )   → ¶","Removes a tensor dimension. Returns a tuple of all slices along a given dimension, already without it. 
 Parameters 
 
 
 Example: 
",">>> torch.unbind(torch.tensor([[1,2,3],
>>> [4,5,6],
>>> [7,8,9]]))
(tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9]))
",,,
"
 torch. unsqueeze ( input ,  dim )   → ¶","Returns a new tensor with a dimension of size one inserted at the
specified position. The returned tensor shares the same underlying data with this tensor. A  dim  value within the range  [-input.dim() 
can be used. Negative  dim  will correspond to  unsqueeze() 
applied at  dim  =  dim . 
 Parameters 
 
 
 Example: 
",">>> x=torch.tensor([1,2,3,4])
>>> torch.unsqueeze(x,0)
tensor([[ 1,  2,  3,  4]])
>>> torch.unsqueeze(x,1)
tensor([[ 1],
        [ 2],
        [ 3],
        [ 4]])
",,,
"
 torch. vsplit ( input ,  indices_or_sections )   → ¶","Splits  input , a tensor with two or more dimensions, into multiple tensors
vertically according to  indices_or_sections . Each split is a view of
 input . This is equivalent to calling torch.tensor_split(input, indices_or_sections, dim=0)
(the split dimension is 0), except that if  indices_or_sections  is an integer
it must evenly divide the split dimension or a runtime error will be thrown. This function is based on NumPy’s  numpy.vsplit() . 
 Parameters 
 
 
 
 Example:: 
",,,,
"
 torch. where ( condition ,  x ,  y )   → ¶","Return a tensor of elements selected from either  x  or  y , depending on  condition . The operation is defined as: 
 out 
 Note 
 The tensors  
 
 Parameters 
 
 
 Returns 
 A tensor of shape equal to the broadcasted shape of  
 Return type 
 Tensor 
 Example: 
 
 
 
 torch.where(condition)  is identical to
 torch.nonzero(condition, . 
 Note 
 See also  
",">>> x=torch.randn(3,2)
>>> y=torch.ones(3,2)
>>> x
tensor([[-0.4620,  0.3139],
        [ 0.3898, -0.7197],
        [ 0.0478, -0.1657]])
>>> torch.where(x>0,x,y)
tensor([[ 1.0000,  0.3139],
        [ 0.3898,  1.0000],
        [ 0.0478,  1.0000]])
>>> x=torch.randn(2,2,dtype=torch.double)
>>> x
tensor([[ 1.0779,  0.0383],
        [-0.8785, -1.1089]], dtype=torch.float64)
>>> torch.where(x>0,x,0.)
tensor([[1.0779, 0.0383],
        [0.0000, 0.0000]], dtype=torch.float64)
",,,
"
 class torch. Generator ( device ) ¶","Creates and returns a generator object that manages the state of the algorithm which
produces pseudo random numbers. Used as a keyword argument in many  In-place random sampling 
functions. 
 Parameters 
 device 
 Returns 
 An torch.Generator object. 
 Return type 
 Generator 
 Example: 
 
 
 
 Generator.device -> device 
 
 
 Returns the Generator state as a  
 
 
 Returns the initial seed for generating random numbers. 
 
 
 Sets the seed for generating random numbers. Returns a  
 
 
 Gets a non-deterministic random number from std::random_device or the current
time and uses it to seed a Generator. 
 
 
 Sets the Generator state.",">>> g_cpu=torch.Generator()
>>> g_cuda=torch.Generator(device='cuda')
",,,
"
 torch. seed ( ) [source] ¶","Sets the seed for generating random numbers to a non-deterministic
random number. Returns a 64 bit number used to seed the RNG. 
 Return type 
 int 
",,,,
"
 torch. manual_seed ( seed ) [source] ¶","Sets the seed for generating random numbers. Returns a
 torch.Generator  object. 
 Parameters 
 seed 
 Return type 
 Generator 
",,,,
"
 torch. initial_seed ( ) [source] ¶","Returns the initial seed for generating random numbers as a
Python  long . 
 Return type 
 int 
",,,,
"
 torch. get_rng_state ( ) [source] ¶","Returns the random number generator state as a  torch.ByteTensor . 
 Return type 
 Tensor 
",,,,
"
 torch. set_rng_state ( new_state ) [source] ¶","Sets the random number generator state. 
 Parameters 
 new_state 
",,,,
"
 torch. bernoulli ( input ,  * ,  generator ,  out )   → ¶","Draws binary random numbers (0 or 1) from a Bernoulli distribution. The  input  tensor should be a tensor containing probabilities
to be used for drawing the binary random number.
Hence, all values in  input  have to be in the range:
 0 . The  i  element of the output tensor will draw a
value  1  according to the  i  probability value given
in  input . 
 out The returned  out  tensor only has values 0 or 1 and is of the same
shape as  input . out  can have integral  dtype , but  input  must have floating
point  dtype . 
 Parameters 
 input 
 Keyword Arguments 
 
 
 Example: 
",">>> a=torch.empty(3,3).uniform_(0,1)# generate a uniform random matrix with range [0, 1]
>>> a
tensor([[ 0.1737,  0.0950,  0.3609],
        [ 0.7148,  0.0289,  0.2676],
        [ 0.9456,  0.8937,  0.7202]])
>>> torch.bernoulli(a)
tensor([[ 1.,  0.,  0.],
        [ 0.,  0.,  0.],
        [ 1.,  1.,  1.]])>>> a=torch.ones(3,3)# probability of drawing ""1"" is 1
>>> torch.bernoulli(a)
tensor([[ 1.,  1.,  1.],
        [ 1.,  1.,  1.],
        [ 1.,  1.,  1.]])
>>> a=torch.zeros(3,3)# probability of drawing ""1"" is 0
>>> torch.bernoulli(a)
tensor([[ 0.,  0.,  0.],
        [ 0.,  0.,  0.],
        [ 0.,  0.,  0.]])
",,,
"
 torch. multinomial ( input ,  num_samples ,  replacement ,  * ,  generator ,  out )   → ¶","Returns a tensor where each row contains  num_samples  indices sampled
from the multinomial probability distribution located in the corresponding row
of tensor  input . 
 Note 
 The rows of  
 Indices are ordered from left to right according to when each was sampled
(first samples are placed in first column). If  input  is a vector,  out  is a vector of size  num_samples . If  input  is a matrix with  m  rows,  out  is an matrix of shape
 ( . If replacement is  True , samples are drawn with replacement. If not, they are drawn without replacement, which means that when a
sample index is drawn for a row, it cannot be drawn again for that row. 
 Note 
 When drawn without replacement,  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> weights=torch.tensor([0,10,3,0],dtype=torch.float)# create a tensor of weights
>>> torch.multinomial(weights,2)
tensor([1, 2])
>>> torch.multinomial(weights,4)# ERROR!
RuntimeError: invalid argument 2: invalid multinomial distribution (with replacement=False,
not enough non-negative category to sample) at ../aten/src/TH/generic/THTensorRandom.cpp:320
>>> torch.multinomial(weights,4,replacement=True)
tensor([ 2,  1,  1,  1])
",,,
"
 torch. normal ( mean ,  std ,  * ,  generator ,  out )   → ¶","Returns a tensor of random numbers drawn from separate normal distributions
whose mean and standard deviation are given. The  mean  is a tensor with the mean of
each output element’s normal distribution The  std  is a tensor with the standard deviation of
each output element’s normal distribution The shapes of  mean  and  std  don’t need to match, but the
total number of elements in each tensor need to be the same. 
 Note 
 When the shapes do not match, the shape of  
 
 Note 
 When  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
 
 
 
 Similar to the function above, but the means are shared among all drawn
elements. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
 
 
 
 Similar to the function above, but the standard deviations are shared among
all drawn elements. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
 
 
 
 Similar to the function above, but the means and standard deviations are shared
among all drawn elements. The resulting tensor has size given by  size . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.normal(mean=torch.arange(1.,11.),std=torch.arange(1,0,-0.1))
tensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,
          8.0505,   8.1408,   9.0563,  10.0566])
",">>> torch.normal(mean=0.5,std=torch.arange(1.,6.))
tensor([-1.2793, -1.0732, -2.0687,  5.1177, -1.2303])
",">>> torch.normal(mean=torch.arange(1.,6.))
tensor([ 1.1552,  2.6148,  2.6535,  5.8318,  4.2361])
",">>> torch.normal(2,3,size=(1,4))
tensor([[-1.3987, -1.9544,  3.6048,  0.7909]])
"
"
 torch. poisson ( input ,  generator )   → ¶","Returns a tensor of the same size as  input  with each element
sampled from a Poisson distribution with rate parameter given by the corresponding
element in  input  i.e., 
 out input  must be non-negative. 
 Parameters 
 input 
 Keyword Arguments 
 generator 
 Example: 
",">>> rates=torch.rand(4,4)*5# rate parameter between 0 and 5
>>> torch.poisson(rates)
tensor([[9., 1., 3., 5.],
        [8., 6., 6., 0.],
        [0., 4., 5., 3.],
        [2., 1., 4., 2.]])
",,,
"
 Tensor. bernoulli_ ( p ,  * ,  generator )   → ¶","Fills each location of  self  with an independent sample from
 Bernoulli .  self  can have integral
 dtype . p  should either be a scalar or tensor containing probabilities to be
used for drawing the binary random number. If it is a tensor, the  i  element of  self  tensor
will be set to a value sampled from
 Bernoulli . In this case  p  must have
floating point  dtype . See also  bernoulli()  and  torch.bernoulli()",,,,
"
 Tensor. cauchy_ ( median ,  sigma ,  * ,  generator )   → ¶","Fills the tensor with numbers drawn from the Cauchy distribution: 
 f",,,,
"
 Tensor. exponential_ ( lambd ,  * ,  generator )   → ¶","Fills  self  tensor with elements drawn from the exponential distribution: 
 f",,,,
"
 Tensor. geometric_ ( p ,  * ,  generator )   → ¶","Fills  self  tensor with elements drawn from the geometric distribution: 
 f",,,,
"
 Tensor. log_normal_ ( mean ,  std ,  * ,  generator ) ¶","Fills  self  tensor with numbers samples from the log-normal distribution
parameterized by the given mean  μ  and standard deviation
 σ . Note that  mean  and  std  are the mean and
standard deviation of the underlying normal distribution, and not of the
returned distribution: 
 f",,,,
"
 Tensor. normal_ ( mean ,  std ,  * ,  generator )   → ¶","Fills  self  tensor with elements samples from the normal distribution
parameterized by  mean  and  std .",,,,
"
 Tensor. random_ ( from=0 ,  to=None ,  * ,  generator=None )   → ¶","Fills  self  tensor with numbers sampled from the discrete uniform
distribution over  [from, . If not specified, the values are usually
only bounded by  self  tensor’s data type. However, for floating point
types, if unspecified, range will be  [0,  to ensure that every
value is representable. For example,  torch.tensor(1, dtype=torch.double).random_() 
will be uniform in  [0, .",,,,
"
 Tensor. uniform_ ( from=0 ,  to=1 )   → ¶","Fills  self  tensor with numbers sampled from the continuous uniform
distribution: 
 P",,,,
"
 class torch.quasirandom. SobolEngine ( dimension ,  scramble ,  seed ) [source] ¶","The  torch.quasirandom.SobolEngine  is an engine for generating
(scrambled) Sobol sequences. Sobol sequences are an example of low
discrepancy quasi-random sequences. This implementation of an engine for Sobol sequences is capable of
sampling sequences up to a maximum dimension of 21201. It uses direction
numbers from  https://web.maths.unsw.edu.au/~fkuo/sobol/  obtained using the
search criterion D(6) up to the dimension 21201. This is the recommended
choice by the authors. References 
 Art B. Owen. Scrambling Sobol and Niederreiter-Xing points.
Journal of Complexity, 14(4):466-489, December 1998. 
 I. M. Sobol. The distribution of points in a cube and the accurate
evaluation of integrals.
Zh. Vychisl. Mat. i Mat. Phys., 7:784-802, 1967. 
 
 Parameters 
 
 
 Examples: 
 
 
 
 Function to draw a sequence of  
 
 
 Function to draw a sequence of  
 
 
 Function to fast-forward the state of the  
 
 
 Function to reset the ",">>> soboleng=torch.quasirandom.SobolEngine(dimension=5)
>>> soboleng.draw(3)
tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
        [0.7500, 0.2500, 0.2500, 0.2500, 0.7500]])
",,,
"
 torch. save ( obj ,  f ,  pickle_module ,  pickle_protocol ,  _use_new_zipfile_serialization ) [source] ¶","Saves an object to a disk file. See also:  Saving and loading tensors 
 Parameters 
 
 
 
 Note 
 A common PyTorch convention is to save tensors using .pt file extension. 
 
 Note 
 PyTorch preserves storage sharing across serialization. See
 
 
 Note 
 The 1.6 release of PyTorch switched  
 Example 
",,,,
"
 torch. load ( f ,  map_location ,  pickle_module ,  * ,  weights_only ,  ** ) [source] ¶","Loads an object saved with  torch.save()  from a file. torch.load()  uses Python’s unpickling facilities but treats storages,
which underlie tensors, specially. They are first deserialized on the
CPU and are then moved to the device they were saved from. If this fails
(e.g. because the run time system doesn’t have certain devices), an exception
is raised. However, storages can be dynamically remapped to an alternative
set of devices using the  map_location  argument. If  map_location  is a callable, it will be called once for each serialized
storage with two arguments: storage and location. The storage argument
will be the initial deserialization of the storage, residing on the CPU.
Each serialized storage has a location tag associated with it which
identifies the device it was saved from, and this tag is the second
argument passed to  map_location . The builtin location tags are  'cpu' 
for CPU tensors and  'cuda:device_id'  (e.g.  'cuda:2' ) for CUDA tensors.
 map_location  should return either  None  or a storage. If
 map_location  returns a storage, it will be used as the final deserialized
object, already moved to the right device. Otherwise,  torch.load()  will
fall back to the default behavior, as if  map_location  wasn’t specified. If  map_location  is a  torch.device  object or a string containing
a device tag, it indicates the location where all tensors should be loaded. Otherwise, if  map_location  is a dict, it will be used to remap location tags
appearing in the file (keys), to ones that specify where to put the
storages (values). User extensions can register their own location tags and tagging and
deserialization methods using  torch.serialization.register_package() . 
 Parameters 
 
 
 Return type 
 Any 
 
 Warning 
 torch.load() 
 
 Note 
 When you call  
 
 Note 
 By default, we decode byte strings as  
 Example 
",,,,
"
 torch. get_num_threads ( )   → ¶",Returns the number of threads used for parallelizing CPU operations,,,,
"
 torch. set_num_threads ( int ) ¶","Sets the number of threads used for intraop parallelism on CPU. 
 Warning 
 To ensure that the correct number of threads is used, set_num_threads
must be called before running eager, JIT or autograd code. 
",,,,
"
 torch. get_num_interop_threads ( )   → ¶","Returns the number of threads used for inter-op parallelism on CPU
(e.g. in JIT interpreter)",,,,
"
 torch. set_num_interop_threads ( int ) ¶","Sets the number of threads used for interop parallelism
(e.g. in JIT interpreter) on CPU. 
 Warning 
 Can only be called once and before any inter-op parallel work
is started (e.g. JIT execution). 
",,,,
"
 class torch. no_grad [source] ¶","Context-manager that disabled gradient calculation. Disabling gradient calculation is useful for inference, when you are sure
that you will not call  Tensor.backward() . It will reduce memory
consumption for computations that would otherwise have  requires_grad=True . In this mode, the result of every computation will have
 requires_grad=False , even when the inputs have  requires_grad=True . This context manager is thread local; it will not affect computation
in other threads. Also functions as a decorator. (Make sure to instantiate with parenthesis.) 
 Note 
 No-grad is one of several mechanisms that can enable or
disable gradients locally see  
 
 Note 
 This API does not apply to  
 
 Example:: 
 
",,,,
"
 class torch. enable_grad [source] ¶","Context-manager that enables gradient calculation. Enables gradient calculation, if it has been disabled via  no_grad 
or  set_grad_enabled . This context manager is thread local; it will not affect computation
in other threads. Also functions as a decorator. (Make sure to instantiate with parenthesis.) 
 Note 
 enable_grad is one of several mechanisms that can enable or
disable gradients locally see  
 
 Note 
 This API does not apply to  
 
 Example:: 
",,,,
"
 class torch. set_grad_enabled ( mode ) [source] ¶","Context-manager that sets gradient calculation to on or off. set_grad_enabled  will enable or disable grads based on its argument  mode .
It can be used as a context-manager or as a function. This context manager is thread local; it will not affect computation
in other threads. 
 Parameters 
 mode 
 
 Note 
 set_grad_enabled is one of several mechanisms that can enable or
disable gradients locally see  
 
 Note 
 This API does not apply to  
 
 Example:: 
",,,,
"
 torch. is_grad_enabled ( ) ¶",Returns True if grad mode is currently enabled.,,,,
"
 class torch. inference_mode ( mode ) [source] ¶","Context-manager that enables or disables inference mode InferenceMode is a new context manager analogous to  no_grad 
to be used when you are certain your operations will have no interactions
with autograd (e.g., model training). Code run under this mode gets better
performance by disabling view tracking and version counter bumps. Note that
unlike some other mechanisms that locally enable or disable grad,
entering inference_mode also disables to  forward-mode AD . This context manager is thread local; it will not affect computation
in other threads. Also functions as a decorator. (Make sure to instantiate with parenthesis.) 
 Note 
 Inference mode is one of several mechanisms that can enable or
disable gradients locally see  
 
 Parameters 
 mode 
 
 Example:: 
",,,,
"
 torch. is_inference_mode_enabled ( ) ¶",Returns True if inference mode is currently enabled.,,,,
"
 torch. absolute ( input ,  * ,  out )   → ¶",Alias for  torch.abs(),,,,
"
 torch. acos ( input ,  * ,  out )   → ¶","Computes the inverse cosine of each element in  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([ 0.3348, -0.5889,  0.2005, -0.1584])
>>> torch.acos(a)
tensor([ 1.2294,  2.2004,  1.3690,  1.7298])
",,,
"
 torch. arccos ( input ,  * ,  out )   → ¶",Alias for  torch.acos() .,,,,
"
 torch. acosh ( input ,  * ,  out )   → ¶","Returns a new tensor with the inverse hyperbolic cosine of the elements of  input . 
 out 
 Note 
 The domain of the inverse hyperbolic cosine is  
 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4).uniform_(1,2)
>>> a
tensor([ 1.3192, 1.9915, 1.9674, 1.7151 ])
>>> torch.acosh(a)
tensor([ 0.7791, 1.3120, 1.2979, 1.1341 ])
",,,
"
 torch. arccosh ( input ,  * ,  out )   → ¶",Alias for  torch.acosh() .,,,,
"
 torch. add ( input ,  other ,  * ,  alpha ,  out )   → ¶","Adds  other , scaled by  alpha , to  input . 
 out Supports  broadcasting to a common shape ,
 type promotion , and integer, float, and complex inputs. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> a=torch.randn(4)
>>> a
tensor([ 0.0202,  1.0985,  1.3506, -0.6056])
>>> torch.add(a,20)
tensor([ 20.0202,  21.0985,  21.3506,  19.3944])>>> b=torch.randn(4)
>>> b
tensor([-0.9732, -0.3497,  0.6245,  0.4022])
>>> c=torch.randn(4,1)
>>> c
tensor([[ 0.3743],
        [-1.7724],
        [-0.5811],
        [-0.8017]])
>>> torch.add(b,c,alpha=10)
tensor([[  2.7695,   3.3930,   4.3672,   4.1450],
        [-18.6971, -18.0736, -17.0994, -17.3216],
        [ -6.7845,  -6.1610,  -5.1868,  -5.4090],
        [ -8.9902,  -8.3667,  -7.3925,  -7.6147]])
",,,
"
 torch. addcdiv ( input ,  tensor1 ,  tensor2 ,  * ,  value ,  out )   → ¶","Performs the element-wise division of  tensor1  by  tensor2 ,
multiply the result by the scalar  value  and add it to  input . 
 Warning 
 Integer division with addcdiv is no longer supported, and in a future
release addcdiv will perform a true division of tensor1 and tensor2.
The historic addcdiv behavior can be implemented as
(input + value * torch.trunc(tensor1 / tensor2)).to(input.dtype)
for integer inputs and as (input + value * tensor1 / tensor2) for float inputs.
The future addcdiv behavior is just the latter implementation:
(input + value * tensor1 / tensor2), for all dtypes. 
 
 out The shapes of  input ,  tensor1 , and  tensor2  must be
 broadcastable . For inputs of type  FloatTensor  or  DoubleTensor ,  value  must be
a real number, otherwise an integer. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> t=torch.randn(1,3)
>>> t1=torch.randn(3,1)
>>> t2=torch.randn(1,3)
>>> torch.addcdiv(t,t1,t2,value=0.1)
tensor([[-0.2312, -3.6496,  0.1312],
        [-1.0428,  3.4292, -0.1030],
        [-0.5369, -0.9829,  0.0430]])
",,,
"
 torch. addcmul ( input ,  tensor1 ,  tensor2 ,  * ,  value ,  out )   → ¶","Performs the element-wise multiplication of  tensor1 
by  tensor2 , multiply the result by the scalar  value 
and add it to  input . 
 out The shapes of  tensor ,  tensor1 , and  tensor2  must be
 broadcastable . For inputs of type  FloatTensor  or  DoubleTensor ,  value  must be
a real number, otherwise an integer. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> t=torch.randn(1,3)
>>> t1=torch.randn(3,1)
>>> t2=torch.randn(1,3)
>>> torch.addcmul(t,t1,t2,value=0.1)
tensor([[-0.8635, -0.6391,  1.6174],
        [-0.7617, -0.5879,  1.7388],
        [-0.8353, -0.6249,  1.6511]])
",,,
"
 torch. asin ( input ,  * ,  out )   → ¶","Returns a new tensor with the arcsine  of the elements of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([-0.5962,  1.4985, -0.4396,  1.4525])
>>> torch.asin(a)
tensor([-0.6387,     nan, -0.4552,     nan])
",,,
"
 torch. arcsin ( input ,  * ,  out )   → ¶",Alias for  torch.asin() .,,,,
"
 torch. asinh ( input ,  * ,  out )   → ¶","Returns a new tensor with the inverse hyperbolic sine of the elements of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([ 0.1606, -1.4267, -1.0899, -1.0250 ])
>>> torch.asinh(a)
tensor([ 0.1599, -1.1534, -0.9435, -0.8990 ])
",,,
"
 torch. arcsinh ( input ,  * ,  out )   → ¶",Alias for  torch.asinh() .,,,,
"
 torch. atan ( input ,  * ,  out )   → ¶","Returns a new tensor with the arctangent  of the elements of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([ 0.2341,  0.2539, -0.6256, -0.6448])
>>> torch.atan(a)
tensor([ 0.2299,  0.2487, -0.5591, -0.5727])
",,,
"
 torch. arctan ( input ,  * ,  out )   → ¶",Alias for  torch.atan() .,,,,
"
 torch. atanh ( input ,  * ,  out )   → ¶","Returns a new tensor with the inverse hyperbolic tangent of the elements of  input . 
 Note 
 The domain of the inverse hyperbolic tangent is  
 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4).uniform_(-1,1)
>>> a
tensor([ -0.9385, 0.2968, -0.8591, -0.1871 ])
>>> torch.atanh(a)
tensor([ -1.7253, 0.3060, -1.2899, -0.1893 ])
",,,
"
 torch. arctanh ( input ,  * ,  out )   → ¶",Alias for  torch.atanh() .,,,,
"
 torch. atan2 ( input ,  other ,  * ,  out )   → ¶","Element-wise arctangent of  input 
with consideration of the quadrant. Returns a new tensor with the signed angles
in radians between vector  ( 
and vector  ( . (Note that  other , the second
parameter, is the x-coordinate, while  input , the first
parameter, is the y-coordinate.) The shapes of  input  and  other  must be
 broadcastable . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([ 0.9041,  0.0196, -0.3108, -2.4423])
>>> torch.atan2(a,torch.randn(4))
tensor([ 0.9833,  0.0811, -1.9743, -1.4151])
",,,
"
 torch. arctan2 ( input ,  other ,  * ,  out )   → ¶",Alias for  torch.atan2() .,,,,
"
 torch. bitwise_not ( input ,  * ,  out )   → ¶","Computes the bitwise NOT of the given input tensor. The input tensor must be of
integral or Boolean types. For bool tensors, it computes the logical NOT. 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example 
",,,,
"
 torch. bitwise_and ( input ,  other ,  * ,  out )   → ¶","Computes the bitwise AND of  input  and  other . The input tensor must be of
integral or Boolean types. For bool tensors, it computes the logical AND. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
",,,,
"
 torch. bitwise_or ( input ,  other ,  * ,  out )   → ¶","Computes the bitwise OR of  input  and  other . The input tensor must be of
integral or Boolean types. For bool tensors, it computes the logical OR. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
",,,,
"
 torch. bitwise_xor ( input ,  other ,  * ,  out )   → ¶","Computes the bitwise XOR of  input  and  other . The input tensor must be of
integral or Boolean types. For bool tensors, it computes the logical XOR. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
",,,,
"
 torch. bitwise_left_shift ( input ,  other ,  * ,  out )   → ¶","Computes the left arithmetic shift of  input  by  other  bits.
The input tensor must be of integral type. This operator supports
 broadcasting to a common shape  and
 type promotion . The operation applied is: 
 out 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
",,,,
"
 torch. bitwise_right_shift ( input ,  other ,  * ,  out )   → ¶","Computes the right arithmetic shift of  input  by  other  bits.
The input tensor must be of integral type. This operator supports
 broadcasting to a common shape  and
 type promotion . The operation applied is: 
 out 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
",,,,
"
 torch. ceil ( input ,  * ,  out )   → ¶","Returns a new tensor with the ceil of the elements of  input ,
the smallest integer greater than or equal to each element. For integer inputs, follows the array-api convention of returning a
copy of the input tensor. 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([-0.6341, -1.4208, -1.0900,  0.5826])
>>> torch.ceil(a)
tensor([-0., -1., -1.,  1.])
",,,
"
 torch. clamp ( input ,  min ,  max ,  * ,  out )   → ¶","Clamps all elements in  input  into the range  [   min ,  max   ] .
Letting min_value and max_value be  min  and  max , respectively, this returns: 
 y If  min  is  None , there is no lower bound.
Or, if  max  is  None  there is no upper bound. 
 Note 
 If  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([-1.7120,  0.1734, -0.0478, -0.0922])
>>> torch.clamp(a,min=-0.5,max=0.5)
tensor([-0.5000,  0.1734, -0.0478, -0.0922])>>> min=torch.linspace(-1,1,steps=4)
>>> torch.clamp(a,min=min)
tensor([-1.0000,  0.1734,  0.3333,  1.0000])
",,,
"
 torch. min ( input )   → ¶","Returns the minimum value of all elements in the  input  tensor. 
 Warning 
 This function produces deterministic (sub)gradients unlike  
 
 Parameters 
 input 
 Example: 
 
 
 
 Returns a namedtuple  (values,  where  values  is the minimum
value of each row of the  input  tensor in the given dimension
 dim . And  indices  is the index location of each minimum value found
(argmin). If  keepdim  is  True , the output tensors are of the same size as
 input  except in the dimension  dim  where they are of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in
the output tensors having 1 fewer dimension than  input . 
 Note 
 If there are multiple minimal values in a reduced row then
the indices of the first minimal value are returned. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
 
 
 
 See  torch.minimum() .",">>> a=torch.randn(1,3)
>>> a
tensor([[ 0.6750,  1.0857,  1.7197]])
>>> torch.min(a)
tensor(0.6750)
",">>> a=torch.randn(4,4)
>>> a
tensor([[-0.6248,  1.1334, -1.1899, -0.2803],
        [-1.4644, -0.2635, -0.3651,  0.6134],
        [ 0.2457,  0.0384,  1.0128,  0.7015],
        [-0.1153,  2.9849,  2.1458,  0.5788]])
>>> torch.min(a,1)
torch.return_types.min(values=tensor([-1.1899, -1.4644,  0.0384, -0.1153]), indices=tensor([2, 0, 1, 0]))
",,
"
 torch. max ( input )   → ¶","Returns the maximum value of all elements in the  input  tensor. 
 Warning 
 This function produces deterministic (sub)gradients unlike  
 
 Parameters 
 input 
 Example: 
 
 
 
 Returns a namedtuple  (values,  where  values  is the maximum
value of each row of the  input  tensor in the given dimension
 dim . And  indices  is the index location of each maximum value found
(argmax). If  keepdim  is  True , the output tensors are of the same size
as  input  except in the dimension  dim  where they are of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting
in the output tensors having 1 fewer dimension than  input . 
 Note 
 If there are multiple maximal values in a reduced row then
the indices of the first maximal value are returned. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
 
 
 
 See  torch.maximum() .",">>> a=torch.randn(1,3)
>>> a
tensor([[ 0.6763,  0.7445, -2.2369]])
>>> torch.max(a)
tensor(0.7445)
",">>> a=torch.randn(4,4)
>>> a
tensor([[-1.2360, -0.2942, -0.1222,  0.8475],
        [ 1.1949, -1.1127, -2.2379, -0.6702],
        [ 1.5717, -0.9207,  0.1297, -1.8768],
        [-0.6172,  1.0036, -0.6060, -0.2432]])
>>> torch.max(a,1)
torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1]))
",,
"
 torch. clip ( input ,  min ,  max ,  * ,  out )   → ¶",Alias for  torch.clamp() .,,,,
"
 torch. conj_physical ( input ,  * ,  out )   → ¶","Computes the element-wise conjugate of the given  input  tensor.
If  input  has a non-complex dtype, this function just returns  input . 
 Note 
 This performs the conjugate operation regardless of the fact conjugate bit is set or not. 
 
 Warning 
 In the future,  
 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.conj_physical(torch.tensor([-1+1j,-2+2j,3-3j]))
tensor([-1 - 1j, -2 - 2j, 3 + 3j])
",,,
"
 torch. copysign ( input ,  other ,  * ,  out )   → ¶","Create a new floating-point tensor with the magnitude of  input  and the sign of  other , elementwise. 
 out Supports  broadcasting to a common shape ,
and integer and float inputs. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
 
 Note 
 copysign handles signed zeros. If the other argument has a negative zero (-0),
the corresponding output value will be negative. 
",">>> a=torch.randn(5)
>>> a
tensor([-1.2557, -0.0026, -0.5387,  0.4740, -0.9244])
>>> torch.copysign(a,1)
tensor([1.2557, 0.0026, 0.5387, 0.4740, 0.9244])
>>> a=torch.randn(4,4)
>>> a
tensor([[ 0.7079,  0.2778, -1.0249,  0.5719],
        [-0.0059, -0.2600, -0.4475, -1.3948],
        [ 0.3667, -0.9567, -2.5757, -0.1751],
        [ 0.2046, -0.0742,  0.2998, -0.1054]])
>>> b=torch.randn(4)
tensor([ 0.2373,  0.3120,  0.3190, -1.1128])
>>> torch.copysign(a,b)
tensor([[ 0.7079,  0.2778,  1.0249, -0.5719],
        [ 0.0059,  0.2600,  0.4475, -1.3948],
        [ 0.3667,  0.9567,  2.5757, -0.1751],
        [ 0.2046,  0.0742,  0.2998, -0.1054]])
>>> a=torch.tensor([1.])
>>> b=torch.tensor([-0.])
>>> torch.copysign(a,b)
tensor([-1.])
",,,
"
 torch. cos ( input ,  * ,  out )   → ¶","Returns a new tensor with the cosine  of the elements of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([ 1.4309,  1.2706, -0.8562,  0.9796])
>>> torch.cos(a)
tensor([ 0.1395,  0.2957,  0.6553,  0.5574])
",,,
"
 torch. cosh ( input ,  * ,  out )   → ¶","Returns a new tensor with the hyperbolic cosine  of the elements of
 input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
 
 Note 
 When  
",">>> a=torch.randn(4)
>>> a
tensor([ 0.1632,  1.1835, -0.6979, -0.7325])
>>> torch.cosh(a)
tensor([ 1.0133,  1.7860,  1.2536,  1.2805])
",,,
"
 torch. deg2rad ( input ,  * ,  out )   → ¶","Returns a new tensor with each of the elements of  input 
converted from angles in degrees to radians. 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([[180.0,-180.0],[360.0,-360.0],[90.0,-90.0]])
>>> torch.deg2rad(a)
tensor([[ 3.1416, -3.1416],
        [ 6.2832, -6.2832],
        [ 1.5708, -1.5708]])
",,,
"
 torch. div ( input ,  other ,  * ,  rounding_mode ,  out )   → ¶","Divides each element of the input  input  by the corresponding element of
 other . 
 out 
 Note 
 By default, this performs a “true” division like Python 3.
See the  
 Supports  broadcasting to a common shape ,
 type promotion , and integer, float, and complex inputs.
Always promotes integer types to the default scalar type. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> x=torch.tensor([0.3810,1.2774,-0.2972,-0.3719,0.4637])
>>> torch.div(x,0.5)
tensor([ 0.7620,  2.5548, -0.5944, -0.7438,  0.9274])>>> a=torch.tensor([[-0.3711,-1.9353,-0.4605,-0.2917],
... [0.1815,-1.0111,0.9805,-1.5923],
... [0.1062,1.4581,0.7759,-1.2344],
... [-0.1830,-0.0313,1.1908,-1.4757]])
>>> b=torch.tensor([0.8032,0.2930,-0.8113,-0.2308])
>>> torch.div(a,b)
tensor([[-0.4620, -6.6051,  0.5676,  1.2639],
        [ 0.2260, -3.4509, -1.2086,  6.8990],
        [ 0.1322,  4.9764, -0.9564,  5.3484],
        [-0.2278, -0.1068, -1.4678,  6.3938]])>>> torch.div(a,b,rounding_mode='trunc')
tensor([[-0., -6.,  0.,  1.],
        [ 0., -3., -1.,  6.],
        [ 0.,  4., -0.,  5.],
        [-0., -0., -1.,  6.]])>>> torch.div(a,b,rounding_mode='floor')
tensor([[-1., -7.,  0.,  1.],
        [ 0., -4., -2.,  6.],
        [ 0.,  4., -1.,  5.],
        [-1., -1., -2.,  6.]])
",,,
"
 torch. divide ( input ,  other ,  * ,  rounding_mode ,  out )   → ¶",Alias for  torch.div() .,,,,
"
 torch. digamma ( input ,  * ,  out )   → ¶",Alias for  torch.special.digamma() .,,,,
"
 torch. erf ( input ,  * ,  out )   → ¶",Alias for  torch.special.erf() .,,,,
"
 torch. erfc ( input ,  * ,  out )   → ¶",Alias for  torch.special.erfc() .,,,,
"
 torch. erfinv ( input ,  * ,  out )   → ¶",Alias for  torch.special.erfinv() .,,,,
"
 torch. exp ( input ,  * ,  out )   → ¶","Returns a new tensor with the exponential of the elements
of the input tensor  input . 
 y 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.exp(torch.tensor([0,math.log(2.)]))
tensor([ 1.,  2.])
",,,
"
 torch. exp2 ( input ,  * ,  out )   → ¶",Alias for  torch.special.exp2() .,,,,
"
 torch. expm1 ( input ,  * ,  out )   → ¶",Alias for  torch.special.expm1() .,,,,
"
 torch. fake_quantize_per_channel_affine ( input ,  scale ,  zero_point ,  quant_min ,  quant_max )   → ¶","Returns a new tensor with the data in  input  fake quantized per channel using  scale ,
 zero_point ,  quant_min  and  quant_max , across the channel specified by  axis . 
 output 
 Parameters 
 
 
 Returns 
 A newly fake_quantized per channel  
 Return type 
 Tensor 
 Example: 
",">>> x=torch.randn(2,2,2)
>>> x
tensor([[[-0.2525, -0.0466],
         [ 0.3491, -0.2168]],        [[-0.5906,  1.6258],
         [ 0.6444, -0.0542]]])
>>> scales=(torch.randn(2)+1)*0.05
>>> scales
tensor([0.0475, 0.0486])
>>> zero_points=torch.zeros(2).to(torch.int32)
>>> zero_points
tensor([0, 0])
>>> torch.fake_quantize_per_channel_affine(x,scales,zero_points,1,0,255)
tensor([[[0.0000, 0.0000],
         [0.3405, 0.0000]],        [[0.0000, 1.6134],
        [0.6323, 0.0000]]])
",,,
"
 torch. fake_quantize_per_tensor_affine ( input ,  scale ,  zero_point ,  quant_min ,  quant_max )   → ¶","Returns a new tensor with the data in  input  fake quantized using  scale ,
 zero_point ,  quant_min  and  quant_max . 
 output 
 Parameters 
 
 
 Returns 
 A newly fake_quantized  
 Return type 
 Tensor 
 Example: 
",">>> x=torch.randn(4)
>>> x
tensor([ 0.0552,  0.9730,  0.3973, -1.0780])
>>> torch.fake_quantize_per_tensor_affine(x,0.1,0,0,255)
tensor([0.1000, 1.0000, 0.4000, 0.0000])
>>> torch.fake_quantize_per_tensor_affine(x,torch.tensor(0.1),torch.tensor(0),0,255)
tensor([0.6000, 0.4000, 0.0000, 0.0000])
",,,
"
 torch. fix ( input ,  * ,  out )   → ¶",Alias for  torch.trunc(),,,,
"
 torch. trunc ( input ,  * ,  out )   → ¶","Returns a new tensor with the truncated integer values of
the elements of  input . For integer inputs, follows the array-api convention of returning a
copy of the input tensor. 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([ 3.4742,  0.5466, -0.8008, -0.9079])
>>> torch.trunc(a)
tensor([ 3.,  0., -0., -0.])
",,,
"
 torch. float_power ( input ,  exponent ,  * ,  out )   → ¶","Raises  input  to the power of  exponent , elementwise, in double precision.
If neither input is complex returns a  torch.float64  tensor,
and if one or more inputs is complex returns a  torch.complex128  tensor. 
 Note 
 This function always computes in double precision, unlike  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randint(10,(4,))
>>> a
tensor([6, 4, 7, 1])
>>> torch.float_power(a,2)
tensor([36., 16., 49.,  1.], dtype=torch.float64)>>> a=torch.arange(1,5)
>>> a
tensor([ 1,  2,  3,  4])
>>> exp=torch.tensor([2,-3,4,-5])
>>> exp
tensor([ 2, -3,  4, -5])
>>> torch.float_power(a,exp)
tensor([1.0000e+00, 1.2500e-01, 8.1000e+01, 9.7656e-04], dtype=torch.float64)
",,,
"
 torch. floor ( input ,  * ,  out )   → ¶","Returns a new tensor with the floor of the elements of  input ,
the largest integer less than or equal to each element. For integer inputs, follows the array-api convention of returning a
copy of the input tensor. 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([-0.8166,  1.5308, -0.2530, -0.2091])
>>> torch.floor(a)
tensor([-1.,  1., -1., -1.])
",,,
"
 torch. floor_divide ( input ,  other ,  * ,  out )   → ¶","
 Note 
 Before PyTorch 1.13  
 Computes  input  divided by  other , elementwise, and floors
the result. 
 out Supports broadcasting to a common shape, type promotion, and integer and float inputs. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([4.0,3.0])
>>> b=torch.tensor([2.0,2.0])
>>> torch.floor_divide(a,b)
tensor([2.0, 1.0])
>>> torch.floor_divide(a,1.4)
tensor([2.0, 2.0])
",,,
"
 torch. fmod ( input ,  other ,  * ,  out )   → ¶","Applies C++’s  std::fmod  entrywise.
The result has the same sign as the dividend  input  and its absolute value
is less than that of  other . This function may be defined in terms of  torch.div()  as 
 Supports  broadcasting to a common shape ,
 type promotion , and integer and float inputs. 
 Note 
 When the divisor is zero, returns  
 
 Note 
 Complex inputs are not supported. In some cases, it is not mathematically
possible to satisfy the definition of a modulo operation with complex numbers. 
 
 See also 
 torch.remainder() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.fmod(torch.tensor([-3.,-2,-1,1,2,3]),2)
tensor([-1., -0., -1.,  1.,  0.,  1.])
>>> torch.fmod(torch.tensor([1,2,3,4,5]),-1.5)
tensor([1.0000, 0.5000, 0.0000, 1.0000, 0.5000])
",,,
"
 torch. frac ( input ,  * ,  out )   → ¶","Computes the fractional portion of each element in  input . 
 out Example: 
",">>> torch.frac(torch.tensor([1,2.5,-3.2]))
tensor([ 0.0000,  0.5000, -0.2000])
",,,
"
 torch. frexp ( input ,  * ,  out=None) ,  Tensor ) ¶","Decomposes  input  into mantissa and exponent tensors
such that  input . The range of mantissa is the open interval (-1, 1). Supports float inputs. 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> x=torch.arange(9.)
>>> mantissa,exponent=torch.frexp(x)
>>> mantissa
tensor([0.0000, 0.5000, 0.5000, 0.7500, 0.5000, 0.6250, 0.7500, 0.8750, 0.5000])
>>> exponent
tensor([0, 1, 2, 2, 3, 3, 3, 3, 4], dtype=torch.int32)
>>> torch.ldexp(mantissa,exponent)
tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])
",,,
"
 torch. gradient ( input ,  * ,  spacing ,  dim ,  edge_order )   → ¶","Estimates the gradient of a function  g  in
one or more dimensions using the  second-order accurate central differences method . The gradient of  g  is estimated using samples. By default, when  spacing  is not
specified, the samples are entirely described by  input , and the mapping of input coordinates
to an output is the same as the tensor’s mapping of indices to values. For example, for a three-dimensional
 input  the function described is  g , and
 g . When  spacing  is specified, it modifies the relationship between  input  and input coordinates.
This is detailed in the “Keyword Arguments” section below. The gradient is estimated by estimating each partial derivative of  g  independently. This estimation is
accurate if  g  is in  C  (it has at least 3 continuous derivatives), and the estimation can be
improved by providing closer samples. Mathematically, the value at each interior point of a partial derivative
is estimated using  Taylor’s theorem with remainder .
Letting  x  be an interior point and   x  be point neighboring it, the partial gradient at
 f  is estimated using: 
 f where  x  is a number in the interval  [   and using the fact that  f 
we derive : 
 f 
 Note 
 We estimate the gradient of functions in complex domain
 
 The value of each partial derivative at the boundary points is computed differently. See edge_order below. 
 Parameters 
 input 
 Keyword Arguments 
 
 
 Examples: 
",">>> # Estimates the gradient of f(x)=x^2 at points [-2, -1, 2, 4]
>>> coordinates=(torch.tensor([-2.,-1.,1.,4.]),)
>>> values=torch.tensor([4.,1.,1.,16.],)
>>> torch.gradient(values,spacing=coordinates)
(tensor([-3., -2., 2., 5.]),)>>> # Estimates the gradient of the R^2 -> R function whose samples are
>>> # described by the tensor t. Implicit coordinates are [0, 1] for the outermost
>>> # dimension and [0, 1, 2, 3] for the innermost dimension, and function estimates
>>> # partial derivative for both dimensions.
>>> t=torch.tensor([[1,2,4,8],[10,20,40,80]])
>>> torch.gradient(t)
(tensor([[ 9., 18., 36., 72.],
         [ 9., 18., 36., 72.]]),
 tensor([[ 1.0000, 1.5000, 3.0000, 4.0000],
         [10.0000, 15.0000, 30.0000, 40.0000]]))>>> # A scalar value for spacing modifies the relationship between tensor indices
>>> # and input coordinates by multiplying the indices to find the
>>> # coordinates. For example, below the indices of the innermost
>>> # 0, 1, 2, 3 translate to coordinates of [0, 2, 4, 6], and the indices of
>>> # the outermost dimension 0, 1 translate to coordinates of [0, 2].
>>> torch.gradient(t,spacing=2.0)# dim = None (implicitly [0, 1])
(tensor([[ 4.5000, 9.0000, 18.0000, 36.0000],
          [ 4.5000, 9.0000, 18.0000, 36.0000]]),
 tensor([[ 0.5000, 0.7500, 1.5000, 2.0000],
          [ 5.0000, 7.5000, 15.0000, 20.0000]]))
>>> # doubling the spacing between samples halves the estimated partial gradients.>>>
>>> # Estimates only the partial derivative for dimension 1
>>> torch.gradient(t,dim=1)# spacing = None (implicitly 1.)
(tensor([[ 1.0000, 1.5000, 3.0000, 4.0000],
         [10.0000, 15.0000, 30.0000, 40.0000]]),)>>> # When spacing is a list of scalars, the relationship between the tensor
>>> # indices and input coordinates changes based on dimension.
>>> # For example, below, the indices of the innermost dimension 0, 1, 2, 3 translate
>>> # to coordinates of [0, 3, 6, 9], and the indices of the outermost dimension
>>> # 0, 1 translate to coordinates of [0, 2].
>>> torch.gradient(t,spacing=[3.,2.])
(tensor([[ 4.5000, 9.0000, 18.0000, 36.0000],
         [ 4.5000, 9.0000, 18.0000, 36.0000]]),
 tensor([[ 0.3333, 0.5000, 1.0000, 1.3333],
         [ 3.3333, 5.0000, 10.0000, 13.3333]]))>>> # The following example is a replication of the previous one with explicit
>>> # coordinates.
>>> coords=(torch.tensor([0,2]),torch.tensor([0,3,6,9]))
>>> torch.gradient(t,spacing=coords)
(tensor([[ 4.5000, 9.0000, 18.0000, 36.0000],
         [ 4.5000, 9.0000, 18.0000, 36.0000]]),
 tensor([[ 0.3333, 0.5000, 1.0000, 1.3333],
         [ 3.3333, 5.0000, 10.0000, 13.3333]]))
",,,
"
 torch. ldexp ( input ,  other ,  * ,  out )   → ¶","Multiplies  input  by 2**:attr: other . 
 out Typically this function is used to construct floating point numbers by multiplying
mantissas in  input  with integral powers of two created from the exponents
in  other . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.ldexp(torch.tensor([1.]),torch.tensor([1]))
tensor([2.])
>>> torch.ldexp(torch.tensor([1.0]),torch.tensor([1,2,3,4]))
tensor([ 2.,  4.,  8., 16.])
",,,
"
 torch. lerp ( input ,  end ,  weight ,  * ,  out ) ¶","Does a linear interpolation of two tensors  start  (given by  input ) and  end  based
on a scalar or tensor  weight  and returns the resulting  out  tensor. 
 out The shapes of  start  and  end  must be
 broadcastable . If  weight  is a tensor, then
the shapes of  weight ,  start , and  end  must be  broadcastable . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> start=torch.arange(1.,5.)
>>> end=torch.empty(4).fill_(10)
>>> start
tensor([ 1.,  2.,  3.,  4.])
>>> end
tensor([ 10.,  10.,  10.,  10.])
>>> torch.lerp(start,end,0.5)
tensor([ 5.5000,  6.0000,  6.5000,  7.0000])
>>> torch.lerp(start,end,torch.full_like(start,0.5))
tensor([ 5.5000,  6.0000,  6.5000,  7.0000])
",,,
"
 torch. lgamma ( input ,  * ,  out )   → ¶","Computes the natural logarithm of the absolute value of the gamma function on  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.arange(0.5,2,0.5)
>>> torch.lgamma(a)
tensor([ 0.5724,  0.0000, -0.1208])
",,,
"
 torch. log ( input ,  * ,  out )   → ¶","Returns a new tensor with the natural logarithm of the elements
of  input . 
 y 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.rand(5)*5
>>> a
tensor([4.7767, 4.3234, 1.2156, 0.2411, 4.5739])
>>> torch.log(a)
tensor([ 1.5637,  1.4640,  0.1952, -1.4226,  1.5204])
",,,
"
 torch. log10 ( input ,  * ,  out )   → ¶","Returns a new tensor with the logarithm to the base 10 of the elements
of  input . 
 y 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.rand(5)
>>> a
tensor([ 0.5224,  0.9354,  0.7257,  0.1301,  0.2251])>>> torch.log10(a)
tensor([-0.2820, -0.0290, -0.1392, -0.8857, -0.6476])
",,,
"
 torch. log1p ( input ,  * ,  out )   → ¶","Returns a new tensor with the natural logarithm of (1 +  input ). 
 y 
 Note 
 This function is more accurate than  
 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(5)
>>> a
tensor([-1.0090, -0.9923,  1.0249, -0.5372,  0.2492])
>>> torch.log1p(a)
tensor([    nan, -4.8653,  0.7055, -0.7705,  0.2225])
",,,
"
 torch. log2 ( input ,  * ,  out )   → ¶","Returns a new tensor with the logarithm to the base 2 of the elements
of  input . 
 y 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.rand(5)
>>> a
tensor([ 0.8419,  0.8003,  0.9971,  0.5287,  0.0490])>>> torch.log2(a)
tensor([-0.2483, -0.3213, -0.0042, -0.9196, -4.3504])
",,,
"
 torch. logaddexp ( input ,  other ,  * ,  out )   → ¶","Logarithm of the sum of exponentiations of the inputs. Calculates pointwise  log . This function is useful
in statistics where the calculated probabilities of events may be so small as to
exceed the range of normal floating point numbers. In such cases the logarithm
of the calculated probability is stored. This function allows adding
probabilities stored in such a fashion. This op should be disambiguated with  torch.logsumexp()  which performs a
reduction on a single tensor. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.logaddexp(torch.tensor([-1.0]),torch.tensor([-1.0,-2,-3]))
tensor([-0.3069, -0.6867, -0.8731])
>>> torch.logaddexp(torch.tensor([-100.0,-200,-300]),torch.tensor([-1.0,-2,-3]))
tensor([-1., -2., -3.])
>>> torch.logaddexp(torch.tensor([1.0,2000,30000]),torch.tensor([-1.0,-2,-3]))
tensor([1.1269e+00, 2.0000e+03, 3.0000e+04])
",,,
"
 torch. logaddexp2 ( input ,  other ,  * ,  out )   → ¶","Logarithm of the sum of exponentiations of the inputs in base-2. Calculates pointwise  log . See
 torch.logaddexp()  for more details. 
 Parameters 
 
 
 Keyword Arguments 
 out 
",,,,
"
 torch. logical_and ( input ,  other ,  * ,  out )   → ¶","Computes the element-wise logical AND of the given input tensors. Zeros are treated as  False  and nonzeros are
treated as  True . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.logical_and(torch.tensor([True,False,True]),torch.tensor([True,False,False]))
tensor([ True, False, False])
>>> a=torch.tensor([0,1,10,0],dtype=torch.int8)
>>> b=torch.tensor([4,0,1,0],dtype=torch.int8)
>>> torch.logical_and(a,b)
tensor([False, False,  True, False])
>>> torch.logical_and(a.double(),b.double())
tensor([False, False,  True, False])
>>> torch.logical_and(a.double(),b)
tensor([False, False,  True, False])
>>> torch.logical_and(a,b,out=torch.empty(4,dtype=torch.bool))
tensor([False, False,  True, False])
",,,
"
 torch. logical_not ( input ,  * ,  out )   → ¶","Computes the element-wise logical NOT of the given input tensor. If not specified, the output tensor will have the bool
dtype. If the input tensor is not a bool tensor, zeros are treated as  False  and non-zeros are treated as  True . 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.logical_not(torch.tensor([True,False]))
tensor([False,  True])
>>> torch.logical_not(torch.tensor([0,1,-10],dtype=torch.int8))
tensor([ True, False, False])
>>> torch.logical_not(torch.tensor([0.,1.5,-10.],dtype=torch.double))
tensor([ True, False, False])
>>> torch.logical_not(torch.tensor([0.,1.,-10.],dtype=torch.double),out=torch.empty(3,dtype=torch.int16))
tensor([1, 0, 0], dtype=torch.int16)
",,,
"
 torch. logical_or ( input ,  other ,  * ,  out )   → ¶","Computes the element-wise logical OR of the given input tensors. Zeros are treated as  False  and nonzeros are
treated as  True . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.logical_or(torch.tensor([True,False,True]),torch.tensor([True,False,False]))
tensor([ True, False,  True])
>>> a=torch.tensor([0,1,10,0],dtype=torch.int8)
>>> b=torch.tensor([4,0,1,0],dtype=torch.int8)
>>> torch.logical_or(a,b)
tensor([ True,  True,  True, False])
>>> torch.logical_or(a.double(),b.double())
tensor([ True,  True,  True, False])
>>> torch.logical_or(a.double(),b)
tensor([ True,  True,  True, False])
>>> torch.logical_or(a,b,out=torch.empty(4,dtype=torch.bool))
tensor([ True,  True,  True, False])
",,,
"
 torch. logical_xor ( input ,  other ,  * ,  out )   → ¶","Computes the element-wise logical XOR of the given input tensors. Zeros are treated as  False  and nonzeros are
treated as  True . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.logical_xor(torch.tensor([True,False,True]),torch.tensor([True,False,False]))
tensor([False, False,  True])
>>> a=torch.tensor([0,1,10,0],dtype=torch.int8)
>>> b=torch.tensor([4,0,1,0],dtype=torch.int8)
>>> torch.logical_xor(a,b)
tensor([ True,  True, False, False])
>>> torch.logical_xor(a.double(),b.double())
tensor([ True,  True, False, False])
>>> torch.logical_xor(a.double(),b)
tensor([ True,  True, False, False])
>>> torch.logical_xor(a,b,out=torch.empty(4,dtype=torch.bool))
tensor([ True,  True, False, False])
",,,
"
 torch. logit ( input ,  eps ,  * ,  out )   → ¶",Alias for  torch.special.logit() .,,,,
"
 torch. hypot ( input ,  other ,  * ,  out )   → ¶","Given the legs of a right triangle, return its hypotenuse. 
 out The shapes of  input  and  other  must be
 broadcastable . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.hypot(torch.tensor([4.0]),torch.tensor([3.0,4.0,5.0]))
tensor([5.0000, 5.6569, 6.4031])
",,,
"
 torch. i0 ( input ,  * ,  out )   → ¶",Alias for  torch.special.i0() .,,,,
"
 torch. igamma ( input ,  other ,  * ,  out )   → ¶",Alias for  torch.special.gammainc() .,,,,
"
 torch. igammac ( input ,  other ,  * ,  out )   → ¶",Alias for  torch.special.gammaincc() .,,,,
"
 torch. mul ( input ,  other ,  * ,  out )   → ¶","Multiplies  input  by  other . 
 out Supports  broadcasting to a common shape ,
 type promotion , and integer, float, and complex inputs. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Examples: 
",">>> a=torch.randn(3)
>>> a
tensor([ 0.2015, -0.4255,  2.6087])
>>> torch.mul(a,100)
tensor([  20.1494,  -42.5491,  260.8663])>>> b=torch.randn(4,1)
>>> b
tensor([[ 1.1207],
        [-0.3137],
        [ 0.0700],
        [ 0.8378]])
>>> c=torch.randn(1,4)
>>> c
tensor([[ 0.5146,  0.1216, -0.5244,  2.2382]])
>>> torch.mul(b,c)
tensor([[ 0.5767,  0.1363, -0.5877,  2.5083],
        [-0.1614, -0.0382,  0.1645, -0.7021],
        [ 0.0360,  0.0085, -0.0367,  0.1567],
        [ 0.4312,  0.1019, -0.4394,  1.8753]])
",,,
"
 torch. multiply ( input ,  other ,  * ,  out ) ¶",Alias for  torch.mul() .,,,,
"
 torch. mvlgamma ( input ,  p ,  * ,  out )   → ¶",Alias for  torch.special.multigammaln() .,,,,
"
 torch. nan_to_num ( input ,  nan ,  posinf ,  neginf ,  * ,  out )   → ¶","Replaces  NaN , positive infinity, and negative infinity values in  input 
with the values specified by  nan ,  posinf , and  neginf , respectively.
By default,  NaN s are replaced with zero, positive infinity is replaced with the
greatest finite value representable by  input ’s dtype, and negative infinity
is replaced with the least finite value representable by  input ’s dtype. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> x=torch.tensor([float('nan'),float('inf'),-float('inf'),3.14])
>>> torch.nan_to_num(x)
tensor([ 0.0000e+00,  3.4028e+38, -3.4028e+38,  3.1400e+00])
>>> torch.nan_to_num(x,nan=2.0)
tensor([ 2.0000e+00,  3.4028e+38, -3.4028e+38,  3.1400e+00])
>>> torch.nan_to_num(x,nan=2.0,posinf=1.0)
tensor([ 2.0000e+00,  1.0000e+00, -3.4028e+38,  3.1400e+00])
",,,
"
 torch. neg ( input ,  * ,  out )   → ¶","Returns a new tensor with the negative of the elements of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(5)
>>> a
tensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])
>>> torch.neg(a)
tensor([-0.0090,  0.2262,  0.0682,  0.2866, -0.3940])
",,,
"
 torch. negative ( input ,  * ,  out )   → ¶",Alias for  torch.neg(),,,,
"
 torch. nextafter ( input ,  other ,  * ,  out )   → ¶","Return the next floating-point value after  input  towards  other , elementwise. The shapes of  input  and  other  must be
 broadcastable . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> eps=torch.finfo(torch.float32).eps
>>> torch.nextafter(torch.tensor([1.0,2.0]),torch.tensor([2.0,1.0]))==torch.tensor([eps+1,2-eps])
tensor([True, True])
",,,
"
 torch. polygamma ( n ,  input ,  * ,  out )   → ¶",Alias for  torch.special.polygamma() .,,,,
"
 torch. positive ( input )   → ¶","Returns  input .
Throws a runtime error if  input  is a bool tensor. 
 Parameters 
 input 
 Example: 
",">>> t=torch.randn(5)
>>> t
tensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])
>>> torch.positive(t)
tensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])
",,,
"
 torch. pow ( input ,  exponent ,  * ,  out )   → ¶","Takes the power of each element in  input  with  exponent  and
returns a tensor with the result. exponent  can be either a single  float  number or a  Tensor 
with the same number of elements as  input . When  exponent  is a scalar value, the operation applied is: 
 out When  exponent  is a tensor, the operation applied is: 
 out When  exponent  is a tensor, the shapes of  input 
and  exponent  must be  broadcastable . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
 
 
 
 self  is a scalar  float  value, and  exponent  is a tensor.
The returned tensor  out  is of the same shape as  exponent The operation applied is: 
 out 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([ 0.4331,  1.2475,  0.6834, -0.2791])
>>> torch.pow(a,2)
tensor([ 0.1875,  1.5561,  0.4670,  0.0779])
>>> exp=torch.arange(1.,5.)>>> a=torch.arange(1.,5.)
>>> a
tensor([ 1.,  2.,  3.,  4.])
>>> exp
tensor([ 1.,  2.,  3.,  4.])
>>> torch.pow(a,exp)
tensor([   1.,    4.,   27.,  256.])
",">>> exp=torch.arange(1.,5.)
>>> base=2
>>> torch.pow(base,exp)
tensor([  2.,   4.,   8.,  16.])
",,
"
 torch. quantized_batch_norm ( input ,  weight=None ,  bias=None ,  mean ,  var ,  eps ,  output_scale ,  output_zero_point )   → ¶","Applies batch normalization on a 4D (NCHW) quantized tensor. 
 y 
 Parameters 
 
 
 Returns 
 A quantized tensor with batch normalization applied. 
 Return type 
 Tensor 
 Example: 
",">>> qx=torch.quantize_per_tensor(torch.rand(2,2,2,2),1.5,3,torch.quint8)
>>> torch.quantized_batch_norm(qx,torch.ones(2),torch.zeros(2),torch.rand(2),torch.rand(2),0.00001,0.2,2)
tensor([[[[-0.2000, -0.2000],
      [ 1.6000, -0.2000]],     [[-0.4000, -0.4000],
      [-0.4000,  0.6000]]],    [[[-0.2000, -0.2000],
      [-0.2000, -0.2000]],     [[ 0.6000, -0.4000],
      [ 0.6000, -0.4000]]]], size=(2, 2, 2, 2), dtype=torch.quint8,
   quantization_scheme=torch.per_tensor_affine, scale=0.2, zero_point=2)
",,,
"
 torch. quantized_max_pool1d ( input ,  kernel_size ,  stride ,  padding ,  dilation ,  ceil_mode )   → ¶","Applies a 1D max pooling over an input quantized tensor composed of several input planes. 
 Parameters 
 
 
 Returns 
 A quantized tensor with max_pool1d applied. 
 Return type 
 Tensor 
 Example: 
",">>> qx=torch.quantize_per_tensor(torch.rand(2,2),1.5,3,torch.quint8)
>>> torch.quantized_max_pool1d(qx,[2])
tensor([[0.0000],
        [1.5000]], size=(2, 1), dtype=torch.quint8,
    quantization_scheme=torch.per_tensor_affine, scale=1.5, zero_point=3)
",,,
"
 torch. quantized_max_pool2d ( input ,  kernel_size ,  stride ,  padding ,  dilation ,  ceil_mode )   → ¶","Applies a 2D max pooling over an input quantized tensor composed of several input planes. 
 Parameters 
 
 
 Returns 
 A quantized tensor with max_pool2d applied. 
 Return type 
 Tensor 
 Example: 
",">>> qx=torch.quantize_per_tensor(torch.rand(2,2,2,2),1.5,3,torch.quint8)
>>> torch.quantized_max_pool2d(qx,[2,2])
tensor([[[[1.5000]],        [[1.5000]]],        [[[0.0000]],        [[0.0000]]]], size=(2, 2, 1, 1), dtype=torch.quint8,
    quantization_scheme=torch.per_tensor_affine, scale=1.5, zero_point=3)
",,,
"
 torch. rad2deg ( input ,  * ,  out )   → ¶","Returns a new tensor with each of the elements of  input 
converted from angles in radians to degrees. 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([[3.142,-3.142],[6.283,-6.283],[1.570,-1.570]])
>>> torch.rad2deg(a)
tensor([[ 180.0233, -180.0233],
        [ 359.9894, -359.9894],
        [  89.9544,  -89.9544]])
",,,
"
 torch. reciprocal ( input ,  * ,  out )   → ¶","Returns a new tensor with the reciprocal of the elements of  input 
 out 
 Note 
 Unlike NumPy’s reciprocal, torch.reciprocal supports integral inputs. Integral
inputs to reciprocal are automatically  
 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([-0.4595, -2.1219, -1.4314,  0.7298])
>>> torch.reciprocal(a)
tensor([-2.1763, -0.4713, -0.6986,  1.3702])
",,,
"
 torch. remainder ( input ,  other ,  * ,  out )   → ¶","Computes
 Python’s modulus operation 
entrywise.  The result has the same sign as the divisor  other  and its absolute value
is less than that of  other . It may also be defined in terms of  torch.div()  as 
 Supports  broadcasting to a common shape ,
 type promotion , and integer and float inputs. 
 Note 
 Complex inputs are not supported. In some cases, it is not mathematically
possible to satisfy the definition of a modulo operation with complex numbers.
See  
 
 See also 
 torch.fmod() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.remainder(torch.tensor([-3.,-2,-1,1,2,3]),2)
tensor([ 1.,  0.,  1.,  1.,  0.,  1.])
>>> torch.remainder(torch.tensor([1,2,3,4,5]),-1.5)
tensor([ -0.5000, -1.0000,  0.0000, -0.5000, -1.0000 ])
",,,
"
 torch. round ( input ,  * ,  decimals ,  out )   → ¶","Rounds elements of  input  to the nearest integer. For integer inputs, follows the array-api convention of returning a
copy of the input tensor. 
 Note 
 This function implements the “round half to even” to
break ties when a number is equidistant from two
integers (e.g.  
 When the :attr:`decimals` argument is specified the
algorithm used is similar to NumPy’s  
 
 See also 
 torch.ceil() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.round(torch.tensor((4.7,-2.3,9.1,-7.7)))
tensor([ 5.,  -2.,  9., -8.])>>> # Values equidistant from two integers are rounded towards the
>>> #   the nearest even value (zero is treated as even)
>>> torch.round(torch.tensor([-0.5,0.5,1.5,2.5]))
tensor([-0., 0., 2., 2.])>>> # A positive decimals argument rounds to the to that decimal place
>>> torch.round(torch.tensor([0.1234567]),decimals=3)
tensor([0.1230])>>> # A negative decimals argument rounds to the left of the decimal
>>> torch.round(torch.tensor([1200.1234567]),decimals=-3)
tensor([1000.])
",,,
"
 torch. rsqrt ( input ,  * ,  out )   → ¶","Returns a new tensor with the reciprocal of the square-root of each of
the elements of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([-0.0370,  0.2970,  1.5420, -0.9105])
>>> torch.rsqrt(a)
tensor([    nan,  1.8351,  0.8053,     nan])
",,,
"
 torch. sigmoid ( input ,  * ,  out )   → ¶",Alias for  torch.special.expit() .,,,,
"
 torch. sign ( input ,  * ,  out )   → ¶","Returns a new tensor with the signs of the elements of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([0.7,-1.2,0.,2.3])
>>> a
tensor([ 0.7000, -1.2000,  0.0000,  2.3000])
>>> torch.sign(a)
tensor([ 1., -1.,  0.,  1.])
",,,
"
 torch. sgn ( input ,  * ,  out )   → ¶","This function is an extension of torch.sign() to complex tensors.
It computes a new tensor whose elements have
the same angles as the corresponding elements of  input  and
absolute values (i.e. magnitudes) of one for complex tensors and
is equivalent to torch.sign() for non-complex tensors. 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> t=torch.tensor([3+4j,7-24j,0,1+2j])
>>> t.sgn()
tensor([0.6000+0.8000j, 0.2800-0.9600j, 0.0000+0.0000j, 0.4472+0.8944j])
",,,
"
 torch. signbit ( input ,  * ,  out )   → ¶","Tests if each element of  input  has its sign bit set or not. 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
 
 Note 
 signbit handles signed zeros, so negative zero (-0) returns True. 
",">>> a=torch.tensor([0.7,-1.2,0.,2.3])
>>> torch.signbit(a)
tensor([ False, True,  False,  False])
>>> a=torch.tensor([-0.0,0.0])
>>> torch.signbit(a)
tensor([ True,  False])
",,,
"
 torch. sin ( input ,  * ,  out )   → ¶","Returns a new tensor with the sine of the elements of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([-0.5461,  0.1347, -2.7266, -0.2746])
>>> torch.sin(a)
tensor([-0.5194,  0.1343, -0.4032, -0.2711])
",,,
"
 torch. sinc ( input ,  * ,  out )   → ¶",Alias for  torch.special.sinc() .,,,,
"
 torch. sinh ( input ,  * ,  out )   → ¶","Returns a new tensor with the hyperbolic sine of the elements of
 input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
 
 Note 
 When  
",">>> a=torch.randn(4)
>>> a
tensor([ 0.5380, -0.8632, -0.1265,  0.9399])
>>> torch.sinh(a)
tensor([ 0.5644, -0.9744, -0.1268,  1.0845])
",,,
"
 torch. sqrt ( input ,  * ,  out )   → ¶","Returns a new tensor with the square-root of the elements of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([-2.0755,  1.0226,  0.0831,  0.4806])
>>> torch.sqrt(a)
tensor([    nan,  1.0112,  0.2883,  0.6933])
",,,
"
 torch. square ( input ,  * ,  out )   → ¶","Returns a new tensor with the square of the elements of  input . 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([-2.0755,  1.0226,  0.0831,  0.4806])
>>> torch.square(a)
tensor([ 4.3077,  1.0457,  0.0069,  0.2310])
",,,
"
 torch. sub ( input ,  other ,  * ,  alpha ,  out )   → ¶","Subtracts  other , scaled by  alpha , from  input . 
 out Supports  broadcasting to a common shape ,
 type promotion , and integer, float, and complex inputs. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> a=torch.tensor((1,2))
>>> b=torch.tensor((0,1))
>>> torch.sub(a,b,alpha=2)
tensor([1, 0])
",,,
"
 torch. subtract ( input ,  other ,  * ,  alpha ,  out )   → ¶",Alias for  torch.sub() .,,,,
"
 torch. tan ( input ,  * ,  out )   → ¶","Returns a new tensor with the tangent of the elements of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([-1.2027, -1.7687,  0.4412, -1.3856])
>>> torch.tan(a)
tensor([-2.5930,  4.9859,  0.4722, -5.3366])
",,,
"
 torch. tanh ( input ,  * ,  out )   → ¶","Returns a new tensor with the hyperbolic tangent of the elements
of  input . 
 out 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4)
>>> a
tensor([ 0.8986, -0.7279,  1.1745,  0.2611])
>>> torch.tanh(a)
tensor([ 0.7156, -0.6218,  0.8257,  0.2553])
",,,
"
 torch. true_divide ( dividend ,  divisor ,  * ,  out )   → ¶",Alias for  torch.div()  with  rounding_mode=None .,,,,
"
 torch. xlogy ( input ,  other ,  * ,  out )   → ¶",Alias for  torch.special.xlogy() .,,,,
"
 torch. argmax ( input )   → ¶","Returns the indices of the maximum value of all elements in the  input  tensor. This is the second value returned by  torch.max() . See its
documentation for the exact semantics of this method. 
 Note 
 If there are multiple maximal values then the indices of the first maximal value are returned. 
 
 Parameters 
 input 
 Example: 
 
 
 
 Returns the indices of the maximum values of a tensor across a dimension. This is the second value returned by  torch.max() . See its
documentation for the exact semantics of this method. 
 Parameters 
 
 
 Example: 
",">>> a=torch.randn(4,4)
>>> a
tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],
        [-0.7401, -0.8805, -0.3402, -1.1936],
        [ 0.4907, -1.3948, -1.0691, -0.3132],
        [-1.6092,  0.5419, -0.2993,  0.3195]])
>>> torch.argmax(a)
tensor(0)
",">>> a=torch.randn(4,4)
>>> a
tensor([[ 1.3398,  0.2663, -0.2686,  0.2450],
        [-0.7401, -0.8805, -0.3402, -1.1936],
        [ 0.4907, -1.3948, -1.0691, -0.3132],
        [-1.6092,  0.5419, -0.2993,  0.3195]])
>>> torch.argmax(a,dim=1)
tensor([ 0,  2,  0,  1])
",,
"
 torch. argmin ( input ,  dim ,  keepdim )   → ¶","Returns the indices of the minimum value(s) of the flattened tensor or along a dimension This is the second value returned by  torch.min() . See its
documentation for the exact semantics of this method. 
 Note 
 If there are multiple minimal values then the indices of the first minimal value are returned. 
 
 Parameters 
 
 
 Example: 
",">>> a=torch.randn(4,4)
>>> a
tensor([[ 0.1139,  0.2254, -0.1381,  0.3687],
        [ 1.0100, -1.1975, -0.0102, -0.4732],
        [-0.9240,  0.1207, -0.7506, -1.0213],
        [ 1.7809, -1.2960,  0.9384,  0.1438]])
>>> torch.argmin(a)
tensor(13)
>>> torch.argmin(a,dim=1)
tensor([ 2,  1,  3,  1])
>>> torch.argmin(a,dim=1,keepdim=True)
tensor([[2],
        [1],
        [3],
        [1]])
",,,
"
 torch. amax ( input ,  dim ,  keepdim ,  * ,  out )   → ¶","Returns the maximum value of each slice of the  input  tensor in the given
dimension(s)  dim . 
 Note 
 
 
 If  keepdim  is  True , the output tensor is of the same size
as  input  except in the dimension(s)  dim  where it is of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in the
output tensor having 1 (or  len(dim) ) fewer dimension(s). 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4,4)
>>> a
tensor([[ 0.8177,  1.4878, -0.2491,  0.9130],
        [-0.7158,  1.1775,  2.0992,  0.4817],
        [-0.0053,  0.0164, -1.3738, -0.0507],
        [ 1.9700,  1.1106, -1.0318, -1.0816]])
>>> torch.amax(a,1)
tensor([1.4878, 2.0992, 0.0164, 1.9700])
",,,
"
 torch. amin ( input ,  dim ,  keepdim ,  * ,  out )   → ¶","Returns the minimum value of each slice of the  input  tensor in the given
dimension(s)  dim . 
 Note 
 
 
 If  keepdim  is  True , the output tensor is of the same size
as  input  except in the dimension(s)  dim  where it is of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in the
output tensor having 1 (or  len(dim) ) fewer dimension(s). 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4,4)
>>> a
tensor([[ 0.6451, -0.4866,  0.2987, -1.3312],
        [-0.5744,  1.2980,  1.8397, -0.2713],
        [ 0.9128,  0.9214, -1.7268, -0.2995],
        [ 0.9023,  0.4853,  0.9075, -1.6165]])
>>> torch.amin(a,1)
tensor([-1.3312, -0.5744, -1.7268, -1.6165])
",,,
"
 torch. aminmax ( input ,  * ,  dim=None ,  keepdim=False ,  out=None) ,  Tensor ) ¶","Computes the minimum and maximum values of the  input  tensor. 
 Parameters 
 input 
 Keyword Arguments 
 
 
 Returns 
 A named tuple  
 Raises 
 RuntimeError 
 
 Note 
 NaN values are propagated to the output if at least one value is NaN. 
 
 See also 
 torch.amin() 
 Example: 
",">>> torch.aminmax(torch.tensor([1,-3,5]))
torch.return_types.aminmax(
min=tensor(-3),
max=tensor(5))>>> # aminmax propagates NaNs
>>> torch.aminmax(torch.tensor([1,-3,5,torch.nan]))
torch.return_types.aminmax(
min=tensor(nan),
max=tensor(nan))>>> t=torch.arange(10).view(2,5)
>>> t
tensor([[0, 1, 2, 3, 4],
        [5, 6, 7, 8, 9]])
>>> t.aminmax(dim=0,keepdim=True)
torch.return_types.aminmax(
min=tensor([[0, 1, 2, 3, 4]]),
max=tensor([[5, 6, 7, 8, 9]]))
",,,
"
 torch. all ( input )   → ¶","Tests if all elements in  input  evaluate to  True . 
 Note 
 This function matches the behaviour of NumPy in returning
output of dtype  
 Example: 
 
 
 
 For each row of  input  in the given dimension  dim ,
returns  True  if all elements in the row evaluate to  True  and  False  otherwise. If  keepdim  is  True , the output tensor is of the same size
as  input  except in the dimension  dim  where it is of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in
the output tensor having 1 fewer dimension than  input . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.rand(1,2).bool()
>>> a
tensor([[False, True]], dtype=torch.bool)
>>> torch.all(a)
tensor(False, dtype=torch.bool)
>>> a=torch.arange(0,3)
>>> a
tensor([0, 1, 2])
>>> torch.all(a)
tensor(False)
",">>> a=torch.rand(4,2).bool()
>>> a
tensor([[True, True],
        [True, False],
        [True, True],
        [True, True]], dtype=torch.bool)
>>> torch.all(a,dim=1)
tensor([ True, False,  True,  True], dtype=torch.bool)
>>> torch.all(a,dim=0)
tensor([ True, False], dtype=torch.bool)
",,
"
 torch. any ( input )   → ¶","Tests if any element in  input  evaluates to  True . 
 Note 
 This function matches the behaviour of NumPy in returning
output of dtype  
 Example: 
 
 
 
 For each row of  input  in the given dimension  dim ,
returns  True  if any element in the row evaluate to  True  and  False  otherwise. If  keepdim  is  True , the output tensor is of the same size
as  input  except in the dimension  dim  where it is of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in
the output tensor having 1 fewer dimension than  input . 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.rand(1,2).bool()
>>> a
tensor([[False, True]], dtype=torch.bool)
>>> torch.any(a)
tensor(True, dtype=torch.bool)
>>> a=torch.arange(0,3)
>>> a
tensor([0, 1, 2])
>>> torch.any(a)
tensor(True)
",">>> a=torch.randn(4,2)<0
>>> a
tensor([[ True,  True],
        [False,  True],
        [ True,  True],
        [False, False]])
>>> torch.any(a,1)
tensor([ True,  True,  True, False])
>>> torch.any(a,0)
tensor([True, True])
",,
"
 torch. dist ( input ,  other ,  p )   → ¶","Returns the p-norm of ( input  -  other ) The shapes of  input  and  other  must be
 broadcastable . 
 Parameters 
 
 
 Example: 
",">>> x=torch.randn(4)
>>> x
tensor([-1.5393, -0.8675,  0.5916,  1.6321])
>>> y=torch.randn(4)
>>> y
tensor([ 0.0967, -1.0511,  0.6295,  0.8360])
>>> torch.dist(x,y,3.5)
tensor(1.6727)
>>> torch.dist(x,y,3)
tensor(1.6973)
>>> torch.dist(x,y,0)
tensor(4.)
>>> torch.dist(x,y,1)
tensor(2.6537)
",,,
"
 torch. logsumexp ( input ,  dim ,  keepdim ,  * ,  out ) ¶","Returns the log of summed exponentials of each row of the  input 
tensor in the given dimension  dim . The computation is numerically
stabilized. For summation index  j  given by  dim  and other indices  i , the result is 
 
 If  keepdim  is  True , the output tensor is of the same size
as  input  except in the dimension(s)  dim  where it is of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in the
output tensor having 1 (or  len(dim) ) fewer dimension(s). 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(3,3)
>>> torch.logsumexp(a,1)
tensor([1.4907, 1.0593, 1.5696])
>>> torch.dist(torch.logsumexp(a,1),torch.log(torch.sum(torch.exp(a),1)))
tensor(1.6859e-07)
",,,
"
 torch. mean ( input ,  * ,  dtype )   → ¶","Returns the mean value of all elements in the  input  tensor. 
 Parameters 
 input 
 Keyword Arguments 
 dtype 
 Example: 
 
 
 
 Returns the mean value of each row of the  input  tensor in the given
dimension  dim . If  dim  is a list of dimensions,
reduce over all of them. If  keepdim  is  True , the output tensor is of the same size
as  input  except in the dimension(s)  dim  where it is of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in the
output tensor having 1 (or  len(dim) ) fewer dimension(s). 
 Parameters 
 
 
 Keyword Arguments 
 
 
 
 See also 
 torch.nanmean() 
 Example: 
",">>> a=torch.randn(1,3)
>>> a
tensor([[ 0.2294, -0.5481,  1.3288]])
>>> torch.mean(a)
tensor(0.3367)
",">>> a=torch.randn(4,4)
>>> a
tensor([[-0.3841,  0.6320,  0.4254, -0.7384],
        [-0.9644,  1.0131, -0.6549, -1.4279],
        [-0.2951, -1.3350, -0.7694,  0.5600],
        [ 1.0842, -0.9580,  0.3623,  0.2343]])
>>> torch.mean(a,1)
tensor([-0.0163, -0.5085, -0.4599,  0.1807])
>>> torch.mean(a,1,True)
tensor([[-0.0163],
        [-0.5085],
        [-0.4599],
        [ 0.1807]])
",,
"
 torch. nanmean ( input ,  dim ,  keepdim ,  * ,  dtype ,  out )   → ¶","Computes the mean of all  non-NaN  elements along the specified dimensions. This function is identical to  torch.mean()  when there are no  NaN  values
in the  input  tensor. In the presence of  NaN ,  torch.mean()  will
propagate the  NaN  to the output whereas  torch.nanmean()  will ignore the
 NaN  values ( torch.nanmean(a)  is equivalent to  torch.mean(a[~a.isnan()]) ). If  keepdim  is  True , the output tensor is of the same size
as  input  except in the dimension(s)  dim  where it is of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in the
output tensor having 1 (or  len(dim) ) fewer dimension(s). 
 Parameters 
 
 
 Keyword Arguments 
 
 
 
 See also 
 torch.mean() 
 Example: 
",">>> x=torch.tensor([[torch.nan,1,2],[1,2,3]])
>>> x.mean()
tensor(nan)
>>> x.nanmean()
tensor(1.8000)
>>> x.mean(dim=0)
tensor([   nan, 1.5000, 2.5000])
>>> x.nanmean(dim=0)
tensor([1.0000, 1.5000, 2.5000])# If all elements in the reduced dimensions are NaN then the result is NaN
>>> torch.tensor([torch.nan]).nanmean()
tensor(nan)
",,,
"
 torch. median ( input )   → ¶","Returns the median of the values in  input . 
 Note 
 The median is not unique for  
 
 Warning 
 This function produces deterministic (sub)gradients unlike  
 
 Parameters 
 input 
 Example: 
 
 
 
 Returns a namedtuple  (values,  where  values  contains the median of each row of  input 
in the dimension  dim , and  indices  contains the index of the median values found in the dimension  dim . By default,  dim  is the last dimension of the  input  tensor. If  keepdim  is  True , the output tensors are of the same size
as  input  except in the dimension  dim  where they are of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in
the outputs tensor having 1 fewer dimension than  input . 
 Note 
 The median is not unique for  
 
 Warning 
 indices 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(1,3)
>>> a
tensor([[ 1.5219, -1.5212,  0.2202]])
>>> torch.median(a)
tensor(0.2202)
",">>> a=torch.randn(4,5)
>>> a
tensor([[ 0.2505, -0.3982, -0.9948,  0.3518, -1.3131],
        [ 0.3180, -0.6993,  1.0436,  0.0438,  0.2270],
        [-0.2751,  0.7303,  0.2192,  0.3321,  0.2488],
        [ 1.0778, -1.9510,  0.7048,  0.4742, -0.7125]])
>>> torch.median(a,1)
torch.return_types.median(values=tensor([-0.3982,  0.2270,  0.2488,  0.4742]), indices=tensor([1, 4, 4, 3]))
",,
"
 torch. nanmedian ( input )   → ¶","Returns the median of the values in  input , ignoring  NaN  values. This function is identical to  torch.median()  when there are no  NaN  values in  input .
When  input  has one or more  NaN  values,  torch.median()  will always return  NaN ,
while this function will return the median of the non- NaN  elements in  input .
If all the elements in  input  are  NaN  it will also return  NaN . 
 Parameters 
 input 
 Example: 
 
 
 
 Returns a namedtuple  (values,  where  values  contains the median of each row of  input 
in the dimension  dim , ignoring  NaN  values, and  indices  contains the index of the median values
found in the dimension  dim . This function is identical to  torch.median()  when there are no  NaN  values in a reduced row. When a reduced row has
one or more  NaN  values,  torch.median()  will always reduce it to  NaN , while this function will reduce it to the
median of the non- NaN  elements. If all the elements in a reduced row are  NaN  then it will be reduced to  NaN , too. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([1,float('nan'),3,2])
>>> a.median()
tensor(nan)
>>> a.nanmedian()
tensor(2.)
",">>> a=torch.tensor([[2,3,1],[float('nan'),1,float('nan')]])
>>> a
tensor([[2., 3., 1.],
        [nan, 1., nan]])
>>> a.median(0)
torch.return_types.median(values=tensor([nan, 1., nan]), indices=tensor([1, 1, 1]))
>>> a.nanmedian(0)
torch.return_types.nanmedian(values=tensor([2., 1., 1.]), indices=tensor([0, 1, 0]))
",,
"
 torch. mode ( input ,  dim ,  keepdim ,  * ,  out ) ¶","Returns a namedtuple  (values,  where  values  is the mode
value of each row of the  input  tensor in the given dimension
 dim , i.e. a value which appears most often
in that row, and  indices  is the index location of each mode value found. By default,  dim  is the last dimension of the  input  tensor. If  keepdim  is  True , the output tensors are of the same size as
 input  except in the dimension  dim  where they are of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting
in the output tensors having 1 fewer dimension than  input . 
 Note 
 This function is not defined for  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randint(10,(5,))
>>> a
tensor([6, 5, 1, 0, 2])
>>> b=a+(torch.randn(50,1)*5).long()
>>> torch.mode(b,0)
torch.return_types.mode(values=tensor([6, 5, 1, 0, 2]), indices=tensor([2, 2, 2, 2, 2]))
",,,
"
 torch. norm ( input ,  p ,  dim ,  keepdim ,  out ,  dtype ) [source] ¶","Returns the matrix norm or vector norm of a given tensor. 
 Warning 
 torch.norm is deprecated and may be removed in a future PyTorch release.
Its documentation and behavior may be incorrect, and it is no longer
actively maintained. 
 Use  
 
 Parameters 
 
 
 
 Note 
 Even though  
 Example: 
",">>> importtorch
>>> a=torch.arange(9,dtype=torch.float)-4
>>> b=a.reshape((3,3))
>>> torch.norm(a)
tensor(7.7460)
>>> torch.norm(b)
tensor(7.7460)
>>> torch.norm(a,float('inf'))
tensor(4.)
>>> torch.norm(b,float('inf'))
tensor(4.)
>>> c=torch.tensor([[1,2,3],[-1,1,4]],dtype=torch.float)
>>> torch.norm(c,dim=0)
tensor([1.4142, 2.2361, 5.0000])
>>> torch.norm(c,dim=1)
tensor([3.7417, 4.2426])
>>> torch.norm(c,p=1,dim=1)
tensor([6., 6.])
>>> d=torch.arange(8,dtype=torch.float).reshape(2,2,2)
>>> torch.norm(d,dim=(1,2))
tensor([ 3.7417, 11.2250])
>>> torch.norm(d[0,:,:]),torch.norm(d[1,:,:])
(tensor(3.7417), tensor(11.2250))
",,,
"
 torch. nansum ( input ,  * ,  dtype )   → ¶","Returns the sum of all elements, treating Not a Numbers (NaNs) as zero. 
 Parameters 
 input 
 Keyword Arguments 
 dtype 
 Example: 
 
 
 
 Returns the sum of each row of the  input  tensor in the given
dimension  dim , treating Not a Numbers (NaNs) as zero.
If  dim  is a list of dimensions, reduce over all of them. If  keepdim  is  True , the output tensor is of the same size
as  input  except in the dimension(s)  dim  where it is of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in the
output tensor having 1 (or  len(dim) ) fewer dimension(s). 
 Parameters 
 
 
 Keyword Arguments 
 dtype 
 Example: 
",">>> a=torch.tensor([1.,2.,float('nan'),4.])
>>> torch.nansum(a)
tensor(7.)
",">>> torch.nansum(torch.tensor([1.,float(""nan"")]))
1.0
>>> a=torch.tensor([[1,2],[3.,float(""nan"")]])
>>> torch.nansum(a)
tensor(6.)
>>> torch.nansum(a,dim=0)
tensor([4., 2.])
>>> torch.nansum(a,dim=1)
tensor([3., 3.])
",,
"
 torch. prod ( input ,  * ,  dtype )   → ¶","Returns the product of all elements in the  input  tensor. 
 Parameters 
 input 
 Keyword Arguments 
 dtype 
 Example: 
 
 
 
 Returns the product of each row of the  input  tensor in the given
dimension  dim . If  keepdim  is  True , the output tensor is of the same size
as  input  except in the dimension  dim  where it is of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in
the output tensor having 1 fewer dimension than  input . 
 Parameters 
 
 
 Keyword Arguments 
 dtype 
 Example: 
",">>> a=torch.randn(1,3)
>>> a
tensor([[-0.8020,  0.5428, -1.5854]])
>>> torch.prod(a)
tensor(0.6902)
",">>> a=torch.randn(4,2)
>>> a
tensor([[ 0.5261, -0.3837],
        [ 1.1857, -0.2498],
        [-1.1646,  0.0705],
        [ 1.1131, -1.0629]])
>>> torch.prod(a,1)
tensor([-0.2018, -0.2962, -0.0821, -1.1831])
",,
"
 torch. quantile ( input ,  q ,  dim ,  keepdim ,  * ,  interpolation ,  out )   → ¶","Computes the q-th quantiles of each row of the  input  tensor along the dimension  dim . To compute the quantile, we map q in [0, 1] to the range of indices [0, n] to find the location
of the quantile in the sorted input. If the quantile lies between two data points  a  with
indices  i  and  j  in the sorted order, result is computed according to the given
 interpolation  method as follows: 
 linear 
 lower 
 higher 
 nearest 
 midpoint 
 If  q  is a 1D tensor, the first dimension of the output represents the quantiles and has size
equal to the size of  q , the remaining dimensions are what remains from the reduction. 
 Note 
 By default  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> a=torch.randn(2,3)
>>> a
tensor([[ 0.0795, -1.2117,  0.9765],
        [ 1.1707,  0.6706,  0.4884]])
>>> q=torch.tensor([0.25,0.5,0.75])
>>> torch.quantile(a,q,dim=1,keepdim=True)
tensor([[[-0.5661],
        [ 0.5795]],        [[ 0.0795],
        [ 0.6706]],        [[ 0.5280],
        [ 0.9206]]])
>>> torch.quantile(a,q,dim=1,keepdim=True).shape
torch.Size([3, 2, 1])
>>> a=torch.arange(4.)
>>> a
tensor([0., 1., 2., 3.])
>>> torch.quantile(a,0.6,interpolation='linear')
tensor(1.8000)
>>> torch.quantile(a,0.6,interpolation='lower')
tensor(1.)
>>> torch.quantile(a,0.6,interpolation='higher')
tensor(2.)
>>> torch.quantile(a,0.6,interpolation='midpoint')
tensor(1.5000)
>>> torch.quantile(a,0.6,interpolation='nearest')
tensor(2.)
>>> torch.quantile(a,0.4,interpolation='nearest')
tensor(1.)
",,,
"
 torch. nanquantile ( input ,  q ,  dim ,  keepdim ,  * ,  interpolation ,  out )   → ¶","This is a variant of  torch.quantile()  that “ignores”  NaN  values,
computing the quantiles  q  as if  NaN  values in  input  did
not exist. If all values in a reduced row are  NaN  then the quantiles for
that reduction will be  NaN . See the documentation for  torch.quantile() . 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> t=torch.tensor([float('nan'),1,2])
>>> t.quantile(0.5)
tensor(nan)
>>> t.nanquantile(0.5)
tensor(1.5000)
>>> t=torch.tensor([[float('nan'),float('nan')],[1,2]])
>>> t
tensor([[nan, nan],
        [1., 2.]])
>>> t.nanquantile(0.5,dim=0)
tensor([1., 2.])
>>> t.nanquantile(0.5,dim=1)
tensor([   nan, 1.5000])
",,,
"
 torch. std ( input ,  dim ,  unbiased ,  keepdim ,  * ,  out )   → ¶","If  unbiased  is  True , Bessel’s correction will be used.
Otherwise, the sample deviation is calculated, without any correction. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 
 
 
 Calculates the standard deviation of all elements in the  input  tensor. If  unbiased  is  True , Bessel’s correction will be used.
Otherwise, the sample deviation is calculated, without any correction. 
 Parameters 
 
 
 Example: 
",">>> a=torch.tensor([[-0.8166,-1.3802,-0.3560]])
>>> torch.std(a,unbiased=False)
tensor(0.4188)
",,,
"
 torch. std_mean ( input ,  dim ,  unbiased ,  keepdim ,  * ,  out ) ¶","If  unbiased  is  True , Bessel’s correction will be used to calculate
the standard deviation. Otherwise, the sample deviation is calculated, without
any correction. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A tuple (std, mean) containing the standard deviation and mean. 
 
 
 
 Calculates the standard deviation and mean of all elements in the  input 
tensor. If  unbiased  is  True , Bessel’s correction will be used.
Otherwise, the sample deviation is calculated, without any correction. 
 Parameters 
 
 
 Returns 
 A tuple (std, mean) containing the standard deviation and mean. 
 Example: 
",">>> a=torch.tensor([[-0.8166,-1.3802,-0.3560]])
>>> torch.std_mean(a,unbiased=False)
(tensor(0.4188), tensor(-0.8509))
",,,
"
 torch. sum ( input ,  * ,  dtype )   → ¶","Returns the sum of all elements in the  input  tensor. 
 Parameters 
 input 
 Keyword Arguments 
 dtype 
 Example: 
 
 
 
 Returns the sum of each row of the  input  tensor in the given
dimension  dim . If  dim  is a list of dimensions,
reduce over all of them. If  keepdim  is  True , the output tensor is of the same size
as  input  except in the dimension(s)  dim  where it is of size 1.
Otherwise,  dim  is squeezed (see  torch.squeeze() ), resulting in the
output tensor having 1 (or  len(dim) ) fewer dimension(s). 
 Parameters 
 
 
 Keyword Arguments 
 dtype 
 Example: 
",">>> a=torch.randn(1,3)
>>> a
tensor([[ 0.1133, -0.9567,  0.2958]])
>>> torch.sum(a)
tensor(-0.5475)
",">>> a=torch.randn(4,4)
>>> a
tensor([[ 0.0569, -0.2475,  0.0737, -0.3429],
        [-0.2993,  0.9138,  0.9337, -1.6864],
        [ 0.1132,  0.7892, -0.1003,  0.5688],
        [ 0.3637, -0.9906, -0.4752, -1.5197]])
>>> torch.sum(a,1)
tensor([-0.4598, -0.1381,  1.3708, -2.6217])
>>> b=torch.arange(4*5*6).view(4,5,6)
>>> torch.sum(b,(2,1))
tensor([  435.,  1335.,  2235.,  3135.])
",,
"
 torch. unique ( input ,  sorted ,  return_inverse ,  return_counts ,  dim )   → ¶","Returns the unique elements of the input tensor. 
 Note 
 This function is different from  
 
 Note 
 Currently in the CUDA implementation and the CPU implementation when dim is specified,
 
 
 Parameters 
 
 
 Returns 
 A tensor or a tuple of tensors containing 
 Return type 
 ( 
 Example: 
",">>> output=torch.unique(torch.tensor([1,3,2,3],dtype=torch.long))
>>> output
tensor([1, 2, 3])>>> output,inverse_indices=torch.unique(
... torch.tensor([1,3,2,3],dtype=torch.long),sorted=True,return_inverse=True)
>>> output
tensor([1, 2, 3])
>>> inverse_indices
tensor([0, 2, 1, 2])>>> output,inverse_indices=torch.unique(
... torch.tensor([[1,3],[2,3]],dtype=torch.long),sorted=True,return_inverse=True)
>>> output
tensor([1, 2, 3])
>>> inverse_indices
tensor([[0, 2],
        [1, 2]])
",,,
"
 torch. unique_consecutive ( * ,  ** ) ¶","Eliminates all but the first element from every consecutive group of equivalent elements. 
 Note 
 This function is different from  
 
 Parameters 
 
 
 Returns 
 A tensor or a tuple of tensors containing 
 Return type 
 ( 
 Example: 
",">>> x=torch.tensor([1,1,2,2,3,1,1,2])
>>> output=torch.unique_consecutive(x)
>>> output
tensor([1, 2, 3, 1, 2])>>> output,inverse_indices=torch.unique_consecutive(x,return_inverse=True)
>>> output
tensor([1, 2, 3, 1, 2])
>>> inverse_indices
tensor([0, 0, 1, 1, 2, 3, 3, 4])>>> output,counts=torch.unique_consecutive(x,return_counts=True)
>>> output
tensor([1, 2, 3, 1, 2])
>>> counts
tensor([2, 2, 1, 2, 1])
",,,
"
 torch. var ( input ,  dim ,  unbiased ,  keepdim ,  * ,  out )   → ¶","If  unbiased  is  True , Bessel’s correction will be used.
Otherwise, the sample variance is calculated, without any correction. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 
 
 
 Calculates the variance of all elements in the  input  tensor. If  unbiased  is  True , Bessel’s correction will be used.
Otherwise, the sample deviation is calculated, without any correction. 
 Parameters 
 
 
 Example: 
",">>> a=torch.tensor([[-0.8166,-1.3802,-0.3560]])
>>> torch.var(a,unbiased=False)
tensor(0.1754)
",,,
"
 torch. var_mean ( input ,  dim ,  unbiased ,  keepdim ,  * ,  out ) ¶","If  unbiased  is  True , Bessel’s correction will be used to calculate
the variance. Otherwise, the sample variance is calculated, without any
correction. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A tuple (var, mean) containing the variance and mean. 
 
 
 
 Calculates the variance and mean of all elements in the  input 
tensor. If  unbiased  is  True , Bessel’s correction will be used.
Otherwise, the sample deviation is calculated, without any correction. 
 Parameters 
 
 
 Returns 
 A tuple (var, mean) containing the variance and mean. 
 Example: 
",">>> a=torch.tensor([[-0.8166,-1.3802,-0.3560]])
>>> torch.var_mean(a,unbiased=False)
(tensor(0.1754), tensor(-0.8509))
",,,
"
 torch. count_nonzero ( input ,  dim )   → ¶","Counts the number of non-zero values in the tensor  input  along the given  dim .
If no dim is specified then all non-zeros in the tensor are counted. 
 Parameters 
 
 
 Example: 
",">>> x=torch.zeros(3,3)
>>> x[torch.randn(3,3)>0.5]=1
>>> x
tensor([[0., 1., 1.],
        [0., 0., 0.],
        [0., 0., 1.]])
>>> torch.count_nonzero(x)
tensor(3)
>>> torch.count_nonzero(x,dim=0)
tensor([0, 1, 2])
",,,
"
 torch. allclose ( input ,  other ,  rtol ,  atol ,  equal_nan )   → ¶","This function checks if all  input  and  other  satisfy the condition: 
 ∣ elementwise, for all elements of  input  and  other . The behaviour of this function is analogous to
 numpy.allclose 
 Parameters 
 
 
 Example: 
",">>> torch.allclose(torch.tensor([10000.,1e-07]),torch.tensor([10000.1,1e-08]))
False
>>> torch.allclose(torch.tensor([10000.,1e-08]),torch.tensor([10000.1,1e-09]))
True
>>> torch.allclose(torch.tensor([1.0,float('nan')]),torch.tensor([1.0,float('nan')]))
False
>>> torch.allclose(torch.tensor([1.0,float('nan')]),torch.tensor([1.0,float('nan')]),equal_nan=True)
True
",,,
"
 torch. argsort ( input ,  dim ,  descending ,  stable )   → ¶","Returns the indices that sort a tensor along a given dimension in ascending
order by value. This is the second value returned by  torch.sort() .  See its documentation
for the exact semantics of this method. If  stable  is  True  then the sorting routine becomes stable, preserving
the order of equivalent elements. If  False , the relative order of values
which compare equal is not guaranteed.  True  is slower. 
 Parameters 
 
 
 Example: 
",">>> a=torch.randn(4,4)
>>> a
tensor([[ 0.0785,  1.5267, -0.8521,  0.4065],
        [ 0.1598,  0.0788, -0.0745, -1.2700],
        [ 1.2208,  1.0722, -0.7064,  1.2564],
        [ 0.0669, -0.2318, -0.8229, -0.9280]])>>> torch.argsort(a,dim=1)
tensor([[2, 0, 3, 1],
        [3, 2, 1, 0],
        [2, 1, 0, 3],
        [3, 2, 1, 0]])
",,,
"
 torch. eq ( input ,  other ,  * ,  out )   → ¶","Computes element-wise equality The second argument can be a number or a tensor whose shape is
 broadcastable  with the first argument. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A boolean tensor that is True where  
 Example: 
",">>> torch.eq(torch.tensor([[1,2],[3,4]]),torch.tensor([[1,1],[4,4]]))
tensor([[ True, False],
        [False, True]])
",,,
"
 torch. equal ( input ,  other )   → ¶","True  if two tensors have the same size and elements,  False  otherwise. Example: 
",">>> torch.equal(torch.tensor([1,2]),torch.tensor([1,2]))
True
",,,
"
 torch. ge ( input ,  other ,  * ,  out )   → ¶","Computes  input  element-wise. The second argument can be a number or a tensor whose shape is
 broadcastable  with the first argument. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A boolean tensor that is True where  
 Example: 
",">>> torch.ge(torch.tensor([[1,2],[3,4]]),torch.tensor([[1,1],[4,4]]))
tensor([[True, True], [False, True]])
",,,
"
 torch. greater_equal ( input ,  other ,  * ,  out )   → ¶",Alias for  torch.ge() .,,,,
"
 torch. gt ( input ,  other ,  * ,  out )   → ¶","Computes  input  element-wise. The second argument can be a number or a tensor whose shape is
 broadcastable  with the first argument. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A boolean tensor that is True where  
 Example: 
",">>> torch.gt(torch.tensor([[1,2],[3,4]]),torch.tensor([[1,1],[4,4]]))
tensor([[False, True], [False, False]])
",,,
"
 torch. greater ( input ,  other ,  * ,  out )   → ¶",Alias for  torch.gt() .,,,,
"
 torch. isclose ( input ,  other ,  rtol ,  atol ,  equal_nan )   → ¶","Returns a new tensor with boolean elements representing if each element of
 input  is “close” to the corresponding element of  other .
Closeness is defined as: 
 ∣ where  input  and  other  are finite. Where  input 
and/or  other  are nonfinite they are close if and only if
they are equal, with NaNs being considered equal to each other when
 equal_nan  is True. 
 Parameters 
 
 
 Examples: 
",">>> torch.isclose(torch.tensor((1.,2,3)),torch.tensor((1+1e-10,3,4)))
tensor([ True, False, False])
>>> torch.isclose(torch.tensor((float('inf'),4)),torch.tensor((float('inf'),6)),rtol=.5)
tensor([True, True])
",,,
"
 torch. isfinite ( input )   → ¶","Returns a new tensor with boolean elements representing if each element is  finite  or not. Real values are finite when they are not NaN, negative infinity, or infinity.
Complex values are finite when both their real and imaginary parts are finite. 
 Parameters 
 input 
 Returns 
 A boolean tensor that is True where  
 Example: 
",">>> torch.isfinite(torch.tensor([1,float('inf'),2,float('-inf'),float('nan')]))
tensor([True,  False,  True,  False,  False])
",,,
"
 torch. isin ( elements ,  test_elements ,  * ,  assume_unique ,  invert )   → ¶","Tests if each element of  elements  is in  test_elements . Returns
a boolean tensor of the same shape as  elements  that is True for elements
in  test_elements  and False otherwise. 
 Note 
 One of  
 
 Parameters 
 
 
 Returns 
 A boolean tensor of the same shape as  
 Example 
",,,,
"
 torch. isinf ( input )   → ¶","Tests if each element of  input  is infinite
(positive or negative infinity) or not. 
 Note 
 Complex values are infinite when their real or imaginary part is
infinite. 
 
 Parameters 
 input 
 Returns 
 A boolean tensor that is True where  
 Example: 
",">>> torch.isinf(torch.tensor([1,float('inf'),2,float('-inf'),float('nan')]))
tensor([False,  True,  False,  True,  False])
",,,
"
 torch. isposinf ( input ,  * ,  out )   → ¶","Tests if each element of  input  is positive infinity or not. 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([-float('inf'),float('inf'),1.2])
>>> torch.isposinf(a)
tensor([False,  True, False])
",,,
"
 torch. isneginf ( input ,  * ,  out )   → ¶","Tests if each element of  input  is negative infinity or not. 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([-float('inf'),float('inf'),1.2])
>>> torch.isneginf(a)
tensor([ True, False, False])
",,,
"
 torch. isnan ( input )   → ¶","Returns a new tensor with boolean elements representing if each element of  input 
is NaN or not. Complex values are considered NaN when either their real
and/or imaginary part is NaN. 
 Parameters 
 input 
 Returns 
 A boolean tensor that is True where  
 Example: 
",">>> torch.isnan(torch.tensor([1,float('nan'),2]))
tensor([False, True, False])
",,,
"
 torch. isreal ( input )   → ¶","Returns a new tensor with boolean elements representing if each element of  input  is real-valued or not.
All real-valued types are considered real. Complex values are considered real when their imaginary part is 0. 
 Parameters 
 input 
 Returns 
 A boolean tensor that is True where  
 Example: 
",">>> torch.isreal(torch.tensor([1,1+1j,2+0j]))
tensor([True, False, True])
",,,
"
 torch. kthvalue ( input ,  k ,  dim ,  keepdim ,  * ,  out ) ¶","Returns a namedtuple  (values,  where  values  is the  k  th
smallest element of each row of the  input  tensor in the given dimension
 dim . And  indices  is the index location of each element found. If  dim  is not given, the last dimension of the  input  is chosen. If  keepdim  is  True , both the  values  and  indices  tensors
are the same size as  input , except in the dimension  dim  where
they are of size 1. Otherwise,  dim  is squeezed
(see  torch.squeeze() ), resulting in both the  values  and
 indices  tensors having 1 fewer dimension than the  input  tensor. 
 Note 
 When  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> x=torch.arange(1.,6.)
>>> x
tensor([ 1.,  2.,  3.,  4.,  5.])
>>> torch.kthvalue(x,4)
torch.return_types.kthvalue(values=tensor(4.), indices=tensor(3))>>> x=torch.arange(1.,7.).resize_(2,3)
>>> x
tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.]])
>>> torch.kthvalue(x,2,0,True)
torch.return_types.kthvalue(values=tensor([[4., 5., 6.]]), indices=tensor([[1, 1, 1]]))
",,,
"
 torch. le ( input ,  other ,  * ,  out )   → ¶","Computes  input  element-wise. The second argument can be a number or a tensor whose shape is
 broadcastable  with the first argument. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A boolean tensor that is True where  
 Example: 
",">>> torch.le(torch.tensor([[1,2],[3,4]]),torch.tensor([[1,1],[4,4]]))
tensor([[True, False], [True, True]])
",,,
"
 torch. less_equal ( input ,  other ,  * ,  out )   → ¶",Alias for  torch.le() .,,,,
"
 torch. lt ( input ,  other ,  * ,  out )   → ¶","Computes  input  element-wise. The second argument can be a number or a tensor whose shape is
 broadcastable  with the first argument. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A boolean tensor that is True where  
 Example: 
",">>> torch.lt(torch.tensor([[1,2],[3,4]]),torch.tensor([[1,1],[4,4]]))
tensor([[False, False], [True, False]])
",,,
"
 torch. less ( input ,  other ,  * ,  out )   → ¶",Alias for  torch.lt() .,,,,
"
 torch. maximum ( input ,  other ,  * ,  out )   → ¶","Computes the element-wise maximum of  input  and  other . 
 Note 
 If one of the elements being compared is a NaN, then that element is returned.
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor((1,2,-1))
>>> b=torch.tensor((3,0,4))
>>> torch.maximum(a,b)
tensor([3, 2, 4])
",,,
"
 torch. minimum ( input ,  other ,  * ,  out )   → ¶","Computes the element-wise minimum of  input  and  other . 
 Note 
 If one of the elements being compared is a NaN, then that element is returned.
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor((1,2,-1))
>>> b=torch.tensor((3,0,4))
>>> torch.minimum(a,b)
tensor([1, 0, -1])
",,,
"
 torch. fmax ( input ,  other ,  * ,  out )   → ¶","Computes the element-wise maximum of  input  and  other . This is like  torch.maximum()  except it handles NaNs differently:
if exactly one of the two elements being compared is a NaN then the non-NaN element is taken as the maximum.
Only if both elements are NaN is NaN propagated. This function is a wrapper around C++’s  std::fmax  and is similar to NumPy’s  fmax  function. Supports  broadcasting to a common shape ,
 type promotion , and integer and floating-point inputs. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([9.7,float('nan'),3.1,float('nan')])
>>> b=torch.tensor([-2.2,0.5,float('nan'),float('nan')])
>>> torch.fmax(a,b)
tensor([9.7000, 0.5000, 3.1000,    nan])
",,,
"
 torch. fmin ( input ,  other ,  * ,  out )   → ¶","Computes the element-wise minimum of  input  and  other . This is like  torch.minimum()  except it handles NaNs differently:
if exactly one of the two elements being compared is a NaN then the non-NaN element is taken as the minimum.
Only if both elements are NaN is NaN propagated. This function is a wrapper around C++’s  std::fmin  and is similar to NumPy’s  fmin  function. Supports  broadcasting to a common shape ,
 type promotion , and integer and floating-point inputs. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([2.2,float('nan'),2.1,float('nan')])
>>> b=torch.tensor([-9.3,0.1,float('nan'),float('nan')])
>>> torch.fmin(a,b)
tensor([-9.3000, 0.1000, 2.1000,    nan])
",,,
"
 torch. ne ( input ,  other ,  * ,  out )   → ¶","Computes  input  element-wise. The second argument can be a number or a tensor whose shape is
 broadcastable  with the first argument. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A boolean tensor that is True where  
 Example: 
",">>> torch.ne(torch.tensor([[1,2],[3,4]]),torch.tensor([[1,1],[4,4]]))
tensor([[False, True], [True, False]])
",,,
"
 torch. not_equal ( input ,  other ,  * ,  out )   → ¶",Alias for  torch.ne() .,,,,
"
 torch. sort ( input ,  dim ,  descending ,  stable ,  * ,  out ) ¶","Sorts the elements of the  input  tensor along a given dimension
in ascending order by value. If  dim  is not given, the last dimension of the  input  is chosen. If  descending  is  True  then the elements are sorted in descending
order by value. If  stable  is  True  then the sorting routine becomes stable, preserving
the order of equivalent elements. A namedtuple of (values, indices) is returned, where the  values  are the
sorted values and  indices  are the indices of the elements in the original
 input  tensor. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> x=torch.randn(3,4)
>>> sorted,indices=torch.sort(x)
>>> sorted
tensor([[-0.2162,  0.0608,  0.6719,  2.3332],
        [-0.5793,  0.0061,  0.6058,  0.9497],
        [-0.5071,  0.3343,  0.9553,  1.0960]])
>>> indices
tensor([[ 1,  0,  2,  3],
        [ 3,  1,  0,  2],
        [ 0,  3,  1,  2]])>>> sorted,indices=torch.sort(x,0)
>>> sorted
tensor([[-0.5071, -0.2162,  0.6719, -0.5793],
        [ 0.0608,  0.0061,  0.9497,  0.3343],
        [ 0.6058,  0.9553,  1.0960,  2.3332]])
>>> indices
tensor([[ 2,  0,  0,  1],
        [ 0,  1,  1,  2],
        [ 1,  2,  2,  0]])
>>> x=torch.tensor([0,1]*9)
>>> x.sort()
torch.return_types.sort(
    values=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),
    indices=tensor([ 2, 16,  4,  6, 14,  8,  0, 10, 12,  9, 17, 15, 13, 11,  7,  5,  3,  1]))
>>> x.sort(stable=True)
torch.return_types.sort(
    values=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),
    indices=tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16,  1,  3,  5,  7,  9, 11, 13, 15, 17]))
",,,
"
 torch. topk ( input ,  k ,  dim ,  largest ,  sorted ,  * ,  out ) ¶","Returns the  k  largest elements of the given  input  tensor along
a given dimension. If  dim  is not given, the last dimension of the  input  is chosen. If  largest  is  False  then the  k  smallest elements are returned. A namedtuple of  (values, indices)  is returned with the  values  and
 indices  of the largest  k  elements of each row of the  input  tensor in the
given dimension  dim . The boolean option  sorted  if  True , will make sure that the returned
 k  elements are themselves sorted 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> x=torch.arange(1.,6.)
>>> x
tensor([ 1.,  2.,  3.,  4.,  5.])
>>> torch.topk(x,3)
torch.return_types.topk(values=tensor([5., 4., 3.]), indices=tensor([4, 3, 2]))
",,,
"
 torch. msort ( input ,  * ,  out )   → ¶","Sorts the elements of the  input  tensor along its first dimension
in ascending order by value. 
 Note 
 torch.msort(t) 
 
 Parameters 
 input 
 Keyword Arguments 
 out 
 Example: 
",">>> t=torch.randn(3,4)
>>> t
tensor([[-0.1321,  0.4370, -1.2631, -1.1289],
        [-2.0527, -1.1250,  0.2275,  0.3077],
        [-0.0881, -0.1259, -0.5495,  1.0284]])
>>> torch.msort(t)
tensor([[-2.0527, -1.1250, -1.2631, -1.1289],
        [-0.1321, -0.1259, -0.5495,  0.3077],
        [-0.0881,  0.4370,  0.2275,  1.0284]])
",,,
"
 torch. stft ( input ,  n_fft ,  hop_length ,  win_length ,  window ,  center ,  pad_mode ,  normalized ,  onesided ,  return_complex ) [source] ¶","Short-time Fourier transform (STFT). 
 Warning 
 From version 1.8.0,  
 Note that  
 The STFT computes the Fourier transform of short overlapping windows of the
input. This giving frequency components of the signal as they change over
time. The interface of this function is modeled after (but  not  a drop-in
replacement for)  librosa  stft function. Ignoring the optional batch dimension, this method computes the following
expression: 
 X where  m  is the index of the sliding window, and  ω  is
the frequency  0  for  onesided=False ,
or  0  for  onesided=True . 
 input 
 If  
 If  
 window 
 If  
 pad_mode 
 If  
 If  
 If  
 Returns either a complex tensor of size  (  if
 return_complex  is true, or a real tensor of size  ( . Where  ∗  is the optional batch size of
 input ,  N  is the number of frequencies where STFT is applied
and  T  is the total number of frames used. 
 Warning 
 This function changed signature at version 0.4.1. Calling with the
previous signature may cause error or return incorrect result. 
 
 Parameters 
 
 
 Returns 
 A tensor containing the STFT result with shape described above 
 Return type 
 Tensor 
",,,,
"
 torch. istft ( input ,  n_fft ,  hop_length ,  win_length ,  window ,  center ,  normalized ,  onesided ,  length ,  return_complex )   → ¶","Inverse short time Fourier Transform. This is expected to be the inverse of  stft() . It has the same parameters (+ additional optional parameter of  length ) and it should return the
least squares estimation of the original signal. The algorithm will check using the NOLA condition (
nonzero overlap). Important consideration in the parameters  window  and  center  so that the envelop
created by the summation of all the windows is never zero at certain point in time. Specifically,
 ∑ . Since  stft()  discards elements at the end of the signal if they do not fit in a frame,
 istft  may return a shorter signal than the original signal (can occur if  center  is False
since the signal isn’t padded). If  length  is given in the arguments and is longer than expected,
 istft  will pad zeros to the end of the returned signal. If  center  is  True , then there will be padding e.g.  'constant' ,  'reflect' , etc.
Left padding can be trimmed off exactly because they can be calculated but right padding cannot be
calculated without additional information. Example: Suppose the last window is:
 [17,  vs  [18, The  n_fft ,  hop_length ,  win_length  are all the same which prevents the calculation
of right padding. These additional values could be zeros or a reflection of the signal so providing
 length  could be useful. If  length  is  None  then padding will be aggressively removed
(some loss of signal). [1] D. W. Griffin and J. S. Lim, “Signal estimation from modified short-time Fourier transform,”
IEEE Trans. ASSP, vol.32, no.2, pp.236-243, Apr. 1984. 
 Parameters 
 
 
 Returns 
 Least squares estimation of the original signal of size (…, signal_length) 
 Return type 
 Tensor 
",,,,
"
 torch. bartlett_window ( window_length ,  periodic ,  * ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Bartlett window function. 
 w where  N  is the full window size. The input  window_length  is a positive integer controlling the
returned window size.  periodic  flag determines whether the returned
window trims off the last duplicate value from the symmetric window and is
ready to be used as a periodic window with functions like
 torch.stft() . Therefore, if  periodic  is true, the  N  in
above formula is in fact  window_length . Also, we always have
 torch.bartlett_window(L,  equal to
 torch.bartlett_window(L . 
 Note 
 If  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A 1-D tensor of size  
 Return type 
 Tensor 
",,,,
"
 torch. blackman_window ( window_length ,  periodic ,  * ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Blackman window function. 
 w where  N  is the full window size. The input  window_length  is a positive integer controlling the
returned window size.  periodic  flag determines whether the returned
window trims off the last duplicate value from the symmetric window and is
ready to be used as a periodic window with functions like
 torch.stft() . Therefore, if  periodic  is true, the  N  in
above formula is in fact  window_length . Also, we always have
 torch.blackman_window(L,  equal to
 torch.blackman_window(L . 
 Note 
 If  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A 1-D tensor of size  
 Return type 
 Tensor 
",,,,
"
 torch. hamming_window ( window_length ,  periodic ,  alpha ,  beta ,  * ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Hamming window function. 
 w where  N  is the full window size. The input  window_length  is a positive integer controlling the
returned window size.  periodic  flag determines whether the returned
window trims off the last duplicate value from the symmetric window and is
ready to be used as a periodic window with functions like
 torch.stft() . Therefore, if  periodic  is true, the  N  in
above formula is in fact  window_length . Also, we always have
 torch.hamming_window(L,  equal to
 torch.hamming_window(L . 
 Note 
 If  
 
 Note 
 This is a generalized version of  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A 1-D tensor of size  
 Return type 
 Tensor 
",,,,
"
 torch. hann_window ( window_length ,  periodic ,  * ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Hann window function. 
 w where  N  is the full window size. The input  window_length  is a positive integer controlling the
returned window size.  periodic  flag determines whether the returned
window trims off the last duplicate value from the symmetric window and is
ready to be used as a periodic window with functions like
 torch.stft() . Therefore, if  periodic  is true, the  N  in
above formula is in fact  window_length . Also, we always have
 torch.hann_window(L,  equal to
 torch.hann_window(L . 
 Note 
 If  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A 1-D tensor of size  
 Return type 
 Tensor 
",,,,
"
 torch. kaiser_window ( window_length ,  periodic ,  beta ,  * ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Computes the Kaiser window with window length  window_length  and shape parameter  beta . Let I_0 be the zeroth order modified Bessel function of the first kind (see  torch.i0() ) and
 N  if  periodic  is False and  L  if  periodic  is True,
where  L  is the  window_length . This function computes: 
 o Calling  torch.kaiser_window(L,  is equivalent to calling
 torch.kaiser_window(L .
The  periodic  argument is intended as a helpful shorthand
to produce a periodic window as input to functions like  torch.stft() . 
 Note 
 If  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
",,,,
"
 torch. atleast_1d ( * ) [source] ¶","Returns a 1-dimensional view of each input tensor with zero dimensions.
Input tensors with one or more dimensions are returned as-is. 
 Parameters 
 input 
 Returns 
 output (Tensor or tuple of Tensors) 
 Example: 
",">>> x=torch.arange(2)
>>> x
tensor([0, 1])
>>> torch.atleast_1d(x)
tensor([0, 1])
>>> x=torch.tensor(1.)
>>> x
tensor(1.)
>>> torch.atleast_1d(x)
tensor([1.])
>>> x=torch.tensor(0.5)
>>> y=torch.tensor(1.)
>>> torch.atleast_1d((x,y))
(tensor([0.5000]), tensor([1.]))
",,,
"
 torch. atleast_2d ( * ) [source] ¶","Returns a 2-dimensional view of each input tensor with zero dimensions.
Input tensors with two or more dimensions are returned as-is. 
 Parameters 
 input 
 Returns 
 output (Tensor or tuple of Tensors) 
 Example: 
",">>> x=torch.tensor(1.)
>>> x
tensor(1.)
>>> torch.atleast_2d(x)
tensor([[1.]])
>>> x=torch.arange(4).view(2,2)
>>> x
tensor([[0, 1],
        [2, 3]])
>>> torch.atleast_2d(x)
tensor([[0, 1],
        [2, 3]])
>>> x=torch.tensor(0.5)
>>> y=torch.tensor(1.)
>>> torch.atleast_2d((x,y))
(tensor([[0.5000]]), tensor([[1.]]))
",,,
"
 torch. atleast_3d ( * ) [source] ¶","Returns a 3-dimensional view of each input tensor with zero dimensions.
Input tensors with three or more dimensions are returned as-is. 
 Parameters 
 input 
 Returns 
 output (Tensor or tuple of Tensors) 
 Example 
",,,,
"
 torch. bincount ( input ,  weights ,  minlength )   → ¶","Count the frequency of each value in an array of non-negative ints. The number of bins (size 1) is one larger than the largest value in
 input  unless  input  is empty, in which case the result is a
tensor of size 0. If  minlength  is specified, the number of bins is at least
 minlength  and if  input  is empty, then the result is tensor of size
 minlength  filled with zeros. If  n  is the value at position  i ,
 out[n]  if  weights  is specified else
 out[n] . 
 Note 
 This operation may produce nondeterministic gradients when given tensors on a CUDA device. See  
 
 Parameters 
 
 
 Returns 
 a tensor of shape  
 Return type 
 output ( 
 Example: 
",">>> input=torch.randint(0,8,(5,),dtype=torch.int64)
>>> weights=torch.linspace(0,1,steps=5)
>>> input,weights
(tensor([4, 3, 6, 3, 4]),
 tensor([ 0.0000,  0.2500,  0.5000,  0.7500,  1.0000])>>> torch.bincount(input)
tensor([0, 0, 0, 2, 2, 0, 1])>>> input.bincount(weights)
tensor([0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.5000])
",,,
"
 torch. block_diag ( * ) [source] ¶","Create a block diagonal matrix from provided tensors. 
 Parameters 
 *tensors 
 Returns 
 A 2 dimensional tensor with all the input tensors arranged in
order such that their upper left and lower right corners are
diagonally adjacent. All other elements are set to 0. 
 Return type 
 Tensor 
 Example: 
",">>> importtorch
>>> A=torch.tensor([[0,1],[1,0]])
>>> B=torch.tensor([[3,4,5],[6,7,8]])
>>> C=torch.tensor(7)
>>> D=torch.tensor([1,2,3])
>>> E=torch.tensor([[4],[5],[6]])
>>> torch.block_diag(A,B,C,D,E)
tensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 0, 3, 4, 5, 0, 0, 0, 0, 0],
        [0, 0, 6, 7, 8, 0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 7, 0, 0, 0, 0],
        [0, 0, 0, 0, 0, 0, 1, 2, 3, 0],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 4],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 6]])
",,,
"
 torch. broadcast_tensors ( * )   → [source] ¶","Broadcasts the given tensors according to  Broadcasting semantics . 
 Parameters 
 *tensors 
 
 Warning 
 More than one element of a broadcasted tensor may refer to a single
memory location. As a result, in-place operations (especially ones that
are vectorized) may result in incorrect behavior. If you need to write
to the tensors, please clone them first. 
 Example: 
",">>> x=torch.arange(3).view(1,3)
>>> y=torch.arange(2).view(2,1)
>>> a,b=torch.broadcast_tensors(x,y)
>>> a.size()
torch.Size([2, 3])
>>> a
tensor([[0, 1, 2],
        [0, 1, 2]])
",,,
"
 torch. broadcast_to ( input ,  shape )   → ¶","Broadcasts  input  to the shape  shape .
Equivalent to calling  input.expand(shape) . See  expand()  for details. 
 Parameters 
 
 
 Example: 
",">>> x=torch.tensor([1,2,3])
>>> torch.broadcast_to(x,(3,3))
tensor([[1, 2, 3],
        [1, 2, 3],
        [1, 2, 3]])
",,,
"
 torch. broadcast_shapes ( * )   → [source] ¶","Similar to  broadcast_tensors()  but for shapes. This is equivalent to
 torch.broadcast_tensors(*map(torch.empty, 
but avoids the need create to intermediate tensors. This is useful for
broadcasting tensors of common batch shape but different rightmost shape,
e.g. to broadcast mean vectors with covariance matrices. Example: 
 
 Parameters 
 *shapes 
 Returns 
 A shape compatible with all input shapes. 
 Return type 
 shape (torch.Size) 
 Raises 
 RuntimeError 
",">>> torch.broadcast_shapes((2,),(3,1),(1,1,1))
torch.Size([1, 3, 2])
",,,
"
 torch. bucketize ( input ,  boundaries ,  * ,  out_int32 ,  right ,  out )   → ¶","Returns the indices of the buckets to which each value in the  input  belongs, where the
boundaries of the buckets are set by  boundaries . Return a new tensor with the same size
as  input . If  right  is False (default), then the left boundary is closed. More
formally, the returned index satisfies the following rules: 
 
 
 
 
 
 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> boundaries=torch.tensor([1,3,5,7,9])
>>> boundaries
tensor([1, 3, 5, 7, 9])
>>> v=torch.tensor([[3,6,9],[3,6,9]])
>>> v
tensor([[3, 6, 9],
        [3, 6, 9]])
>>> torch.bucketize(v,boundaries)
tensor([[1, 3, 4],
        [1, 3, 4]])
>>> torch.bucketize(v,boundaries,right=True)
tensor([[2, 3, 5],
        [2, 3, 5]])
",,,
"
 torch. cartesian_prod ( * ) [source] ¶","Do cartesian product of the given sequence of tensors. The behavior is similar to
python’s  itertools.product . 
 Parameters 
 *tensors 
 Returns 
 A tensor equivalent to converting all the input tensors into lists,
do  
 Return type 
 Tensor 
 Example: 
",">>> importitertools
>>> a=[1,2,3]
>>> b=[4,5]
>>> list(itertools.product(a,b))
[(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)]
>>> tensor_a=torch.tensor(a)
>>> tensor_b=torch.tensor(b)
>>> torch.cartesian_prod(tensor_a,tensor_b)
tensor([[1, 4],
        [1, 5],
        [2, 4],
        [2, 5],
        [3, 4],
        [3, 5]])
",,,
"
 torch. cdist ( x1 ,  x2 ,  p ,  compute_mode ) [source] ¶","Computes batched the p-norm distance between each pair of the two collections of row vectors. 
 Parameters 
 
 
 Return type 
 Tensor 
 If x1 has shape  B  and x2 has shape  B  then the
output will have shape  B . This function is equivalent to  scipy.spatial.distance.cdist(input,’minkowski’, p=p) 
if  p . When  p  it is equivalent to
 scipy.spatial.distance.cdist(input, ‘hamming’) * M . When  p , the closest
scipy function is  scipy.spatial.distance.cdist(xn, lambda x, y: np.abs(x - y).max()) . Example 
",,,,
"
 torch. clone ( input ,  * ,  memory_format )   → ¶","Returns a copy of  input . 
 Note 
 This function is differentiable, so gradients will flow back from the
result of this operation to  
 
 Parameters 
 input 
 Keyword Arguments 
 memory_format 
",,,,
"
 torch. combinations ( input ,  r ,  with_replacement )   → ¶","Compute combinations of length  r  of the given tensor. The behavior is similar to
python’s  itertools.combinations  when  with_replacement  is set to  False , and
 itertools.combinations_with_replacement  when  with_replacement  is set to  True . 
 Parameters 
 
 
 Returns 
 A tensor equivalent to converting all the input tensors into lists, do
 
 Return type 
 Tensor 
 Example: 
",">>> a=[1,2,3]
>>> list(itertools.combinations(a,r=2))
[(1, 2), (1, 3), (2, 3)]
>>> list(itertools.combinations(a,r=3))
[(1, 2, 3)]
>>> list(itertools.combinations_with_replacement(a,r=2))
[(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]
>>> tensor_a=torch.tensor(a)
>>> torch.combinations(tensor_a)
tensor([[1, 2],
        [1, 3],
        [2, 3]])
>>> torch.combinations(tensor_a,r=3)
tensor([[1, 2, 3]])
>>> torch.combinations(tensor_a,with_replacement=True)
tensor([[1, 1],
        [1, 2],
        [1, 3],
        [2, 2],
        [2, 3],
        [3, 3]])
",,,
"
 torch. corrcoef ( input )   → ¶","Estimates the Pearson product-moment correlation coefficient matrix of the variables given by the  input  matrix,
where rows are the variables and columns are the observations. 
 Note 
 The correlation coefficient matrix R is computed using the covariance matrix C as given by
 
 
 Note 
 Due to floating point rounding, the resulting array may not be Hermitian and its diagonal elements may not be 1.
The real and imaginary values are clipped to the interval [-1, 1] in an attempt to improve this situation. 
 
 Parameters 
 input 
 Returns 
 (Tensor) The correlation coefficient matrix of the variables. 
 
 See also 
 torch.cov() 
 Example: 
",">>> x=torch.tensor([[0,1,2],[2,1,0]])
>>> torch.corrcoef(x)
tensor([[ 1., -1.],
        [-1.,  1.]])
>>> x=torch.randn(2,4)
>>> x
tensor([[-0.2678, -0.0908, -0.3766,  0.2780],
        [-0.5812,  0.1535,  0.2387,  0.2350]])
>>> torch.corrcoef(x)
tensor([[1.0000, 0.3582],
        [0.3582, 1.0000]])
>>> torch.corrcoef(x[0])
tensor(1.)
",,,
"
 torch. cov ( input ,  * ,  correction ,  fweights ,  aweights )   → ¶","Estimates the covariance matrix of the variables given by the  input  matrix, where rows are
the variables and columns are the observations. A covariance matrix is a square matrix giving the covariance of each pair of variables. The diagonal contains
the variance of each variable (covariance of a variable with itself). By definition, if  input  represents
a single variable (Scalar or 1D) then its variance is returned. The unbiased sample covariance of the variables  x  and  y  is given by: 
 cov where  x  and  y  are the simple means of the  x  and  y  respectively. If  fweights  and/or  aweights  are provided, the unbiased weighted covariance
is calculated, which is given by: 
 cov where  w  denotes  fweights  or  aweights  based on whichever is provided, or
 w  if both are provided, and
 μ  is the weighted mean of the variable. 
 Parameters 
 input 
 Keyword Arguments 
 
 
 Returns 
 (Tensor) The covariance matrix of the variables. 
 
 See also 
 torch.corrcoef() 
 
 Example:: 
",,,,
"
 torch. cross ( input ,  other ,  dim ,  * ,  out )   → ¶","Returns the cross product of vectors in dimension  dim  of  input 
and  other . Supports input of float, double, cfloat and cdouble dtypes. Also supports batches
of vectors, for which it computes the product along the dimension  dim .
In this case, the output has the same batch dimensions as the inputs. If  dim  is not given, it defaults to the first dimension found with the
size 3. Note that this might be unexpected. 
 See also 
 torch.linalg.cross() 
 
 Warning 
 This function may change in a future PyTorch release to match
the default behaviour in  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(4,3)
>>> a
tensor([[-0.3956,  1.1455,  1.6895],
        [-0.5849,  1.3672,  0.3599],
        [-1.1626,  0.7180, -0.0521],
        [-0.1339,  0.9902, -2.0225]])
>>> b=torch.randn(4,3)
>>> b
tensor([[-0.0257, -1.4725, -1.2251],
        [-1.1479, -0.7005, -1.9757],
        [-1.3904,  0.3726, -1.1836],
        [-0.9688, -0.7153,  0.2159]])
>>> torch.cross(a,b,dim=1)
tensor([[ 1.0844, -0.5281,  0.6120],
        [-2.4490, -1.5687,  1.9792],
        [-0.8304, -1.3037,  0.5650],
        [-1.2329,  1.9883,  1.0551]])
>>> torch.cross(a,b)
tensor([[ 1.0844, -0.5281,  0.6120],
        [-2.4490, -1.5687,  1.9792],
        [-0.8304, -1.3037,  0.5650],
        [-1.2329,  1.9883,  1.0551]])
",,,
"
 torch. cummax ( input ,  dim ,  * ,  out ) ¶","Returns a namedtuple  (values,  where  values  is the cumulative maximum of
elements of  input  in the dimension  dim . And  indices  is the index
location of each maximum value found in the dimension  dim . 
 y 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(10)
>>> a
tensor([-0.3449, -1.5447,  0.0685, -1.5104, -1.1706,  0.2259,  1.4696, -1.3284,
     1.9946, -0.8209])
>>> torch.cummax(a,dim=0)
torch.return_types.cummax(
    values=tensor([-0.3449, -0.3449,  0.0685,  0.0685,  0.0685,  0.2259,  1.4696,  1.4696,
     1.9946,  1.9946]),
    indices=tensor([0, 0, 2, 2, 2, 5, 6, 6, 8, 8]))
",,,
"
 torch. cummin ( input ,  dim ,  * ,  out ) ¶","Returns a namedtuple  (values,  where  values  is the cumulative minimum of
elements of  input  in the dimension  dim . And  indices  is the index
location of each maximum value found in the dimension  dim . 
 y 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(10)
>>> a
tensor([-0.2284, -0.6628,  0.0975,  0.2680, -1.3298, -0.4220, -0.3885,  1.1762,
     0.9165,  1.6684])
>>> torch.cummin(a,dim=0)
torch.return_types.cummin(
    values=tensor([-0.2284, -0.6628, -0.6628, -0.6628, -1.3298, -1.3298, -1.3298, -1.3298,
    -1.3298, -1.3298]),
    indices=tensor([0, 1, 1, 1, 4, 4, 4, 4, 4, 4]))
",,,
"
 torch. cumprod ( input ,  dim ,  * ,  dtype ,  out )   → ¶","Returns the cumulative product of elements of  input  in the dimension
 dim . For example, if  input  is a vector of size N, the result will also be
a vector of size N, with elements. 
 y 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> a=torch.randn(10)
>>> a
tensor([ 0.6001,  0.2069, -0.1919,  0.9792,  0.6727,  1.0062,  0.4126,
        -0.2129, -0.4206,  0.1968])
>>> torch.cumprod(a,dim=0)
tensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0158, -0.0065,
         0.0014, -0.0006, -0.0001])>>> a[5]=0.0
>>> torch.cumprod(a,dim=0)
tensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0000, -0.0000,
         0.0000, -0.0000, -0.0000])
",,,
"
 torch. cumsum ( input ,  dim ,  * ,  dtype ,  out )   → ¶","Returns the cumulative sum of elements of  input  in the dimension
 dim . For example, if  input  is a vector of size N, the result will also be
a vector of size N, with elements. 
 y 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> a=torch.randn(10)
>>> a
tensor([-0.8286, -0.4890,  0.5155,  0.8443,  0.1865, -0.1752, -2.0595,
         0.1850, -1.1571, -0.4243])
>>> torch.cumsum(a,dim=0)
tensor([-0.8286, -1.3175, -0.8020,  0.0423,  0.2289,  0.0537, -2.0058,
        -1.8209, -2.9780, -3.4022])
",,,
"
 torch. diag ( input ,  diagonal ,  * ,  out )   → ¶","
 If  
 If  
 The argument  diagonal  controls which diagonal to consider: 
 If  
 If  
 If  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 
 See also 
 torch.diagonal() 
 torch.diagflat() 
 Examples: Get the square matrix where the input vector is the diagonal: 
 Get the k-th diagonal of a given matrix: 
",">>> a=torch.randn(3)
>>> a
tensor([ 0.5950,-0.0872, 2.3298])
>>> torch.diag(a)
tensor([[ 0.5950, 0.0000, 0.0000],
        [ 0.0000,-0.0872, 0.0000],
        [ 0.0000, 0.0000, 2.3298]])
>>> torch.diag(a,1)
tensor([[ 0.0000, 0.5950, 0.0000, 0.0000],
        [ 0.0000, 0.0000,-0.0872, 0.0000],
        [ 0.0000, 0.0000, 0.0000, 2.3298],
        [ 0.0000, 0.0000, 0.0000, 0.0000]])
",">>> a=torch.randn(3,3)
>>> a
tensor([[-0.4264, 0.0255,-0.1064],
        [ 0.8795,-0.2429, 0.1374],
        [ 0.1029,-0.6482,-1.6300]])
>>> torch.diag(a,0)
tensor([-0.4264,-0.2429,-1.6300])
>>> torch.diag(a,1)
tensor([ 0.0255, 0.1374])
",,
"
 torch. diag_embed ( input ,  offset ,  dim1 ,  dim2 )   → ¶","Creates a tensor whose diagonals of certain 2D planes (specified by
 dim1  and  dim2 ) are filled by  input .
To facilitate creating batched diagonal matrices, the 2D planes formed by
the last two dimensions of the returned tensor are chosen by default. The argument  offset  controls which diagonal to consider: 
 If  
 If  
 If  
 The size of the new matrix will be calculated to make the specified diagonal
of the size of the last input dimension.
Note that for  offset  other than  0 , the order of  dim1 
and  dim2  matters. Exchanging them is equivalent to changing the
sign of  offset . Applying  torch.diagonal()  to the output of this function with
the same arguments yields a matrix identical to input. However,
 torch.diagonal()  has different default dimensions, so those
need to be explicitly specified. 
 Parameters 
 
 
 Example: 
",">>> a=torch.randn(2,3)
>>> torch.diag_embed(a)
tensor([[[ 1.5410,  0.0000,  0.0000],
         [ 0.0000, -0.2934,  0.0000],
         [ 0.0000,  0.0000, -2.1788]],        [[ 0.5684,  0.0000,  0.0000],
         [ 0.0000, -1.0845,  0.0000],
         [ 0.0000,  0.0000, -1.3986]]])>>> torch.diag_embed(a,offset=1,dim1=0,dim2=2)
tensor([[[ 0.0000,  1.5410,  0.0000,  0.0000],
         [ 0.0000,  0.5684,  0.0000,  0.0000]],        [[ 0.0000,  0.0000, -0.2934,  0.0000],
         [ 0.0000,  0.0000, -1.0845,  0.0000]],        [[ 0.0000,  0.0000,  0.0000, -2.1788],
         [ 0.0000,  0.0000,  0.0000, -1.3986]],        [[ 0.0000,  0.0000,  0.0000,  0.0000],
         [ 0.0000,  0.0000,  0.0000,  0.0000]]])
",,,
"
 torch. diagflat ( input ,  offset )   → ¶","
 If  
 If  
 The argument  offset  controls which diagonal to consider: 
 If  
 If  
 If  
 
 Parameters 
 
 
 Examples: 
",">>> a=torch.randn(3)
>>> a
tensor([-0.2956, -0.9068,  0.1695])
>>> torch.diagflat(a)
tensor([[-0.2956,  0.0000,  0.0000],
        [ 0.0000, -0.9068,  0.0000],
        [ 0.0000,  0.0000,  0.1695]])
>>> torch.diagflat(a,1)
tensor([[ 0.0000, -0.2956,  0.0000,  0.0000],
        [ 0.0000,  0.0000, -0.9068,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.1695],
        [ 0.0000,  0.0000,  0.0000,  0.0000]])>>> a=torch.randn(2,2)
>>> a
tensor([[ 0.2094, -0.3018],
        [-0.1516,  1.9342]])
>>> torch.diagflat(a)
tensor([[ 0.2094,  0.0000,  0.0000,  0.0000],
        [ 0.0000, -0.3018,  0.0000,  0.0000],
        [ 0.0000,  0.0000, -0.1516,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  1.9342]])
",,,
"
 torch. diagonal ( input ,  offset ,  dim1 ,  dim2 )   → ¶","Returns a partial view of  input  with the its diagonal elements
with respect to  dim1  and  dim2  appended as a dimension
at the end of the shape. The argument  offset  controls which diagonal to consider: 
 If  
 If  
 If  
 Applying  torch.diag_embed()  to the output of this function with
the same arguments yields a diagonal matrix with the diagonal entries
of the input. However,  torch.diag_embed()  has different default
dimensions, so those need to be explicitly specified. 
 Parameters 
 
 
 
 Note 
 To take a batch diagonal, pass in dim1=-2, dim2=-1. 
 Examples: 
",">>> a=torch.randn(3,3)
>>> a
tensor([[-1.0854,  1.1431, -0.1752],
        [ 0.8536, -0.0905,  0.0360],
        [ 0.6927, -0.3735, -0.4945]])>>> torch.diagonal(a,0)
tensor([-1.0854, -0.0905, -0.4945])>>> torch.diagonal(a,1)
tensor([ 1.1431,  0.0360])>>> x=torch.randn(2,5,4,2)
>>> torch.diagonal(x,offset=-1,dim1=1,dim2=2)
tensor([[[-1.2631,  0.3755, -1.5977, -1.8172],
         [-1.1065,  1.0401, -0.2235, -0.7938]],        [[-1.7325, -0.3081,  0.6166,  0.2335],
         [ 1.0500,  0.7336, -0.3836, -1.1015]]])
",,,
"
 torch. diff ( input ,  n ,  dim ,  prepend ,  append )   → ¶","Computes the n-th forward difference along the given dimension. The first-order differences are given by  out[i] = input[i + 1] - input[i] . Higher-order
differences are calculated by using  torch.diff()  recursively. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([1,3,2])
>>> torch.diff(a)
tensor([ 2, -1])
>>> b=torch.tensor([4,5])
>>> torch.diff(a,append=b)
tensor([ 2, -1,  2,  1])
>>> c=torch.tensor([[1,2,3],[3,4,5]])
>>> torch.diff(c,dim=0)
tensor([[2, 2, 2]])
>>> torch.diff(c,dim=1)
tensor([[1, 1],
        [1, 1]])
",,,
"
 torch. einsum ( equation ,  * )   → [source] ¶","Sums the product of the elements of the input  operands  along dimensions specified using a notation
based on the Einstein summation convention. Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them
in a short-hand format based on the Einstein summation convention, given by  equation . The details of
this format are described below, but the general idea is to label every dimension of the input  operands 
with some subscript and define which subscripts are part of the output. The output is then computed by summing
the product of the elements of the  operands  along the dimensions whose subscripts are not part of the
output. For example, matrix multiplication can be computed using einsum as  torch.einsum(“ij,jk->ik”, A, B) .
Here, j is the summation subscript and i and k the output subscripts (see section below for more details on why). Equation: 
 The  
 Note 
 torch.einsum 
 
 Note 
 This function uses opt_einsum ( 
 To bypass this default behavior, add the following line to disable the usage of opt_einsum and skip path
calculation:  
 To specify which strategy you’d like for opt_einsum to compute the contraction path, add the following line:
 
 
 Note 
 As of PyTorch 1.10  
 
 Parameters 
 
 
 Return type 
 Tensor 
 Examples: 
",">>> # trace
>>> torch.einsum('ii',torch.randn(4,4))
tensor(-1.2104)>>> # diagonal
>>> torch.einsum('ii->i',torch.randn(4,4))
tensor([-0.1034,  0.7952, -0.2433,  0.4545])>>> # outer product
>>> x=torch.randn(5)
>>> y=torch.randn(4)
>>> torch.einsum('i,j->ij',x,y)
tensor([[ 0.1156, -0.2897, -0.3918,  0.4963],
        [-0.3744,  0.9381,  1.2685, -1.6070],
        [ 0.7208, -1.8058, -2.4419,  3.0936],
        [ 0.1713, -0.4291, -0.5802,  0.7350],
        [ 0.5704, -1.4290, -1.9323,  2.4480]])>>> # batch matrix multiplication
>>> As=torch.randn(3,2,5)
>>> Bs=torch.randn(3,5,4)
>>> torch.einsum('bij,bjk->bik',As,Bs)
tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],
        [-1.6706, -0.8097, -0.8025, -2.1183]],        [[ 4.2239,  0.3107, -0.5756, -0.2354],
        [-1.4558, -0.3460,  1.5087, -0.8530]],        [[ 2.8153,  1.8787, -4.3839, -1.2112],
        [ 0.3728, -2.1131,  0.0921,  0.8305]]])>>> # with sublist format and ellipsis
>>> torch.einsum(As,[...,0,1],Bs,[...,1,2],[...,0,2])
tensor([[[-1.0564, -1.5904,  3.2023,  3.1271],
        [-1.6706, -0.8097, -0.8025, -2.1183]],        [[ 4.2239,  0.3107, -0.5756, -0.2354],
        [-1.4558, -0.3460,  1.5087, -0.8530]],        [[ 2.8153,  1.8787, -4.3839, -1.2112],
        [ 0.3728, -2.1131,  0.0921,  0.8305]]])>>> # batch permute
>>> A=torch.randn(2,3,4,5)
>>> torch.einsum('...ij->...ji',A).shape
torch.Size([2, 3, 5, 4])>>> # equivalent to torch.nn.functional.bilinear
>>> A=torch.randn(3,5,4)
>>> l=torch.randn(2,5)
>>> r=torch.randn(2,4)
>>> torch.einsum('bn,anm,bm->ba',l,A,r)
tensor([[-0.3430, -5.2405,  0.4494],
        [ 0.3311,  5.5201, -3.0356]])
",,,
"
 torch. flatten ( input ,  start_dim ,  end_dim )   → ¶","Flattens  input  by reshaping it into a one-dimensional tensor. If  start_dim  or  end_dim 
are passed, only dimensions starting with  start_dim  and ending with  end_dim  are flattened.
The order of elements in  input  is unchanged. Unlike NumPy’s flatten, which always copies input’s data, this function may return the original object, a view,
or copy. If no dimensions are flattened, then the original object  input  is returned. Otherwise, if input can
be viewed as the flattened shape, then that view is returned. Finally, only if the input cannot be viewed as the
flattened shape is input’s data copied. See  torch.Tensor.view()  for details on when a view will be returned. 
 Note 
 Flattening a zero-dimensional tensor will return a one-dimensional view. 
 
 Parameters 
 
 
 Example: 
",">>> t=torch.tensor([[[1,2],
... [3,4]],
... [[5,6],
... [7,8]]])
>>> torch.flatten(t)
tensor([1, 2, 3, 4, 5, 6, 7, 8])
>>> torch.flatten(t,start_dim=1)
tensor([[1, 2, 3, 4],
        [5, 6, 7, 8]])
",,,
"
 torch. flip ( input ,  dims )   → ¶","Reverse the order of a n-D tensor along given axis in dims. 
 Note 
 torch.flip 
 
 Parameters 
 
 
 Example: 
",">>> x=torch.arange(8).view(2,2,2)
>>> x
tensor([[[ 0,  1],
         [ 2,  3]],        [[ 4,  5],
         [ 6,  7]]])
>>> torch.flip(x,[0,1])
tensor([[[ 6,  7],
         [ 4,  5]],        [[ 2,  3],
         [ 0,  1]]])
",,,
"
 torch. fliplr ( input )   → ¶","Flip tensor in the left/right direction, returning a new tensor. Flip the entries in each row in the left/right direction.
Columns are preserved, but appear in a different order than before. 
 Note 
 Requires the tensor to be at least 2-D. 
 
 Note 
 torch.fliplr 
 
 Parameters 
 input 
 Example: 
",">>> x=torch.arange(4).view(2,2)
>>> x
tensor([[0, 1],
        [2, 3]])
>>> torch.fliplr(x)
tensor([[1, 0],
        [3, 2]])
",,,
"
 torch. flipud ( input )   → ¶","Flip tensor in the up/down direction, returning a new tensor. Flip the entries in each column in the up/down direction.
Rows are preserved, but appear in a different order than before. 
 Note 
 Requires the tensor to be at least 1-D. 
 
 Note 
 torch.flipud 
 
 Parameters 
 input 
 Example: 
",">>> x=torch.arange(4).view(2,2)
>>> x
tensor([[0, 1],
        [2, 3]])
>>> torch.flipud(x)
tensor([[2, 3],
        [0, 1]])
",,,
"
 torch. kron ( input ,  other ,  * ,  out )   → ¶","Computes the Kronecker product, denoted by  ⊗ , of  input  and  other . If  input  is a  (  tensor and  other  is a
 (  tensor, the result will be a
 (  tensor with the following entries: 
 ( where  k  for  0 .
If one tensor has fewer dimensions than the other it is unsqueezed until it has the same number of dimensions. Supports real-valued and complex-valued inputs. 
 Note 
 This function generalizes the typical definition of the Kronecker product for two matrices to two tensors,
as described above. When  
 
 where  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Examples: 
",">>> mat1=torch.eye(2)
>>> mat2=torch.ones(2,2)
>>> torch.kron(mat1,mat2)
tensor([[1., 1., 0., 0.],
        [1., 1., 0., 0.],
        [0., 0., 1., 1.],
        [0., 0., 1., 1.]])>>> mat1=torch.eye(2)
>>> mat2=torch.arange(1,5).reshape(2,2)
>>> torch.kron(mat1,mat2)
tensor([[1., 2., 0., 0.],
        [3., 4., 0., 0.],
        [0., 0., 1., 2.],
        [0., 0., 3., 4.]])
",,,
"
 torch. rot90 ( input ,  k ,  dims )   → ¶","Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.
Rotation direction is from the first towards the second axis if k > 0, and from the second towards the first for k < 0. 
 Parameters 
 
 
 Example: 
",">>> x=torch.arange(4).view(2,2)
>>> x
tensor([[0, 1],
        [2, 3]])
>>> torch.rot90(x,1,[0,1])
tensor([[1, 3],
        [0, 2]])>>> x=torch.arange(8).view(2,2,2)
>>> x
tensor([[[0, 1],
         [2, 3]],        [[4, 5],
         [6, 7]]])
>>> torch.rot90(x,1,[1,2])
tensor([[[1, 3],
         [0, 2]],        [[5, 7],
         [4, 6]]])
",,,
"
 torch. gcd ( input ,  other ,  * ,  out )   → ¶","Computes the element-wise greatest common divisor (GCD) of  input  and  other . Both  input  and  other  must have integer types. 
 Note 
 This defines  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([5,10,15])
>>> b=torch.tensor([3,4,5])
>>> torch.gcd(a,b)
tensor([1, 2, 5])
>>> c=torch.tensor([3])
>>> torch.gcd(a,c)
tensor([1, 1, 3])
",,,
"
 torch. histc ( input ,  bins ,  min ,  max ,  * ,  out )   → ¶","Computes the histogram of a tensor. The elements are sorted into equal width bins between  min  and
 max . If  min  and  max  are both zero, the minimum and
maximum values of the data are used. Elements lower than min and higher than max are ignored. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 Histogram represented as a tensor 
 Return type 
 Tensor 
 Example: 
",">>> torch.histc(torch.tensor([1.,2,1]),bins=4,min=0,max=3)
tensor([ 0.,  2.,  1.,  0.])
",,,
"
 torch. histogram ( input ,  bins ,  * ,  range ,  weight ,  density ,  out ) ¶","Computes a histogram of the values in a tensor. bins  can be an integer or a 1D tensor. If  bins  is an int, it specifies the number of equal-width bins.
By default, the lower and upper range of the bins is determined by the
minimum and maximum elements of the input tensor. The  range 
argument can be provided to specify a range for the bins. If  bins  is a 1D tensor, it specifies the sequence of bin edges
including the rightmost edge. It should contain at least 2 elements
and its elements should be increasing. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 1D Tensor containing the values of the histogram.
bin_edges(Tensor): 1D Tensor containing the edges of the histogram bins. 
 Return type 
 hist ( 
 Example: 
",">>> torch.histogram(torch.tensor([1.,2,1]),bins=4,range=(0.,3.),weight=torch.tensor([1.,2.,4.]))
(tensor([ 0.,  5.,  2.,  0.]), tensor([0., 0.75, 1.5, 2.25, 3.]))
>>> torch.histogram(torch.tensor([1.,2,1]),bins=4,range=(0.,3.),weight=torch.tensor([1.,2.,4.]),density=True)
(tensor([ 0.,  0.9524,  0.3810,  0.]), tensor([0., 0.75, 1.5, 2.25, 3.]))
",,,
"
 torch. histogramdd ( input ,  bins ,  * ,  range=None ,  weight=None ,  density=False ,  out=None) ,  Tensor[] ) ¶","Computes a multi-dimensional histogram of the values in a tensor. Interprets the elements of an input tensor whose innermost dimension has size N
as a collection of N-dimensional points. Maps each of the points into a set of
N-dimensional bins and returns the number of points (or total weight) in each bin. input  must be a tensor with at least 2 dimensions.
If input has shape (M, N), each of its M rows defines a point in N-dimensional space.
If input has three or more dimensions, all but the last dimension are flattened. Each dimension is independently associated with its own strictly increasing sequence
of bin edges. Bin edges may be specified explicitly by passing a sequence of 1D
tensors. Alternatively, bin edges may be constructed automatically by passing a
sequence of integers specifying the number of equal-width bins in each dimension. 
 For each N-dimensional point in input: 
 
 bins  can be a sequence of N 1D tensors, a sequence of N ints, or a single int. If  bins  is a sequence of N 1D tensors, it explicitly specifies the N sequences
of bin edges. Each 1D tensor should contain a strictly increasing sequence with at
least one element. A sequence of K bin edges defines K-1 bins, explicitly specifying
the left and right edges of all bins. Every bin is exclusive of its left edge. Only
the rightmost bin is inclusive of its right edge. If  bins  is a sequence of N ints, it specifies the number of equal-width bins
in each dimension. By default, the leftmost and rightmost bin edges in each dimension
are determined by the minimum and maximum elements of the input tensor in the
corresponding dimension. The  range  argument can be provided to manually
specify the leftmost and rightmost bin edges in each dimension. If  bins  is an int, it specifies the number of equal-width bins for all dimensions. 
 Note 
 See also  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 N-dimensional Tensor containing the values of the histogram.
bin_edges(Tensor[]): sequence of N 1D Tensors containing the bin edges. 
 Return type 
 hist ( 
 
 Example:: 
",,,,
"
 torch. meshgrid ( * ,  indexing ) [source] ¶","Creates grids of coordinates specified by the 1D inputs in  attr :tensors. This is helpful when you want to visualize data over some
range of inputs. See below for a plotting example. Given  N  1D tensors  T  as
inputs with corresponding sizes  S ,
this creates  N  N-dimensional tensors  G , each with shape  (  where
the output  G  is constructed by expanding  T 
to the result shape. 
 Note 
 0D inputs are treated equivalently to 1D inputs of a
single element. 
 
 Warning 
 torch.meshgrid(*tensors) 
 In the future  
 https://github.com/pytorch/pytorch/issues/50276 
 
 See also 
 torch.cartesian_prod() 
 
 Parameters 
 
 
 Returns 
 If the input has  
 Return type 
 seq (sequence of Tensors) 
 Example: 
",">>> x=torch.tensor([1,2,3])
>>> y=torch.tensor([4,5,6])Observe the element-wise pairings across the grid, (1, 4),
(1, 5), ..., (3, 6). This is the same thing as the
cartesian product.
>>> grid_x,grid_y=torch.meshgrid(x,y,indexing='ij')
>>> grid_x
tensor([[1, 1, 1],
        [2, 2, 2],
        [3, 3, 3]])
>>> grid_y
tensor([[4, 5, 6],
        [4, 5, 6],
        [4, 5, 6]])This correspondence can be seen when these grids are
stacked properly.
>>> torch.equal(torch.cat(tuple(torch.dstack([grid_x,grid_y]))),
... torch.cartesian_prod(x,y))
True`torch.meshgrid` is commonly used to produce a grid for
plotting.
>>> importmatplotlib.pyplotasplt
>>> xs=torch.linspace(-5,5,steps=100)
>>> ys=torch.linspace(-5,5,steps=100)
>>> x,y=torch.meshgrid(xs,ys,indexing='xy')
>>> z=torch.sin(torch.sqrt(x*x+y*y))
>>> ax=plt.axes(projection='3d')
>>> ax.plot_surface(x.numpy(),y.numpy(),z.numpy())
>>> plt.show()
",,,
"
 torch. lcm ( input ,  other ,  * ,  out )   → ¶","Computes the element-wise least common multiple (LCM) of  input  and  other . Both  input  and  other  must have integer types. 
 Note 
 This defines  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([5,10,15])
>>> b=torch.tensor([3,4,5])
>>> torch.lcm(a,b)
tensor([15, 20, 15])
>>> c=torch.tensor([3])
>>> torch.lcm(a,c)
tensor([15, 30, 15])
",,,
"
 torch. logcumsumexp ( input ,  dim ,  * ,  out )   → ¶","Returns the logarithm of the cumulative summation of the exponentiation of
elements of  input  in the dimension  dim . For summation index  j  given by  dim  and other indices  i , the result is 
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(10)
>>> torch.logcumsumexp(a,dim=0)
tensor([-0.42296738, -0.04462666,  0.86278635,  0.94622083,  1.05277811,
         1.39202815,  1.83525007,  1.84492621,  2.06084887,  2.06844475]))
",,,
"
 torch. ravel ( input )   → ¶","Return a contiguous flattened tensor. A copy is made only if needed. 
 Parameters 
 input 
 Example: 
",">>> t=torch.tensor([[[1,2],
... [3,4]],
... [[5,6],
... [7,8]]])
>>> torch.ravel(t)
tensor([1, 2, 3, 4, 5, 6, 7, 8])
",,,
"
 torch. renorm ( input ,  p ,  dim ,  maxnorm ,  * ,  out )   → ¶","Returns a tensor where each sub-tensor of  input  along dimension
 dim  is normalized such that the  p -norm of the sub-tensor is lower
than the value  maxnorm 
 Note 
 If the norm of a row is lower than  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> x=torch.ones(3,3)
>>> x[1].fill_(2)
tensor([ 2.,  2.,  2.])
>>> x[2].fill_(3)
tensor([ 3.,  3.,  3.])
>>> x
tensor([[ 1.,  1.,  1.],
        [ 2.,  2.,  2.],
        [ 3.,  3.,  3.]])
>>> torch.renorm(x,1,0,5)
tensor([[ 1.0000,  1.0000,  1.0000],
        [ 1.6667,  1.6667,  1.6667],
        [ 1.6667,  1.6667,  1.6667]])
",,,
"
 torch. repeat_interleave ( input ,  repeats ,  dim ,  * ,  output_size )   → ¶","Repeat elements of a tensor. 
 Warning 
 This is different from  
 
 Parameters 
 
 
 Keyword Arguments 
 output_size 
 Returns 
 Repeated tensor which has the same shape as input, except along the given axis. 
 Return type 
 Tensor 
 Example: 
 
 
 
 If the  repeats  is  tensor([n1, n2, n3, …]) , then the output will be
 tensor([0, 0, …, 1, 1, …, 2, 2, …, …])  where  0  appears  n1  times,
 1  appears  n2  times,  2  appears  n3  times, etc.",">>> x=torch.tensor([1,2,3])
>>> x.repeat_interleave(2)
tensor([1, 1, 2, 2, 3, 3])
>>> y=torch.tensor([[1,2],[3,4]])
>>> torch.repeat_interleave(y,2)
tensor([1, 1, 2, 2, 3, 3, 4, 4])
>>> torch.repeat_interleave(y,3,dim=1)
tensor([[1, 1, 1, 2, 2, 2],
        [3, 3, 3, 4, 4, 4]])
>>> torch.repeat_interleave(y,torch.tensor([1,2]),dim=0)
tensor([[1, 2],
        [3, 4],
        [3, 4]])
>>> torch.repeat_interleave(y,torch.tensor([1,2]),dim=0,output_size=3)
tensor([[1, 2],
        [3, 4],
        [3, 4]])
",,,
"
 torch. roll ( input ,  shifts ,  dims )   → ¶","Roll the tensor  input  along the given dimension(s). Elements that are
shifted beyond the last position are re-introduced at the first position. If
 dims  is  None , the tensor will be flattened before rolling and then
restored to the original shape. 
 Parameters 
 
 
 Example: 
",">>> x=torch.tensor([1,2,3,4,5,6,7,8]).view(4,2)
>>> x
tensor([[1, 2],
        [3, 4],
        [5, 6],
        [7, 8]])
>>> torch.roll(x,1)
tensor([[8, 1],
        [2, 3],
        [4, 5],
        [6, 7]])
>>> torch.roll(x,1,0)
tensor([[7, 8],
        [1, 2],
        [3, 4],
        [5, 6]])
>>> torch.roll(x,-1,0)
tensor([[3, 4],
        [5, 6],
        [7, 8],
        [1, 2]])
>>> torch.roll(x,shifts=(2,1),dims=(0,1))
tensor([[6, 5],
        [8, 7],
        [2, 1],
        [4, 3]])
",,,
"
 torch. searchsorted ( sorted_sequence ,  values ,  * ,  out_int32 ,  right ,  side ,  out ,  sorter )   → ¶","Find the indices from the  innermost  dimension of  sorted_sequence  such that, if the
corresponding values in  values  were inserted before the indices, when sorted, the order
of the corresponding  innermost  dimension within  sorted_sequence  would be preserved.
Return a new tensor with the same size as  values . If  right  is False or side is
‘left (default), then the left boundary of  sorted_sequence  is closed. More formally,
the returned index satisfies the following rules: 
 
 
 
 
 
 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> sorted_sequence=torch.tensor([[1,3,5,7,9],[2,4,6,8,10]])
>>> sorted_sequence
tensor([[ 1,  3,  5,  7,  9],
        [ 2,  4,  6,  8, 10]])
>>> values=torch.tensor([[3,6,9],[3,6,9]])
>>> values
tensor([[3, 6, 9],
        [3, 6, 9]])
>>> torch.searchsorted(sorted_sequence,values)
tensor([[1, 3, 4],
        [1, 2, 4]])
>>> torch.searchsorted(sorted_sequence,values,side='right')
tensor([[2, 3, 5],
        [1, 3, 4]])>>> sorted_sequence_1d=torch.tensor([1,3,5,7,9])
>>> sorted_sequence_1d
tensor([1, 3, 5, 7, 9])
>>> torch.searchsorted(sorted_sequence_1d,values)
tensor([[1, 3, 4],
        [1, 3, 4]])
",,,
"
 torch. tensordot ( a ,  b ,  dims ,  out ) [source] ¶","Returns a contraction of a and b over multiple dimensions. tensordot  implements a generalized matrix product. 
 Parameters 
 
 
 When called with a non-negative integer argument  dims  =  d , and
the number of dimensions of  a  and  b  is  m  and  n ,
respectively,  tensordot()  computes 
 r When called with  dims  of the list form, the given dimensions will be contracted
in place of the last  d  of  a  and the first  d  of  b . The sizes
in these dimensions must match, but  tensordot()  will deal with broadcasted
dimensions. Examples: 
",">>> a=torch.arange(60.).reshape(3,4,5)
>>> b=torch.arange(24.).reshape(4,3,2)
>>> torch.tensordot(a,b,dims=([1,0],[0,1]))
tensor([[4400., 4730.],
        [4532., 4874.],
        [4664., 5018.],
        [4796., 5162.],
        [4928., 5306.]])>>> a=torch.randn(3,4,5,device='cuda')
>>> b=torch.randn(4,5,6,device='cuda')
>>> c=torch.tensordot(a,b,dims=2).cpu()
tensor([[ 8.3504, -2.5436,  6.2922,  2.7556, -1.0732,  3.2741],
        [ 3.3161,  0.0704,  5.0187, -0.4079, -4.3126,  4.8744],
        [ 0.8223,  3.9445,  3.2168, -0.2400,  3.4117,  1.7780]])>>> a=torch.randn(3,5,4,6)
>>> b=torch.randn(6,4,5,3)
>>> torch.tensordot(a,b,dims=([2,1,3],[1,2,0]))
tensor([[  7.7193,  -2.4867, -10.3204],
        [  1.5513, -14.4737,  -6.5113],
        [ -0.2850,   4.2573,  -3.5997]])
",,,
"
 torch. trace ( input )   → ¶","Returns the sum of the elements of the diagonal of the input 2-D matrix. Example: 
",">>> x=torch.arange(1.,10.).view(3,3)
>>> x
tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.],
        [ 7.,  8.,  9.]])
>>> torch.trace(x)
tensor(15.)
",,,
"
 torch. tril ( input ,  diagonal ,  * ,  out )   → ¶","Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices
 input , the other elements of the result tensor  out  are set to 0. The lower triangular part of the matrix is defined as the elements on and
below the diagonal. The argument  diagonal  controls which diagonal to consider. If
 diagonal  = 0, all elements on and below the main diagonal are
retained. A positive value includes just as many diagonals above the main
diagonal, and similarly a negative value excludes just as many diagonals below
the main diagonal. The main diagonal are the set of indices
 {  for  i  where
 d  are the dimensions of the matrix. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(3,3)
>>> a
tensor([[-1.0813, -0.8619,  0.7105],
        [ 0.0935,  0.1380,  2.2112],
        [-0.3409, -0.9828,  0.0289]])
>>> torch.tril(a)
tensor([[-1.0813,  0.0000,  0.0000],
        [ 0.0935,  0.1380,  0.0000],
        [-0.3409, -0.9828,  0.0289]])>>> b=torch.randn(4,6)
>>> b
tensor([[ 1.2219,  0.5653, -0.2521, -0.2345,  1.2544,  0.3461],
        [ 0.4785, -0.4477,  0.6049,  0.6368,  0.8775,  0.7145],
        [ 1.1502,  3.2716, -1.1243, -0.5413,  0.3615,  0.6864],
        [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024,  0.0978]])
>>> torch.tril(b,diagonal=1)
tensor([[ 1.2219,  0.5653,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.4785, -0.4477,  0.6049,  0.0000,  0.0000,  0.0000],
        [ 1.1502,  3.2716, -1.1243, -0.5413,  0.0000,  0.0000],
        [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024,  0.0000]])
>>> torch.tril(b,diagonal=-1)
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.4785,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
        [ 1.1502,  3.2716,  0.0000,  0.0000,  0.0000,  0.0000],
        [-0.0614, -0.7344, -1.3164,  0.0000,  0.0000,  0.0000]])
",,,
"
 torch. tril_indices ( row ,  col ,  offset ,  * ,  dtype ,  device ,  layout )   → ¶","Returns the indices of the lower triangular part of a  row -by-
 col  matrix in a 2-by-N Tensor, where the first row contains row
coordinates of all indices and the second row contains column coordinates.
Indices are ordered based on rows and then columns. The lower triangular part of the matrix is defined as the elements on and
below the diagonal. The argument  offset  controls which diagonal to consider. If
 offset  = 0, all elements on and below the main diagonal are
retained. A positive value includes just as many diagonals above the main
diagonal, and similarly a negative value excludes just as many diagonals below
the main diagonal. The main diagonal are the set of indices
 {  for  i 
where  d  are the dimensions of the matrix. 
 Note 
 When running on CUDA,  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> a=torch.tril_indices(3,3)
>>> a
tensor([[0, 1, 1, 2, 2, 2],
        [0, 0, 1, 0, 1, 2]])>>> a=torch.tril_indices(4,3,-1)
>>> a
tensor([[1, 2, 2, 3, 3, 3],
        [0, 0, 1, 0, 1, 2]])>>> a=torch.tril_indices(4,3,1)
>>> a
tensor([[0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],
        [0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2]])
",,,
"
 torch. triu ( input ,  diagonal ,  * ,  out )   → ¶","Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices
 input , the other elements of the result tensor  out  are set to 0. The upper triangular part of the matrix is defined as the elements on and
above the diagonal. The argument  diagonal  controls which diagonal to consider. If
 diagonal  = 0, all elements on and above the main diagonal are
retained. A positive value excludes just as many diagonals above the main
diagonal, and similarly a negative value includes just as many diagonals below
the main diagonal. The main diagonal are the set of indices
 {  for  i  where
 d  are the dimensions of the matrix. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(3,3)
>>> a
tensor([[ 0.2309,  0.5207,  2.0049],
        [ 0.2072, -1.0680,  0.6602],
        [ 0.3480, -0.5211, -0.4573]])
>>> torch.triu(a)
tensor([[ 0.2309,  0.5207,  2.0049],
        [ 0.0000, -1.0680,  0.6602],
        [ 0.0000,  0.0000, -0.4573]])
>>> torch.triu(a,diagonal=1)
tensor([[ 0.0000,  0.5207,  2.0049],
        [ 0.0000,  0.0000,  0.6602],
        [ 0.0000,  0.0000,  0.0000]])
>>> torch.triu(a,diagonal=-1)
tensor([[ 0.2309,  0.5207,  2.0049],
        [ 0.2072, -1.0680,  0.6602],
        [ 0.0000, -0.5211, -0.4573]])>>> b=torch.randn(4,6)
>>> b
tensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],
        [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],
        [ 0.4333,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],
        [-0.9888,  1.0679, -1.3337, -1.6556,  0.4798,  0.2830]])
>>> torch.triu(b,diagonal=1)
tensor([[ 0.0000, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],
        [ 0.0000,  0.0000, -1.2919,  1.3378, -0.1768, -1.0857],
        [ 0.0000,  0.0000,  0.0000, -1.0432,  0.9348, -0.4410],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4798,  0.2830]])
>>> torch.triu(b,diagonal=-1)
tensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],
        [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],
        [ 0.0000,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],
        [ 0.0000,  0.0000, -1.3337, -1.6556,  0.4798,  0.2830]])
",,,
"
 torch. triu_indices ( row ,  col ,  offset ,  * ,  dtype ,  device ,  layout )   → ¶","Returns the indices of the upper triangular part of a  row  by
 col  matrix in a 2-by-N Tensor, where the first row contains row
coordinates of all indices and the second row contains column coordinates.
Indices are ordered based on rows and then columns. The upper triangular part of the matrix is defined as the elements on and
above the diagonal. The argument  offset  controls which diagonal to consider. If
 offset  = 0, all elements on and above the main diagonal are
retained. A positive value excludes just as many diagonals above the main
diagonal, and similarly a negative value includes just as many diagonals below
the main diagonal. The main diagonal are the set of indices
 {  for  i 
where  d  are the dimensions of the matrix. 
 Note 
 When running on CUDA,  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> a=torch.triu_indices(3,3)
>>> a
tensor([[0, 0, 0, 1, 1, 2],
        [0, 1, 2, 1, 2, 2]])>>> a=torch.triu_indices(4,3,-1)
>>> a
tensor([[0, 0, 0, 1, 1, 1, 2, 2, 3],
        [0, 1, 2, 0, 1, 2, 1, 2, 2]])>>> a=torch.triu_indices(4,3,1)
>>> a
tensor([[0, 0, 1],
        [1, 2, 2]])
",,,
"
 torch. unflatten ( input ,  dim ,  sizes )   → ¶","Expands a dimension of the input tensor over multiple dimensions. 
 See also 
 torch.flatten() 
 
 Parameters 
 
 
 Returns 
 A View of input with the specified dimension unflattened. 
 
 Examples:: 
",,,,
"
 torch. vander ( x ,  N ,  increasing )   → ¶","Generates a Vandermonde matrix. The columns of the output matrix are elementwise powers of the input vector  x .
If increasing is True, the order of the columns is reversed  x . Such a
matrix with a geometric progression in each row is named for Alexandre-Theophile Vandermonde. 
 Parameters 
 
 
 Returns 
 Vandermonde matrix. If increasing is False, the first column is  
 Return type 
 Tensor 
 Example: 
",">>> x=torch.tensor([1,2,3,5])
>>> torch.vander(x)
tensor([[  1,   1,   1,   1],
        [  8,   4,   2,   1],
        [ 27,   9,   3,   1],
        [125,  25,   5,   1]])
>>> torch.vander(x,N=3)
tensor([[ 1,  1,  1],
        [ 4,  2,  1],
        [ 9,  3,  1],
        [25,  5,  1]])
>>> torch.vander(x,N=3,increasing=True)
tensor([[ 1,  1,  1],
        [ 1,  2,  4],
        [ 1,  3,  9],
        [ 1,  5, 25]])
",,,
"
 torch. view_as_real ( input )   → ¶","Returns a view of  input  as a real tensor. For an input complex tensor of
 size   m , this function returns a new
real tensor of size  m , where the last dimension of size 2
represents the real and imaginary components of complex numbers. 
 Warning 
 view_as_real() 
 
 Parameters 
 input 
 Example: 
",">>> x=torch.randn(4,dtype=torch.cfloat)
>>> x
tensor([(0.4737-0.3839j), (-0.2098-0.6699j), (0.3470-0.9451j), (-0.5174-1.3136j)])
>>> torch.view_as_real(x)
tensor([[ 0.4737, -0.3839],
        [-0.2098, -0.6699],
        [ 0.3470, -0.9451],
        [-0.5174, -1.3136]])
",,,
"
 torch. view_as_complex ( input )   → ¶","Returns a view of  input  as a complex tensor. For an input complex
tensor of  size   m , this function returns a
new complex tensor of  size   m  where the last
dimension of the input tensor is expected to represent the real and imaginary
components of complex numbers. 
 Warning 
 view_as_complex() 
 
 Parameters 
 input 
 Example: 
",">>> x=torch.randn(4,2)
>>> x
tensor([[ 1.6116, -0.5772],
        [-1.4606, -0.9120],
        [ 0.0786, -1.7497],
        [-0.6561, -1.6623]])
>>> torch.view_as_complex(x)
tensor([(1.6116-0.5772j), (-1.4606-0.9120j), (0.0786-1.7497j), (-0.6561-1.6623j)])
",,,
"
 torch. resolve_conj ( input )   → ¶","Returns a new tensor with materialized conjugation if  input ’s conjugate bit is set to  True ,
else returns  input . The output tensor will always have its conjugate bit set to  False . 
 Parameters 
 input 
 Example: 
",">>> x=torch.tensor([-1+1j,-2+2j,3-3j])
>>> y=x.conj()
>>> y.is_conj()
True
>>> z=y.resolve_conj()
>>> z
tensor([-1 - 1j, -2 - 2j, 3 + 3j])
>>> z.is_conj()
False
",,,
"
 torch. resolve_neg ( input )   → ¶","Returns a new tensor with materialized negation if  input ’s negative bit is set to  True ,
else returns  input . The output tensor will always have its negative bit set to  False .
:param input: the input tensor.
:type input: Tensor Example: 
",">>> x=torch.tensor([-1+1j,-2+2j,3-3j])
>>> y=x.conj()
>>> z=y.imag
>>> z.is_neg()
True
>>> out=y.resolve_neg()
>>> out
tensor([-1, -2, -3])
>>> out.is_neg()
False
",,,
"
 torch. addbmm ( input ,  batch1 ,  batch2 ,  * ,  beta ,  alpha ,  out )   → ¶","Performs a batch matrix-matrix product of matrices stored
in  batch1  and  batch2 ,
with a reduced add step (all matrix multiplications get accumulated
along the first dimension).
 input  is added to the final result. batch1  and  batch2  must be 3-D tensors each containing the
same number of matrices. If  batch1  is a  (  tensor,  batch2  is a
 (  tensor,  input  must be
 broadcastable  with a  (  tensor
and  out  will be a  (  tensor. 
 o If  beta  is 0, then  input  will be ignored, and  nan  and  inf  in
it will not be propagated. For inputs of type  FloatTensor  or  DoubleTensor , arguments  beta  and  alpha 
must be real numbers, otherwise they should be integers. This operator supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> M=torch.randn(3,5)
>>> batch1=torch.randn(10,3,4)
>>> batch2=torch.randn(10,4,5)
>>> torch.addbmm(M,batch1,batch2)
tensor([[  6.6311,   0.0503,   6.9768, -12.0362,  -2.1653],
        [ -4.8185,  -1.4255,  -6.6760,   8.9453,   2.5743],
        [ -3.8202,   4.3691,   1.0943,  -1.1109,   5.4730]])
",,,
"
 torch. addmm ( input ,  mat1 ,  mat2 ,  * ,  beta ,  alpha ,  out )   → ¶","Performs a matrix multiplication of the matrices  mat1  and  mat2 .
The matrix  input  is added to the final result. If  mat1  is a  (  tensor,  mat2  is a
 (  tensor, then  input  must be
 broadcastable  with a  (  tensor
and  out  will be a  (  tensor. alpha  and  beta  are scaling factors on matrix-vector product between
 mat1  and  mat2  and the added matrix  input  respectively. 
 out If  beta  is 0, then  input  will be ignored, and  nan  and  inf  in
it will not be propagated. For inputs of type  FloatTensor  or  DoubleTensor , arguments  beta  and
 alpha  must be real numbers, otherwise they should be integers. This operation has support for arguments with  sparse layouts . If
 input  is sparse the result will have the same layout and if  out 
is provided it must have the same layout as  input . 
 Warning 
 Sparse support is a beta feature and some layout(s)/dtype/device combinations may not be supported,
or may not have autograd support. If you notice missing functionality please
open a feature request. 
 This operator supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> M=torch.randn(2,3)
>>> mat1=torch.randn(2,3)
>>> mat2=torch.randn(3,3)
>>> torch.addmm(M,mat1,mat2)
tensor([[-4.8716,  1.4671, -1.3746],
        [ 0.7573, -3.9555, -2.8681]])
",,,
"
 torch. addmv ( input ,  mat ,  vec ,  * ,  beta ,  alpha ,  out )   → ¶","Performs a matrix-vector product of the matrix  mat  and
the vector  vec .
The vector  input  is added to the final result. If  mat  is a  (  tensor,  vec  is a 1-D tensor of
size  m , then  input  must be
 broadcastable  with a 1-D tensor of size  n  and
 out  will be 1-D tensor of size  n . alpha  and  beta  are scaling factors on matrix-vector product between
 mat  and  vec  and the added tensor  input  respectively. 
 out If  beta  is 0, then  input  will be ignored, and  nan  and  inf  in
it will not be propagated. For inputs of type  FloatTensor  or  DoubleTensor , arguments  beta  and
 alpha  must be real numbers, otherwise they should be integers 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> M=torch.randn(2)
>>> mat=torch.randn(2,3)
>>> vec=torch.randn(3)
>>> torch.addmv(M,mat,vec)
tensor([-0.3768, -5.5565])
",,,
"
 torch. addr ( input ,  vec1 ,  vec2 ,  * ,  beta ,  alpha ,  out )   → ¶","Performs the outer-product of vectors  vec1  and  vec2 
and adds it to the matrix  input . Optional values  beta  and  alpha  are scaling factors on the
outer product between  vec1  and  vec2  and the added matrix
 input  respectively. 
 out If  beta  is 0, then  input  will be ignored, and  nan  and  inf  in
it will not be propagated. If  vec1  is a vector of size  n  and  vec2  is a vector
of size  m , then  input  must be
 broadcastable  with a matrix of size
 (  and  out  will be a matrix of size
 ( . 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> vec1=torch.arange(1.,4.)
>>> vec2=torch.arange(1.,3.)
>>> M=torch.zeros(3,2)
>>> torch.addr(M,vec1,vec2)
tensor([[ 1.,  2.],
        [ 2.,  4.],
        [ 3.,  6.]])
",,,
"
 torch. baddbmm ( input ,  batch1 ,  batch2 ,  * ,  beta ,  alpha ,  out )   → ¶","Performs a batch matrix-matrix product of matrices in  batch1 
and  batch2 .
 input  is added to the final result. batch1  and  batch2  must be 3-D tensors each containing the same
number of matrices. If  batch1  is a  (  tensor,  batch2  is a
 (  tensor, then  input  must be
 broadcastable  with a
 (  tensor and  out  will be a
 (  tensor. Both  alpha  and  beta  mean the
same as the scaling factors used in  torch.addbmm() . 
 out If  beta  is 0, then  input  will be ignored, and  nan  and  inf  in
it will not be propagated. For inputs of type  FloatTensor  or  DoubleTensor , arguments  beta  and
 alpha  must be real numbers, otherwise they should be integers. This operator supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example: 
",">>> M=torch.randn(10,3,5)
>>> batch1=torch.randn(10,3,4)
>>> batch2=torch.randn(10,4,5)
>>> torch.baddbmm(M,batch1,batch2).size()
torch.Size([10, 3, 5])
",,,
"
 torch. bmm ( input ,  mat2 ,  * ,  out )   → ¶","Performs a batch matrix-matrix product of matrices stored in  input 
and  mat2 . input  and  mat2  must be 3-D tensors each containing
the same number of matrices. If  input  is a  (  tensor,  mat2  is a
 (  tensor,  out  will be a
 (  tensor. 
 out This operator supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 Note 
 This function does not  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> input=torch.randn(10,3,4)
>>> mat2=torch.randn(10,4,5)
>>> res=torch.bmm(input,mat2)
>>> res.size()
torch.Size([10, 3, 5])
",,,
"
 torch. chain_matmul ( * ,  out ) [source] ¶","Returns the matrix product of the  N  2-D tensors. This product is efficiently computed
using the matrix chain order algorithm which selects the order in which incurs the lowest cost in terms
of arithmetic operations ( [CLRS] ). Note that since this is a function to compute the product,  N 
needs to be greater than or equal to 2; if equal to 2 then a trivial matrix-matrix product is returned.
If  N  is 1, then this is a no-op - the original matrix is returned as is. 
 Warning 
 torch.chain_matmul() 
 
 Parameters 
 
 
 Returns 
 if the  
 Return type 
 Tensor 
 Example: 
",">>> a=torch.randn(3,4)
>>> b=torch.randn(4,5)
>>> c=torch.randn(5,6)
>>> d=torch.randn(6,7)
>>> # will raise a deprecation warning
>>> torch.chain_matmul(a,b,c,d)
tensor([[ -2.3375,  -3.9790,  -4.1119,  -6.6577,   9.5609, -11.5095,  -3.2614],
        [ 21.4038,   3.3378,  -8.4982,  -5.2457, -10.2561,  -2.4684,   2.7163],
        [ -0.9647,  -5.8917,  -2.3213,  -5.2284,  12.8615, -12.2816,  -2.5095]])
",,,
"
 torch. cholesky ( input ,  upper ,  * ,  out )   → ¶","Computes the Cholesky decomposition of a symmetric positive-definite
matrix  A  or for batches of symmetric positive-definite matrices. If  upper  is  True , the returned matrix  U  is upper-triangular, and
the decomposition has the form: 
 A If  upper  is  False , the returned matrix  L  is lower-triangular, and
the decomposition has the form: 
 A If  upper  is  True , and  A  is a batch of symmetric positive-definite
matrices, then the returned tensor will be composed of upper-triangular Cholesky factors
of each of the individual matrices. Similarly, when  upper  is  False , the returned
tensor will be composed of lower-triangular Cholesky factors of each of the individual
matrices. 
 Warning 
 torch.cholesky() 
 L 
 
 U 
 
 This transform will produce equivalent results for all valid (symmetric positive definite) inputs. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(3,3)
>>> a=a@a.mT+1e-3# make symmetric positive-definite
>>> l=torch.cholesky(a)
>>> a
tensor([[ 2.4112, -0.7486,  1.4551],
        [-0.7486,  1.3544,  0.1294],
        [ 1.4551,  0.1294,  1.6724]])
>>> l
tensor([[ 1.5528,  0.0000,  0.0000],
        [-0.4821,  1.0592,  0.0000],
        [ 0.9371,  0.5487,  0.7023]])
>>> l@l.mT
tensor([[ 2.4112, -0.7486,  1.4551],
        [-0.7486,  1.3544,  0.1294],
        [ 1.4551,  0.1294,  1.6724]])
>>> a=torch.randn(3,2,2)# Example for batched input
>>> a=a@a.mT+1e-03# make symmetric positive-definite
>>> l=torch.cholesky(a)
>>> z=l@l.mT
>>> torch.dist(z,a)
tensor(2.3842e-07)
",,,
"
 torch. cholesky_inverse ( input ,  upper ,  * ,  out )   → ¶","Computes the inverse of a symmetric positive-definite matrix  A  using its
Cholesky factor  u : returns matrix  inv . The inverse is computed using
LAPACK routines  dpotri  and  spotri  (and the corresponding MAGMA routines). If  upper  is  False ,  u  is lower triangular
such that the returned tensor is 
 i If  upper  is  True  or not provided,  u  is upper
triangular such that the returned tensor is 
 i Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then the output has the same batch dimensions. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(3,3)
>>> a=torch.mm(a,a.t())+1e-05*torch.eye(3)# make symmetric positive definite
>>> u=torch.linalg.cholesky(a)
>>> a
tensor([[  0.9935,  -0.6353,   1.5806],
        [ -0.6353,   0.8769,  -1.7183],
        [  1.5806,  -1.7183,  10.6618]])
>>> torch.cholesky_inverse(u)
tensor([[ 1.9314,  1.2251, -0.0889],
        [ 1.2251,  2.4439,  0.2122],
        [-0.0889,  0.2122,  0.1412]])
>>> a.inverse()
tensor([[ 1.9314,  1.2251, -0.0889],
        [ 1.2251,  2.4439,  0.2122],
        [-0.0889,  0.2122,  0.1412]])
>>> a=torch.randn(3,2,2)# Example for batched input
>>> a=a@a.mT+1e-03# make symmetric positive-definite
>>> l=torch.linalg.cholesky(a)
>>> z=l@l.mT
>>> torch.dist(z,a)
tensor(3.5894e-07)
",,,
"
 torch. cholesky_solve ( input ,  input2 ,  upper ,  * ,  out )   → ¶","Solves a linear system of equations with a positive semidefinite
matrix to be inverted given its Cholesky factor matrix  u . If  upper  is  False ,  u  is and lower triangular and  c  is
returned such that: 
 c If  upper  is  True  or not provided,  u  is upper triangular
and  c  is returned such that: 
 c torch.cholesky_solve(b, u)  can take in 2D inputs  b, u  or inputs that are
batches of 2D matrices. If the inputs are batches, then returns
batched outputs  c Supports real-valued and complex-valued inputs.
For the complex-valued inputs the transpose operator above is the conjugate transpose. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(3,3)
>>> a=torch.mm(a,a.t())# make symmetric positive definite
>>> u=torch.linalg.cholesky(a)
>>> a
tensor([[ 0.7747, -1.9549,  1.3086],
        [-1.9549,  6.7546, -5.4114],
        [ 1.3086, -5.4114,  4.8733]])
>>> b=torch.randn(3,2)
>>> b
tensor([[-0.6355,  0.9891],
        [ 0.1974,  1.4706],
        [-0.4115, -0.6225]])
>>> torch.cholesky_solve(b,u)
tensor([[ -8.1625,  19.6097],
        [ -5.8398,  14.2387],
        [ -4.3771,  10.4173]])
>>> torch.mm(a.inverse(),b)
tensor([[ -8.1626,  19.6097],
        [ -5.8398,  14.2387],
        [ -4.3771,  10.4173]])
",,,
"
 torch. dot ( input ,  other ,  * ,  out )   → ¶","Computes the dot product of two 1D tensors. 
 Note 
 Unlike NumPy’s dot, torch.dot intentionally only supports computing the dot product
of two 1D tensors with the same number of elements. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> torch.dot(torch.tensor([2,3]),torch.tensor([2,1]))
tensor(7)
",,,
"
 torch. geqrf ( input ,  * ,  out ) ¶","This is a low-level function for calling LAPACK’s geqrf directly. This function
returns a namedtuple (a, tau) as defined in  LAPACK documentation for geqrf  . Computes a QR decomposition of  input .
Both  Q  and  R  matrices are stored in the same output tensor  a .
The elements of  R  are stored on and above the diagonal.
Elementary reflectors (or Householder vectors) implicitly defining matrix  Q 
are stored below the diagonal.
The results of this function can be used together with  torch.linalg.householder_product() 
to obtain the  Q  matrix or
with  torch.ormqr() , which uses an implicit representation of the  Q  matrix,
for an efficient matrix-matrix multiplication. See  LAPACK documentation for geqrf  for further details. 
 Note 
 See also  
 
 Parameters 
 input 
 Keyword Arguments 
 out 
",,,,
"
 torch. ger ( input ,  vec2 ,  * ,  out )   → ¶","Alias of  torch.outer() . 
 Warning 
 This function is deprecated and will be removed in a future PyTorch release.
Use  
",,,,
"
 torch. outer ( input ,  vec2 ,  * ,  out )   → ¶","Outer product of  input  and  vec2 .
If  input  is a vector of size  n  and  vec2  is a vector of
size  m , then  out  must be a matrix of size  ( . 
 Note 
 This function does not  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> v1=torch.arange(1.,5.)
>>> v2=torch.arange(1.,4.)
>>> torch.outer(v1,v2)
tensor([[  1.,   2.,   3.],
        [  2.,   4.,   6.],
        [  3.,   6.,   9.],
        [  4.,   8.,  12.]])
",,,
"
 torch. inner ( input ,  other ,  * ,  out )   → ¶","Computes the dot product for 1D tensors. For higher dimensions, sums the product
of elements from  input  and  other  along their last dimension. 
 Note 
 If either  
 If both  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
","# Dot product
>>>torch.inner(torch.tensor([1,2,3]),torch.tensor([0,2,1]))
tensor(7)# Multidimensional input tensors
>>>a=torch.randn(2,3)
>>>a
tensor([[0.8173,1.0874,1.1784],[0.3279,0.1234,2.7894]])
>>>b=torch.randn(2,4,3)
>>>b
tensor([[[-0.4682,-0.7159,0.1506],[0.4034,-0.3657,1.0387],[0.9892,-0.6684,0.1774],[0.9482,1.3261,0.3917]],[[0.4537,0.7493,1.1724],[0.2291,0.5749,-0.2267],[-0.7920,0.3607,-0.3701],[1.3666,-0.5850,-1.7242]]])
>>>torch.inner(a,b)
tensor([[[-0.9837,1.1560,0.2907,2.6785],[2.5671,0.5452,-0.6912,-1.5509]],[[0.1782,2.9843,0.7366,1.5672],[3.5115,-0.4864,-1.2476,-4.4337]]])# Scalar input
>>>torch.inner(a,torch.tensor(2))
tensor([[1.6347,2.1748,2.3567],[0.6558,0.2469,5.5787]])
",,,
"
 torch. inverse ( input ,  * ,  out )   → ¶",Alias for  torch.linalg.inv(),,,,
"
 torch.linalg. inv ( A ,  * ,  out )   → ¶","Computes the inverse of a square matrix if it exists.
Throws a  RuntimeError  if the matrix is not invertible. Letting  K  be  R  or  C ,
for a matrix  A ,
its  inverse matrix   A  (if it exists) is defined as 
 A where  I  is the  n -dimensional identity matrix. The inverse matrix exists if and only if  A  is  invertible . In this case,
the inverse is unique. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices
then the output has the same batch dimensions. 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU. 
 
 Note 
 Consider using  
 
 It is always prefered to use  
 
 See also 
 torch.linalg.pinv() 
 torch.linalg.solve() 
 
 Parameters 
 A 
 Keyword Arguments 
 out 
 Raises 
 RuntimeError 
 Examples: 
",">>> A=torch.randn(4,4)
>>> Ainv=torch.linalg.inv(A)
>>> torch.dist(A@Ainv,torch.eye(4))
tensor(1.1921e-07)>>> A=torch.randn(2,3,4,4)# Batch of matrices
>>> Ainv=torch.linalg.inv(A)
>>> torch.dist(A@Ainv,torch.eye(4))
tensor(1.9073e-06)>>> A=torch.randn(4,4,dtype=torch.complex128)# Complex matrix
>>> Ainv=torch.linalg.inv(A)
>>> torch.dist(A@Ainv,torch.eye(4))
tensor(7.5107e-16, dtype=torch.float64)
",,,
"
 torch. det ( input )   → ¶",Alias for  torch.linalg.det(),,,,
"
 torch.linalg. det ( A ,  * ,  out )   → ¶","Computes the determinant of a square matrix. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. 
 See also 
 torch.linalg.slogdet() 
 
 Parameters 
 A 
 Keyword Arguments 
 out 
 Examples: 
",">>> A=torch.randn(3,3)
>>> torch.linalg.det(A)
tensor(0.0934)>>> A=torch.randn(3,2,2)
>>> torch.linalg.det(A)
tensor([1.1990, 0.4099, 0.7386])
",,,
"
 torch. logdet ( input )   → ¶","Calculates log determinant of a square matrix or batches of square matrices. It returns  -inf  if the input has a determinant of zero, and  NaN  if it has
a negative determinant. 
 Note 
 Backward through  
 
 See also 
 torch.linalg.slogdet() 
 
 Parameters 
 input 
 Example: 
",">>> A=torch.randn(3,3)
>>> torch.det(A)
tensor(0.2611)
>>> torch.logdet(A)
tensor(-1.3430)
>>> A
tensor([[[ 0.9254, -0.6213],
         [-0.5787,  1.6843]],        [[ 0.3242, -0.9665],
         [ 0.4539, -0.0887]],        [[ 1.1336, -0.4025],
         [-0.7089,  0.9032]]])
>>> A.det()
tensor([1.1990, 0.4099, 0.7386])
>>> A.det().log()
tensor([ 0.1815, -0.8917, -0.3031])
",,,
"
 torch. slogdet ( input ) ¶",Alias for  torch.linalg.slogdet(),,,,
"
 torch.linalg. slogdet ( A ,  * ,  out ) ¶","Computes the sign and natural logarithm of the absolute value of the determinant of a square matrix. For complex  A , it returns the angle and the natural logarithm of the modulus of the
determinant, that is, a logarithmic polar decomposition of the determinant. The determinant can be recovered as  sign * exp(logabsdet) .
When a matrix has a determinant of zero, it returns  (0, -inf) . Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. 
 See also 
 torch.linalg.det() 
 
 Parameters 
 A 
 Keyword Arguments 
 out 
 Returns 
 A named tuple  
 Examples: 
",">>> A=torch.randn(3,3)
>>> A
tensor([[ 0.0032, -0.2239, -1.1219],
        [-0.6690,  0.1161,  0.4053],
        [-1.6218, -0.9273, -0.0082]])
>>> torch.linalg.det(A)
tensor(-0.7576)
>>> torch.logdet(A)
tensor(nan)
>>> torch.linalg.slogdet(A)
torch.return_types.linalg_slogdet(sign=tensor(-1.), logabsdet=tensor(-0.2776))
",,,
"
 torch. lu ( * ,  ** ) ¶","Computes the LU factorization of a matrix or batches of matrices
 A . Returns a tuple containing the LU factorization and
pivots of  A .  Pivoting is done if  pivot  is set to
 True . 
 Warning 
 torch.lu() 
 
 LU, 
 
 
 Note 
 
 
 
 Warning 
 The gradients of this function will only be finite when  
 
 Parameters 
 
 
 Returns 
 A tuple of tensors containing 
 Return type 
 ( 
 Example: 
",">>> A=torch.randn(2,3,3)
>>> A_LU,pivots=torch.lu(A)
>>> A_LU
tensor([[[ 1.3506,  2.5558, -0.0816],
         [ 0.1684,  1.1551,  0.1940],
         [ 0.1193,  0.6189, -0.5497]],        [[ 0.4526,  1.2526, -0.3285],
         [-0.7988,  0.7175, -0.9701],
         [ 0.2634, -0.9255, -0.3459]]])
>>> pivots
tensor([[ 3,  3,  3],
        [ 3,  3,  3]], dtype=torch.int32)
>>> A_LU,pivots,info=torch.lu(A,get_infos=True)
>>> ifinfo.nonzero().size(0)==0:
... print('LU factorization succeeded for all samples!')
LU factorization succeeded for all samples!
",,,
"
 torch. lu_solve ( b ,  LU_data ,  LU_pivots ,  * ,  out )   → ¶","Returns the LU solve of the linear system  A  using the partially pivoted
LU factorization of A from  lu_factor() . This function supports  float ,  double ,  cfloat  and  cdouble  dtypes for  input . 
 Warning 
 torch.lu_solve() 
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> A=torch.randn(2,3,3)
>>> b=torch.randn(2,3,1)
>>> LU,pivots=torch.linalg.lu_factor(A)
>>> x=torch.lu_solve(b,LU,pivots)
>>> torch.dist(A@x,b)
tensor(1.00000e-07 *
       2.8312)
",,,
"
 torch.linalg. lu_factor ( A ,  * ,  bool ,  out=None) ,  Tensor ) ¶","Computes a compact representation of the LU factorization with partial pivoting of a matrix. This function computes a compact representation of the decomposition given by  torch.linalg.lu() .
If the matrix is square, this representation may be used in  torch.linalg.lu_solve() 
to solve system of linear equations that share the matrix  A . The returned decomposition is represented as a named tuple  (LU, pivots) .
The  LU  matrix has the same shape as the input matrix  A . Its upper and lower triangular
parts encode the non-constant elements of  L  and  U  of the LU decomposition of  A . The returned permutation matrix is represented by a 1-indexed vector.  pivots[i] == j  represents
that in the  i -th step of the algorithm, the  i -th row was permuted with the  j-1 -th row. On CUDA, one may use  pivot = False . In this case, this function returns the LU
decomposition without pivoting if it exists. Supports inputs of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if the inputs are batches of matrices then
the output has the same batch dimensions. 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU. For a version of this function that does not synchronize, see  
 
 Warning 
 The LU decomposition is almost never unique, as often there are different permutation
matrices that can yield different LU decompositions.
As such, different platforms, like SciPy, or inputs on different devices,
may produce different valid decompositions. 
 Gradient computations are only supported if the input matrix is full-rank.
If this condition is not met, no error will be thrown, but the gradient may not be finite.
This is because the LU decomposition with pivoting is not differentiable at these points. 
 
 See also 
 torch.linalg.lu_solve() 
 torch.lu_unpack() 
 torch.linalg.lu() 
 torch.linalg.solve() 
 
 Parameters 
 A 
 Keyword Arguments 
 
 
 Returns 
 A named tuple  
 Raises 
 RuntimeError 
 Examples: 
",">>> A=torch.randn(2,3,3)
>>> B1=torch.randn(2,3,4)
>>> B2=torch.randn(2,3,7)
>>> A_factor=torch.linalg.lu_factor(A)
>>> X1=torch.linalg.lu_solve(A_factor,B1)
>>> X2=torch.linalg.lu_solve(A_factor,B2)
>>> torch.allclose(A@X1,B1)
True
>>> torch.allclose(A@X2,B2)
True
",,,
"
 torch. lu_unpack ( LU_data ,  LU_pivots ,  unpack_data ,  unpack_pivots ,  * ,  out ) ¶","Unpacks the LU decomposition returned by  lu_factor()  into the  P, L, U  matrices. 
 See also 
 lu() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A namedtuple  
 Examples: 
",">>> A=torch.randn(2,3,3)
>>> LU,pivots=torch.linalg.lu_factor(A)
>>> P,L,U=torch.lu_unpack(LU,pivots)
>>> # We can recover A from the factorization
>>> A_=P@L@U
>>> torch.allclose(A,A_)
True>>> # LU factorization of a rectangular matrix:
>>> A=torch.randn(2,3,2)
>>> LU,pivots=torch.linalg.lu_factor(A)
>>> P,L,U=torch.lu_unpack(LU,pivots)
>>> # P, L, U are the same as returned by linalg.lu
>>> P_,L_,U_=torch.linalg.lu(A)
>>> torch.allclose(P,P_)andtorch.allclose(L,L_)andtorch.allclose(U,U_)
True
",,,
"
 torch. matmul ( input ,  other ,  * ,  out )   → ¶","Matrix product of two tensors. The behavior depends on the dimensionality of the tensors as follows: 
 If both tensors are 1-dimensional, the dot product (scalar) is returned. 
 If both arguments are 2-dimensional, the matrix-matrix product is returned. 
 If the first argument is 1-dimensional and the second argument is 2-dimensional,
a 1 is prepended to its dimension for the purpose of the matrix multiply.
After the matrix multiply, the prepended dimension is removed. 
 If the first argument is 2-dimensional and the second argument is 1-dimensional,
the matrix-vector product is returned. 
 If both arguments are at least 1-dimensional and at least one argument is
N-dimensional (where N > 2), then a batched matrix multiply is returned.  If the first
argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the
batched matrix multiply and removed after.  If the second argument is 1-dimensional, a
1 is appended to its dimension for the purpose of the batched matrix multiple and removed after.
The non-matrix (i.e. batch) dimensions are  
 This operation has support for arguments with  sparse layouts . In particular the
matrix-matrix (both arguments 2-dimensional) supports sparse arguments with the same restrictions
as  torch.mm() 
 Warning 
 Sparse support is a beta feature and some layout(s)/dtype/device combinations may not be supported,
or may not have autograd support. If you notice missing functionality please
open a feature request. 
 This operator supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 Note 
 The 1-dimensional dot product version of this function does not support an  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> # vector x vector
>>> tensor1=torch.randn(3)
>>> tensor2=torch.randn(3)
>>> torch.matmul(tensor1,tensor2).size()
torch.Size([])
>>> # matrix x vector
>>> tensor1=torch.randn(3,4)
>>> tensor2=torch.randn(4)
>>> torch.matmul(tensor1,tensor2).size()
torch.Size([3])
>>> # batched matrix x broadcasted vector
>>> tensor1=torch.randn(10,3,4)
>>> tensor2=torch.randn(4)
>>> torch.matmul(tensor1,tensor2).size()
torch.Size([10, 3])
>>> # batched matrix x batched matrix
>>> tensor1=torch.randn(10,3,4)
>>> tensor2=torch.randn(10,4,5)
>>> torch.matmul(tensor1,tensor2).size()
torch.Size([10, 3, 5])
>>> # batched matrix x broadcasted matrix
>>> tensor1=torch.randn(10,3,4)
>>> tensor2=torch.randn(4,5)
>>> torch.matmul(tensor1,tensor2).size()
torch.Size([10, 3, 5])
",,,
"
 torch. matrix_power ( input ,  n ,  * ,  out )   → ¶",Alias for  torch.linalg.matrix_power(),,,,
"
 torch.linalg. matrix_power ( A ,  n ,  * ,  out )   → ¶","Computes the  n -th power of a square matrix for an integer  n . Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. If  n = 0 , it returns the identity matrix (or batch) of the same shape
as  A . If  n  is negative, it returns the inverse of each matrix
(if invertible) raised to the power of  abs(n) . 
 Note 
 Consider using  
 
 It is always prefered to use  
 
 See also 
 torch.linalg.solve() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Raises 
 RuntimeError 
 Examples: 
",">>> A=torch.randn(3,3)
>>> torch.linalg.matrix_power(A,0)
tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]])
>>> torch.linalg.matrix_power(A,3)
tensor([[ 1.0756,  0.4980,  0.0100],
        [-1.6617,  1.4994, -1.9980],
        [-0.4509,  0.2731,  0.8001]])
>>> torch.linalg.matrix_power(A.expand(2,-1,-1),-2)
tensor([[[ 0.2640,  0.4571, -0.5511],
        [-1.0163,  0.3491, -1.5292],
        [-0.4899,  0.0822,  0.2773]],
        [[ 0.2640,  0.4571, -0.5511],
        [-1.0163,  0.3491, -1.5292],
        [-0.4899,  0.0822,  0.2773]]])
",,,
"
 torch. matrix_exp ( A )   → ¶",Alias for  torch.linalg.matrix_exp() .,,,,
"
 torch.linalg. matrix_exp ( A )   → ¶","Computes the matrix exponential of a square matrix. Letting  K  be  R  or  C ,
this function computes the  matrix exponential  of  A , which is defined as 
 m If the matrix  A  has eigenvalues  λ ,
the matrix  m  has eigenvalues  e . Supports input of bfloat16, float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. 
 Parameters 
 A 
 Example: 
",">>> A=torch.empty(2,2,2)
>>> A[0,:,:]=torch.eye(2,2)
>>> A[1,:,:]=2*torch.eye(2,2)
>>> A
tensor([[[1., 0.],
         [0., 1.]],        [[2., 0.],
         [0., 2.]]])
>>> torch.linalg.matrix_exp(A)
tensor([[[2.7183, 0.0000],
         [0.0000, 2.7183]],         [[7.3891, 0.0000],
          [0.0000, 7.3891]]])>>> importmath
>>> A=torch.tensor([[0,math.pi/3],[-math.pi/3,0]])# A is skew-symmetric
>>> torch.linalg.matrix_exp(A)# matrix_exp(A) = [[cos(pi/3), sin(pi/3)], [-sin(pi/3), cos(pi/3)]]
tensor([[ 0.5000,  0.8660],
        [-0.8660,  0.5000]])
",,,
"
 torch. mm ( input ,  mat2 ,  * ,  out )   → ¶","Performs a matrix multiplication of the matrices  input  and  mat2 . If  input  is a  (  tensor,  mat2  is a
 (  tensor,  out  will be a  (  tensor. 
 Note 
 This function does not  
 Supports strided and sparse 2-D tensors as inputs, autograd with
respect to strided inputs. This operation has support for arguments with  sparse layouts .
If  out  is provided it’s layout will be used. Otherwise, the result
layout will be deduced from that of  input . 
 Warning 
 Sparse support is a beta feature and some layout(s)/dtype/device combinations may not be supported,
or may not have autograd support. If you notice missing functionality please
open a feature request. 
 This operator supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> mat1=torch.randn(2,3)
>>> mat2=torch.randn(3,3)
>>> torch.mm(mat1,mat2)
tensor([[ 0.4851,  0.5037, -0.3633],
        [-0.0760, -3.6705,  2.4784]])
",,,
"
 torch. mv ( input ,  vec ,  * ,  out )   → ¶","Performs a matrix-vector product of the matrix  input  and the vector
 vec . If  input  is a  (  tensor,  vec  is a 1-D tensor of
size  m ,  out  will be 1-D of size  n . 
 Note 
 This function does not  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> mat=torch.randn(2,3)
>>> vec=torch.randn(3)
>>> torch.mv(mat,vec)
tensor([ 1.0404, -0.6361])
",,,
"
 torch. orgqr ( input ,  tau )   → ¶",Alias for  torch.linalg.householder_product() .,,,,
"
 torch.linalg. householder_product ( A ,  tau ,  * ,  out )   → ¶","Computes the first  n  columns of a product of Householder matrices. Let  K  be  R  or  C , and
let  V  be a matrix with columns  v 
for  i  with  m . Denote by  w  the vector resulting from
zeroing out the first  i  compontents of  v  and setting to  1  the  i -th.
For a vector  τ  with  k , this function computes the
first  n  columns of the matrix 
 H where  I  is the  m -dimensional identity matrix and  w  is the
conjugate transpose when  w  is complex, and the transpose when  w  is real-valued.
The output matrix is the same size as the input matrix  A . See  Representation of Orthogonal or Unitary Matrices  for further details. Supports inputs of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if the inputs are batches of matrices then
the output has the same batch dimensions. 
 See also 
 torch.geqrf() 
 torch.ormqr() 
 
 Warning 
 Gradient computations are only well-defined if  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Raises 
 RuntimeError 
 Examples: 
",">>> A=torch.randn(2,2)
>>> h,tau=torch.geqrf(A)
>>> Q=torch.linalg.householder_product(h,tau)
>>> torch.dist(Q,torch.linalg.qr(A).Q)
tensor(0.)>>> h=torch.randn(3,2,2,dtype=torch.complex128)
>>> tau=torch.randn(3,1,dtype=torch.complex128)
>>> Q=torch.linalg.householder_product(h,tau)
>>> Q
tensor([[[ 1.8034+0.4184j,  0.2588-1.0174j],
        [-0.6853+0.7953j,  2.0790+0.5620j]],        [[ 1.4581+1.6989j, -1.5360+0.1193j],
        [ 1.3877-0.6691j,  1.3512+1.3024j]],        [[ 1.4766+0.5783j,  0.0361+0.6587j],
        [ 0.6396+0.1612j,  1.3693+0.4481j]]], dtype=torch.complex128)
",,,
"
 torch. ormqr ( input ,  tau ,  other ,  left ,  transpose ,  * ,  out )   → ¶","Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix. Multiplies a  m  matrix  C  (given by  other ) with a matrix  Q ,
where  Q  is represented using Householder reflectors  (input, tau) .
See  Representation of Orthogonal or Unitary Matrices  for further details. If  left  is  True  then  op(Q)  times  C  is computed, otherwise the result is  C  times  op(Q) .
When  left  is  True , the implicit matrix  Q  has size  m .
It has size  n  otherwise.
If  transpose  is  True  then  op  is the conjugate transpose operation, otherwise it’s a no-op. Supports inputs of float, double, cfloat and cdouble dtypes.
Also supports batched inputs, and, if the input is batched, the output is batched with the same dimensions. 
 See also 
 torch.geqrf() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
",,,,
"
 torch. pinverse ( input ,  rcond )   → ¶",Alias for  torch.linalg.pinv(),,,,
"
 torch.linalg. pinv ( A ,  * ,  atol ,  rtol ,  hermitian ,  out )   → ¶","Computes the pseudoinverse (Moore-Penrose inverse) of a matrix. The pseudoinverse may be  defined algebraically 
but it is more computationally convenient to understand it  through the SVD Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. If  hermitian = True ,  A  is assumed to be Hermitian if complex or
symmetric if real, but this is not checked internally. Instead, just the lower
triangular part of the matrix is used in the computations. The singular values (or the norm of the eigenvalues when  hermitian = True )
that are below  max  threshold are
treated as zero and discarded in the computation,
where  σ  is the largest singular value (or eigenvalue). If  rtol  is not specified and  A  is a matrix of dimensions  (m, n) ,
the relative tolerance is set to be  rtol 
and  ε  is the epsilon value for the dtype of  A  (see  finfo ).
If  rtol  is not specified and  atol  is specified to be larger than zero then
 rtol  is set to zero. If  atol  or  rtol  is a  torch.Tensor , its shape must be broadcastable to that
of the singular values of  A  as returned by  torch.linalg.svd() . 
 Note 
 This function uses  
 
 Note 
 Consider using  
 
 It is always prefered to use  
 
 Note 
 This function has NumPy compatible variant  
 
 Warning 
 This function uses internally  
 
 See also 
 torch.linalg.inv() 
 torch.linalg.lstsq() 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> A=torch.randn(3,5)
>>> A
tensor([[ 0.5495,  0.0979, -1.4092, -0.1128,  0.4132],
        [-1.1143, -0.3662,  0.3042,  1.6374, -0.9294],
        [-0.3269, -0.5745, -0.0382, -0.5922, -0.6759]])
>>> torch.linalg.pinv(A)
tensor([[ 0.0600, -0.1933, -0.2090],
        [-0.0903, -0.0817, -0.4752],
        [-0.7124, -0.1631, -0.2272],
        [ 0.1356,  0.3933, -0.5023],
        [-0.0308, -0.1725, -0.5216]])>>> A=torch.randn(2,6,3)
>>> Apinv=torch.linalg.pinv(A)
>>> torch.dist(Apinv@A,torch.eye(3))
tensor(8.5633e-07)>>> A=torch.randn(3,3,dtype=torch.complex64)
>>> A=A+A.T.conj()# creates a Hermitian matrix
>>> Apinv=torch.linalg.pinv(A,hermitian=True)
>>> torch.dist(Apinv@A,torch.eye(3))
tensor(1.0830e-06)
",,,
"
 torch. qr ( input ,  some ,  * ,  out ) ¶","Computes the QR decomposition of a matrix or a batch of matrices  input ,
and returns a namedtuple (Q, R) of tensors such that  input 
with  Q  being an orthogonal matrix or batch of orthogonal matrices and
 R  being an upper triangular matrix or batch of upper triangular matrices. If  some  is  True , then this function returns the thin (reduced) QR factorization.
Otherwise, if  some  is  False , this function returns the complete QR factorization. 
 Warning 
 torch.qr() 
 Q, 
 
 Q, 
 
 
 Warning 
 If you plan to backpropagate through QR, note that the current backward implementation
is only well-defined when the first  
 
 Note 
 This function uses LAPACK for CPU inputs and MAGMA for CUDA inputs,
and may produce different (valid) decompositions on different device types
or different platforms. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.tensor([[12.,-51,4],[6,167,-68],[-4,24,-41]])
>>> q,r=torch.qr(a)
>>> q
tensor([[-0.8571,  0.3943,  0.3314],
        [-0.4286, -0.9029, -0.0343],
        [ 0.2857, -0.1714,  0.9429]])
>>> r
tensor([[ -14.0000,  -21.0000,   14.0000],
        [   0.0000, -175.0000,   70.0000],
        [   0.0000,    0.0000,  -35.0000]])
>>> torch.mm(q,r).round()
tensor([[  12.,  -51.,    4.],
        [   6.,  167.,  -68.],
        [  -4.,   24.,  -41.]])
>>> torch.mm(q.t(),q).round()
tensor([[ 1.,  0.,  0.],
        [ 0.,  1., -0.],
        [ 0., -0.,  1.]])
>>> a=torch.randn(3,4,5)
>>> q,r=torch.qr(a,some=False)
>>> torch.allclose(torch.matmul(q,r),a)
True
>>> torch.allclose(torch.matmul(q.mT,q),torch.eye(5))
True
",,,
"
 torch. svd ( input ,  some ,  compute_uv ,  * ,  out ) ¶","Computes the singular value decomposition of either a matrix or batch of
matrices  input . The singular value decomposition is represented as a
namedtuple  (U, S, V) , such that  input   = .
where  V  is the transpose of  V  for real inputs,
and the conjugate transpose of  V  for complex inputs.
If  input  is a batch of matrices, then  U ,  S , and  V  are also
batched with the same batch dimensions as  input . If  some  is  True  (default), the method returns the reduced singular
value decomposition. In this case, if the last two dimensions of  input  are
 m  and  n , then the returned  U  and  V  matrices will contain only
 min(n, m)  orthonormal columns. If  compute_uv  is  False , the returned  U  and  V  will be
zero-filled matrices of shape  (m, m)  and  (n, n) 
respectively, and the same device as  input . The argument  some 
has no effect when  compute_uv  is  False . Supports  input  of float, double, cfloat and cdouble data types.
The dtypes of  U  and  V  are the same as  input ’s.  S  will
always be real-valued, even if  input  is complex. 
 Warning 
 torch.svd() 
 U, 
 
 _, 
 
 
 Note 
 Differences with  
 
 
 
 Note 
 The singular values are returned in descending order. If  
 
 Note 
 The  
 
 Note 
 When  
 
 Note 
 The implementation of  
 
 Note 
 The returned  
 
 Warning 
 The gradients with respect to  
 
 Warning 
 If the distance between any two singular values is close to zero, the gradients with respect to
 
 
 Warning 
 For complex-valued  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example: 
",">>> a=torch.randn(5,3)
>>> a
tensor([[ 0.2364, -0.7752,  0.6372],
        [ 1.7201,  0.7394, -0.0504],
        [-0.3371, -1.0584,  0.5296],
        [ 0.3550, -0.4022,  1.5569],
        [ 0.2445, -0.0158,  1.1414]])
>>> u,s,v=torch.svd(a)
>>> u
tensor([[ 0.4027,  0.0287,  0.5434],
        [-0.1946,  0.8833,  0.3679],
        [ 0.4296, -0.2890,  0.5261],
        [ 0.6604,  0.2717, -0.2618],
        [ 0.4234,  0.2481, -0.4733]])
>>> s
tensor([2.3289, 2.0315, 0.7806])
>>> v
tensor([[-0.0199,  0.8766,  0.4809],
        [-0.5080,  0.4054, -0.7600],
        [ 0.8611,  0.2594, -0.4373]])
>>> torch.dist(a,torch.mm(torch.mm(u,torch.diag(s)),v.t()))
tensor(8.6531e-07)
>>> a_big=torch.randn(7,5,3)
>>> u,s,v=torch.svd(a_big)
>>> torch.dist(a_big,torch.matmul(torch.matmul(u,torch.diag_embed(s)),v.mT))
tensor(2.6503e-06)
",,,
"
 torch. svd_lowrank ( A ,  q ,  niter ,  M ) [source] ¶","Return the singular value decomposition  (U,  of a matrix,
batches of matrices, or a sparse matrix  A  such that
 A . In case  M  is given, then
SVD is computed for the matrix  A . 
 Note 
 The implementation is based on the Algorithm 5.1 from
Halko et al, 2009. 
 
 Note 
 To obtain repeatable results, reset the seed for the
pseudorandom number generator 
 
 Note 
 The input is assumed to be a low-rank matrix. 
 
 Note 
 In general, use the full-rank SVD implementation
 
 
 Args:: A (Tensor): the input tensor of size  
 References:: 
 
 
 Return type 
 Tuple 
",,,,
"
 torch. pca_lowrank ( A ,  q ,  center ,  niter ) [source] ¶","Performs linear Principal Component Analysis (PCA) on a low-rank
matrix, batches of such matrices, or sparse matrix. This function returns a namedtuple  (U,  which is the
nearly optimal approximation of a singular value decomposition of
a centered matrix  A  such that  A . 
 Note 
 The relation of  
 
 
 
 Note 
 Different from the standard SVD, the size of returned
matrices depend on the specified rank and q
values as follows: 
 
 
 
 Note 
 To obtain repeatable results, reset the seed for the
pseudorandom number generator 
 
 Parameters 
 
 
 Return type 
 Tuple 
 References: 
",,,,
"
 torch. symeig ( input ,  eigenvectors ,  upper ,  * ,  out ) ¶","This function returns eigenvalues and eigenvectors
of a real symmetric or complex Hermitian matrix  input  or a batch thereof,
represented by a namedtuple (eigenvalues, eigenvectors). This function calculates all eigenvalues (and vectors) of  input 
such that  input . The boolean argument  eigenvectors  defines computation of
both eigenvectors and eigenvalues or eigenvalues only. If it is  False , only eigenvalues are computed. If it is  True ,
both eigenvalues and eigenvectors are computed. Since the input matrix  input  is supposed to be symmetric or Hermitian,
only the upper triangular portion is used by default. If  upper  is  False , then lower triangular portion is used. 
 Warning 
 torch.symeig() 
 L, 
 
 L, 
 
 
 Note 
 The eigenvalues are returned in ascending order. If  
 
 Note 
 Irrespective of the original strides, the returned matrix  
 
 Warning 
 Extra care needs to be taken when backward through outputs. Such
operation is only stable when all eigenvalues are distinct and becomes
less stable the smaller  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A namedtuple (eigenvalues, eigenvectors) containing 
 Return type 
 ( 
 Examples: 
",">>> a=torch.randn(5,5)
>>> a=a+a.t()# To make a symmetric
>>> a
tensor([[-5.7827,  4.4559, -0.2344, -1.7123, -1.8330],
        [ 4.4559,  1.4250, -2.8636, -3.2100, -0.1798],
        [-0.2344, -2.8636,  1.7112, -5.5785,  7.1988],
        [-1.7123, -3.2100, -5.5785, -2.6227,  3.1036],
        [-1.8330, -0.1798,  7.1988,  3.1036, -5.1453]])
>>> e,v=torch.symeig(a,eigenvectors=True)
>>> e
tensor([-13.7012,  -7.7497,  -2.3163,   5.2477,   8.1050])
>>> v
tensor([[ 0.1643,  0.9034, -0.0291,  0.3508,  0.1817],
        [-0.2417, -0.3071, -0.5081,  0.6534,  0.4026],
        [-0.5176,  0.1223, -0.0220,  0.3295, -0.7798],
        [-0.4850,  0.2695, -0.5773, -0.5840,  0.1337],
        [ 0.6415, -0.0447, -0.6381, -0.0193, -0.4230]])
>>> a_big=torch.randn(5,2,2)
>>> a_big=a_big+a_big.mT# To make a_big symmetric
>>> e,v=a_big.symeig(eigenvectors=True)
>>> torch.allclose(torch.matmul(v,torch.matmul(e.diag_embed(),v.mT)),a_big)
True
",,,
"
 torch. lobpcg ( A ,  k ,  B ,  X ,  n ,  iK ,  niter ,  tol ,  largest ,  method ,  tracker ,  ortho_iparams ,  ortho_fparams ,  ortho_bparams ) [source] ¶","Find the k largest (or smallest) eigenvalues and the corresponding
eigenvectors of a symmetric positive definite generalized
eigenvalue problem using matrix-free LOBPCG methods. This function is a front-end to the following LOBPCG algorithms
selectable via  method  argument: 
 method=”basic” Supported inputs are dense, sparse, and batches of dense matrices. 
 Note 
 In general, the basic method spends least time per
iteration. However, the robust methods converge much faster and
are more stable. So, the usage of the basic method is generally
not recommended but there exist cases where the usage of the
basic method may be preferred. 
 
 Warning 
 The backward method does not support sparse and complex inputs.
It works only when  
 
 Warning 
 While it is assumed that  
 
 Parameters 
 
 
 Returns 
 tensor of eigenvalues of size  
 Return type 
 E ( 
 References [Knyazev2001] Andrew V. Knyazev. (2001) Toward the Optimal
Preconditioned Eigensolver: Locally Optimal Block Preconditioned
Conjugate Gradient Method. SIAM J. Sci. Comput., 23(2),
517-541. (25 pages)
 https://epubs.siam.org/doi/abs/10.1137/S1064827500366124 [StathopoulosEtal2002] Andreas Stathopoulos and Kesheng
Wu. (2002) A Block Orthogonalization Procedure with Constant
Synchronization Requirements. SIAM J. Sci. Comput., 23(6),
2165-2182. (18 pages)
 https://epubs.siam.org/doi/10.1137/S1064827500370883 [DuerschEtal2018] Jed A. Duersch, Meiyue Shao, Chao Yang, Ming
Gu. (2018) A Robust and Efficient Implementation of LOBPCG.
SIAM J. Sci. Comput., 40(5), C655-C676. (22 pages)
 https://epubs.siam.org/doi/abs/10.1137/17M1129830",,,,
"
 torch. trapz ( y ,  x ,  * ,  dim )   → ¶",Alias for  torch.trapezoid() .,,,,
"
 torch. trapezoid ( y ,  x ,  * ,  dx ,  dim )   → ¶","Computes the  trapezoidal rule  along
 dim . By default the spacing between elements is assumed to be 1, but
 dx  can be used to specify a different constant spacing, and  x  can be
used to specify arbitrary spacing along  dim . Assuming  y  is a one-dimensional tensor with elements  y ,
the default computation is 
 ∑ When  dx  is specified the computation becomes 
 ∑ effectively multiplying the result by  dx . When  x  is specified,
assuming  x  is also a one-dimensional tensor with
elements  x , the computation becomes 
 ∑ When  x  and  y  have the same size, the computation is as described above and no broadcasting is needed.
The broadcasting behavior of this function is as follows when their sizes are different. For both  x 
and  y , the function computes the difference between consecutive elements along
dimension  dim . This effectively creates two tensors,  x_diff  and  y_diff , that have
the same shape as the original tensors except their lengths along the dimension  dim  is reduced by 1.
After that, those two tensors are broadcast together to compute final output as part of the trapezoidal rule.
See the examples below for details. 
 Note 
 The trapezoidal rule is a technique for approximating the definite integral of a function
by averaging its left and right Riemann sums. The approximation becomes more accurate as
the resolution of the partition increases. 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> # Computes the trapezoidal rule in 1D, spacing is implicitly 1
>>> y=torch.tensor([1,5,10])
>>> torch.trapezoid(y)
tensor(10.5)>>> # Computes the same trapezoidal rule directly to verify
>>> (1+10+10)/2
10.5>>> # Computes the trapezoidal rule in 1D with constant spacing of 2
>>> # NOTE: the result is the same as before, but multiplied by 2
>>> torch.trapezoid(y,dx=2)
21.0>>> # Computes the trapezoidal rule in 1D with arbitrary spacing
>>> x=torch.tensor([1,3,6])
>>> torch.trapezoid(y,x)
28.5>>> # Computes the same trapezoidal rule directly to verify
>>> ((3-1)*(1+5)+(6-3)*(5+10))/2
28.5>>> # Computes the trapezoidal rule for each row of a 3x3 matrix
>>> y=torch.arange(9).reshape(3,3)
tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
>>> torch.trapezoid(y)
tensor([ 2., 8., 14.])>>> # Computes the trapezoidal rule for each column of the matrix
>>> torch.trapezoid(y,dim=0)
tensor([ 6., 8., 10.])>>> # Computes the trapezoidal rule for each row of a 3x3 ones matrix
>>> #   with the same arbitrary spacing
>>> y=torch.ones(3,3)
>>> x=torch.tensor([1,3,6])
>>> torch.trapezoid(y,x)
array([5., 5., 5.])>>> # Computes the trapezoidal rule for each row of a 3x3 ones matrix
>>> #   with different arbitrary spacing per row
>>> y=torch.ones(3,3)
>>> x=torch.tensor([[1,2,3],[1,3,5],[1,4,7]])
>>> torch.trapezoid(y,x)
array([2., 4., 6.])
",,,
"
 torch. cumulative_trapezoid ( y ,  x ,  * ,  dx ,  dim )   → ¶","Cumulatively computes the  trapezoidal rule 
along  dim . By default the spacing between elements is assumed to be 1, but
 dx  can be used to specify a different constant spacing, and  x  can be
used to specify arbitrary spacing along  dim . For more details, please read  torch.trapezoid() . The difference between  torch.trapezoid() 
and this function is that,  torch.trapezoid()  returns a value for each integration,
where as this function returns a cumulative value for every spacing within the integration. This
is analogous to how  .sum  returns a value and  .cumsum  returns a cumulative sum. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> # Cumulatively computes the trapezoidal rule in 1D, spacing is implicitly 1.
>>> y=torch.tensor([1,5,10])
>>> torch.cumulative_trapezoid(y)
tensor([3., 10.5])>>> # Computes the same trapezoidal rule directly up to each element to verify
>>> (1+5)/2
3.0
>>> (1+10+10)/2
10.5>>> # Cumulatively computes the trapezoidal rule in 1D with constant spacing of 2
>>> # NOTE: the result is the same as before, but multiplied by 2
>>> torch.cumulative_trapezoid(y,dx=2)
tensor([6., 21.])>>> # Cumulatively computes the trapezoidal rule in 1D with arbitrary spacing
>>> x=torch.tensor([1,3,6])
>>> torch.cumulative_trapezoid(y,x)
tensor([6., 28.5])>>> # Computes the same trapezoidal rule directly up to each element to verify
>>> ((3-1)*(1+5))/2
6.0
>>> ((3-1)*(1+5)+(6-3)*(5+10))/2
28.5>>> # Cumulatively computes the trapezoidal rule for each row of a 3x3 matrix
>>> y=torch.arange(9).reshape(3,3)
tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
>>> torch.cumulative_trapezoid(y)
tensor([[ 0.5,  2.],
        [ 3.5,  8.],
        [ 6.5, 14.]])>>> # Cumulatively computes the trapezoidal rule for each column of the matrix
>>> torch.cumulative_trapezoid(y,dim=0)
tensor([[ 1.5,  2.5,  3.5],
        [ 6.0,  8.0, 10.0]])>>> # Cumulatively computes the trapezoidal rule for each row of a 3x3 ones matrix
>>> #   with the same arbitrary spacing
>>> y=torch.ones(3,3)
>>> x=torch.tensor([1,3,6])
>>> torch.cumulative_trapezoid(y,x)
tensor([[2., 5.],
        [2., 5.],
        [2., 5.]])>>> # Cumulatively computes the trapezoidal rule for each row of a 3x3 ones matrix
>>> #   with different arbitrary spacing per row
>>> y=torch.ones(3,3)
>>> x=torch.tensor([[1,2,3],[1,3,5],[1,4,7]])
>>> torch.cumulative_trapezoid(y,x)
tensor([[1., 2.],
        [2., 4.],
        [3., 6.]])
",,,
"
 torch. triangular_solve ( b ,  A ,  upper ,  transpose ,  unitriangular ,  * ,  out ) ¶","Solves a system of equations with a square upper or lower triangular invertible matrix  A 
and multiple right-hand sides  b . In symbols, it solves  A  and assumes  A  is square upper-triangular
(or lower-triangular if  upper = False ) and does not have zeros on the diagonal. torch.triangular_solve(b, A)  can take in 2D inputs  b, A  or inputs that are
batches of 2D matrices. If the inputs are batches, then returns
batched outputs  X If the diagonal of  A  contains zeros or elements that are very close to zero and
 unitriangular = False  (default) or if the input matrix is badly conditioned,
the result may contain  NaN  s. Supports input of float, double, cfloat and cdouble data types. 
 Warning 
 torch.triangular_solve() 
 X 
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A namedtuple  
 Examples: 
",">>> A=torch.randn(2,2).triu()
>>> A
tensor([[ 1.1527, -1.0753],
        [ 0.0000,  0.7986]])
>>> b=torch.randn(2,3)
>>> b
tensor([[-0.0210,  2.3513, -1.5492],
        [ 1.5429,  0.7403, -1.0243]])
>>> torch.triangular_solve(b,A)
torch.return_types.triangular_solve(
solution=tensor([[ 1.7841,  2.9046, -2.5405],
        [ 1.9320,  0.9270, -1.2826]]),
cloned_coefficient=tensor([[ 1.1527, -1.0753],
        [ 0.0000,  0.7986]]))
",,,
"
 torch. vdot ( input ,  other ,  * ,  out )   → ¶","Computes the dot product of two 1D vectors along a dimension. In symbols, this function computes 
 ∑ where  x  denotes the conjugate for complex
vectors, and it is the identity for real vectors. 
 Note 
 Unlike NumPy’s vdot, torch.vdot intentionally only supports computing the dot product
of two 1D tensors with the same number of elements. 
 
 See also 
 torch.linalg.vecdot() 
 
 Parameters 
 
 
 Keyword args: 
 Note 
 out (Tensor, optional): the output tensor. 
 Example: 
",">>> torch.vdot(torch.tensor([2,3]),torch.tensor([2,1]))
tensor(7)
>>> a=torch.tensor((1+2j,3-1j))
>>> b=torch.tensor((2+1j,4-0j))
>>> torch.vdot(a,b)
tensor([16.+1.j])
>>> torch.vdot(b,a)
tensor([16.-1.j])
",,,
"
 torch. compiled_with_cxx11_abi ( ) [source] ¶",Returns whether PyTorch was built with _GLIBCXX_USE_CXX11_ABI=1,,,,
"
 torch. result_type ( tensor1 ,  tensor2 )   → ¶","Returns the  torch.dtype  that would result from performing an arithmetic
operation on the provided input tensors. See type promotion  documentation 
for more information on the type promotion logic. 
 Parameters 
 
 
 Example: 
",">>> torch.result_type(torch.tensor([1,2],dtype=torch.int),1.0)
torch.float32
>>> torch.result_type(torch.tensor([1,2],dtype=torch.uint8),torch.tensor(1))
torch.uint8
",,,
"
 torch. can_cast ( from ,  to )   → ¶","Determines if a type conversion is allowed under PyTorch casting rules
described in the type promotion  documentation . 
 Parameters 
 
 
 Example: 
",">>> torch.can_cast(torch.double,torch.float)
True
>>> torch.can_cast(torch.float,torch.int)
False
",,,
"
 torch. promote_types ( type1 ,  type2 )   → ¶","Returns the  torch.dtype  with the smallest size and scalar kind that is
not smaller nor of lower kind than either  type1  or  type2 . See type promotion
 documentation  for more information on the type
promotion logic. 
 Parameters 
 
 
 Example: 
",">>> torch.promote_types(torch.int32,torch.float32)
torch.float32
>>> torch.promote_types(torch.uint8,torch.long)
torch.long
",,,
"
 torch. use_deterministic_algorithms ( mode ,  * ,  warn_only ) [source] ¶","Sets whether PyTorch operations must use “deterministic”
algorithms. That is, algorithms which, given the same input, and when
run on the same software and hardware, always produce the same output.
When enabled, operations will use deterministic algorithms when available,
and if only nondeterministic algorithms are available they will throw a
 RuntimeError  when called. 
 Note 
 This setting alone is not always enough to make an application
reproducible. Refer to  
 
 Note 
 torch.set_deterministic_debug_mode() 
 The following normally-nondeterministic operations will act
deterministically when  mode=True : 
 
 The following normally-nondeterministic operations will throw a
 RuntimeError  when  mode=True : 
 
 A handful of CUDA operations are nondeterministic if the CUDA version is
10.2 or greater, unless the environment variable  CUBLAS_WORKSPACE_CONFIG=:4096:8 
or  CUBLAS_WORKSPACE_CONFIG=:16:8  is set. See the CUDA documentation for more
details:  https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility 
If one of these environment variable configurations is not set, a  RuntimeError 
will be raised from these operations when called with CUDA tensors: 
 
 Note that deterministic operations tend to have worse performance than
nondeterministic operations. 
 Note 
 This flag does not detect or prevent nondeterministic behavior caused
by calling an inplace operation on a tensor with an internal memory
overlap or by giving such a tensor as the  
 
 Parameters 
 mode 
 Keyword Arguments 
 warn_only 
 Example: 
",">>> torch.use_deterministic_algorithms(True)# Forward mode nondeterministic error
>>> torch.randn(10,device='cuda').kthvalue(0)
...
RuntimeError: kthvalue CUDA does not have a deterministic implementation...# Backward mode nondeterministic error
>>> torch.nn.AvgPool3d(1)(torch.randn(3,4,5,6,requires_grad=True).cuda()).sum().backward()
...
RuntimeError: avg_pool3d_backward_cuda does not have a deterministic implementation...
",,,
"
 torch. are_deterministic_algorithms_enabled ( ) [source] ¶","Returns True if the global deterministic flag is turned on. Refer to
 torch.use_deterministic_algorithms()  documentation for more details.",,,,
"
 torch. is_deterministic_algorithms_warn_only_enabled ( ) [source] ¶","Returns True if the global deterministic flag is set to warn only.
Refer to  torch.use_deterministic_algorithms()  documentation for more
details.",,,,
"
 torch. set_deterministic_debug_mode ( debug_mode ) [source] ¶","Sets the debug mode for deterministic operations. 
 Note 
 This is an alternative interface for
 
 
 Parameters 
 debug_mode 
",,,,
"
 torch. get_deterministic_debug_mode ( ) [source] ¶","Returns the current value of the debug mode for deterministic
operations. Refer to  torch.set_deterministic_debug_mode() 
documentation for more details. 
 Return type 
 int 
",,,,
"
 torch. set_float32_matmul_precision ( precision ) [source] ¶","Sets the internal precision of float32 matrix multiplications. Running float32 matrix multiplications in lower precision may significantly increase
performance, and in some programs the loss of precision has a negligible impact. Supports three settings: 
 
 
 Note 
 This does not change the output dtype of float32 matrix multiplications,
it controls how the internal computation of the matrix multiplication is performed. 
 
 Note 
 This does not change the precision of convolution operations. Other flags,
like  
 
 Note 
 This flag currently only affects one native device type: CUDA.
If “high” or “medium” are set then the TensorFloat32 datatype will be used
when computing float32 matrix multiplications, equivalent to setting
 
 
 Parameters 
 precision 
",,,,
"
 torch. get_float32_matmul_precision ( ) [source] ¶","Returns the current value of float32 matrix multiplication precision. Refer to
 torch.set_float32_matmul_precision()  documentation for more details. 
 Return type 
 str 
",,,,
"
 torch. set_warn_always ( b ) [source] ¶","When this flag is False (default) then some PyTorch warnings may only
appear once per process. This helps avoid excessive warning information.
Setting it to True causes these warnings to always appear, which may be
helpful when debugging. 
 Parameters 
 b 
",,,,
"
 torch. is_warn_always_enabled ( ) [source] ¶","Returns True if the global warn_always flag is turned on. Refer to
 torch.set_warn_always()  documentation for more details.",,,,
"
 torch. _assert ( condition ,  message ) [source] ¶",A wrapper around Python’s assert which is symbolically traceable.,,,,
"
 class torch.nn.parameter. Parameter ( data ,  requires_grad ) [source] ¶","A kind of Tensor that is to be considered a module parameter. Parameters are  Tensor  subclasses, that have a
very special property when used with  Module  s - when they’re
assigned as Module attributes they are automatically added to the list of
its parameters, and will appear e.g. in  parameters()  iterator.
Assigning a Tensor doesn’t have such effect. This is because one might
want to cache some temporary state, like last hidden state of the RNN, in
the model. If there was no such class as  Parameter , these
temporaries would get registered too. 
 Parameters 
 
 
",,,,
"
 class torch.nn.parameter. UninitializedParameter ( requires_grad ,  device ,  dtype ) [source] ¶","A parameter that is not initialized. Unitialized Parameters are a a special case of  torch.nn.Parameter 
where the shape of the data is still unknown. Unlike a  torch.nn.Parameter , uninitialized parameters
hold no data and attempting to access some properties, like their shape,
will throw a runtime error. The only operations that can be performed on a uninitialized
parameter are changing its datatype, moving it to a different device and
converting it to a regular  torch.nn.Parameter . The default device or dtype to use when the parameter is materialized can be set
during construction using e.g.  device='cuda' . 
 
 
 
 alias of ",,,,
"
 class torch.nn.parameter. UninitializedBuffer ( requires_grad ,  device ,  dtype ) [source] ¶","A buffer that is not initialized. Unitialized Buffer is a a special case of  torch.Tensor 
where the shape of the data is still unknown. Unlike a  torch.Tensor , uninitialized parameters
hold no data and attempting to access some properties, like their shape,
will throw a runtime error. The only operations that can be performed on a uninitialized
parameter are changing its datatype, moving it to a different device and
converting it to a regular  torch.Tensor . The default device or dtype to use when the buffer is materialized can be set
during construction using e.g.  device='cuda' . 
",,,,
"
 class torch.nn. Module [source] ¶","Base class for all neural network modules. Your models should also subclass this class. Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes: 
 Submodules assigned in this way will be registered, and will have their
parameters converted too when you call  to() , etc. 
 Note 
 As per the example above, an  
 
 Variables 
 training 
 
 
 
 Adds a child module to the current module. 
 
 
 Applies  
 
 
 Casts all floating point parameters and buffers to  
 
 
 Returns an iterator over module buffers. 
 
 
 Returns an iterator over immediate children modules. 
 
 
 Moves all model parameters and buffers to the CPU. 
 
 
 Moves all model parameters and buffers to the GPU. 
 
 
 Casts all floating point parameters and buffers to  
 
 
 Sets the module in evaluation mode. 
 
 
 Set the extra representation of the module 
 
 
 Casts all floating point parameters and buffers to  
 
 
 Defines the computation performed at every call. 
 
 
 Returns the buffer given by  
 
 
 Returns any extra state to include in the module’s state_dict.
Implement this and a corresponding  
 
 
 Returns the parameter given by  
 
 
 Returns the submodule given by  
 
 
 Casts all floating point parameters and buffers to  
 
 
 Moves all model parameters and buffers to the IPU. 
 
 
 Copies parameters and buffers from  
 
 
 Returns an iterator over all modules in the network. 
 
 
 Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself. 
 
 
 Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself. 
 
 
 Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself. 
 
 
 Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself. 
 
 
 Returns an iterator over module parameters. 
 
 
 Registers a backward hook on the module. 
 
 
 Adds a buffer to the module. 
 
 
 Registers a forward hook on the module. 
 
 
 Registers a forward pre-hook on the module. 
 
 
 Registers a backward hook on the module. 
 
 
 Registers a post hook to be run after module’s  
 
 
 Alias for  
 
 
 Adds a parameter to the module. 
 
 
 Change if autograd should record operations on parameters in this
module. 
 
 
 This function is called from  
 
 
 See  
 
 
 
 
 Returns a dictionary containing references to the whole state of the module. 
 
 
 
 
 
 
 Moves and/or casts the parameters and buffers. 
 
 
 Moves the parameters and buffers to the specified device without copying storage. 
 
 
 Sets the module in training mode. 
 
 
 Casts all parameters and buffers to  
 
 
 Moves all model parameters and buffers to the XPU. 
 
 
 Sets gradients of all model parameters to zero. See similar function
under ",,,,
"
 class torch.nn. Sequential ( * ) [source] ¶",class   torch.nn. Sequential ( arg :   OrderedDict ),,,,
"
 class torch.nn. ModuleList ( modules ) [source] ¶","Holds submodules in a list. ModuleList  can be indexed like a regular Python list, but
modules it contains are properly registered, and will be visible by all
 Module  methods. 
 Parameters 
 modules 
 Example: 
 
 
 
 Appends a given module to the end of the list. 
 
 
 Appends modules from a Python iterable to the end of the list. 
 
 
 Insert a given module before a given index in the list.","classMyModule(nn.Module):def__init__(self):super(MyModule,self).__init__()self.linears=nn.ModuleList([nn.Linear(10,10)foriinrange(10)])defforward(self,x):# ModuleList can act as an iterable, or be indexed using intsfori,linenumerate(self.linears):x=self.linears[i//2](x)+l(x)returnx
",,,
"
 class torch.nn. ModuleDict ( modules ) [source] ¶","Holds submodules in a dictionary. ModuleDict  can be indexed like a regular Python dictionary,
but modules it contains are properly registered, and will be visible by all
 Module  methods. ModuleDict  is an  ordered  dictionary that respects 
 the order of insertion, and 
 in  
 Note that  update()  with other unordered mapping
types (e.g., Python’s plain  dict  before Python version 3.6) does not
preserve the order of the merged mapping. 
 Parameters 
 modules 
 Example: 
 
 
 
 Remove all items from the ModuleDict. 
 
 
 Return an iterable of the ModuleDict key/value pairs. 
 
 
 Return an iterable of the ModuleDict keys. 
 
 
 Remove key from the ModuleDict and return its module. 
 
 
 Update the  
 
 
 Return an iterable of the ModuleDict values.","classMyModule(nn.Module):def__init__(self):super(MyModule,self).__init__()self.choices=nn.ModuleDict({'conv':nn.Conv2d(10,10,3),'pool':nn.MaxPool2d(3)})self.activations=nn.ModuleDict([['lrelu',nn.LeakyReLU()],['prelu',nn.PReLU()]])defforward(self,x,choice,act):x=self.choices[choice](x)x=self.activations[act](x)returnx
",,,
"
 class torch.nn. ParameterList ( values ) [source] ¶","Holds parameters in a list. ParameterList  can be used like a regular Python
list, but Tensors that are  Parameter  are properly registered,
and will be visible by all  Module  methods. Note that the constructor, assigning an element of the list, the
 append()  method and the  extend() 
method will convert any  Tensor  into  Parameter . 
 Parameters 
 parameters 
 Example: 
 
 
 
 Appends a given value at the end of the list. 
 
 
 Appends values from a Python iterable to the end of the list.","classMyModule(nn.Module):def__init__(self):super(MyModule,self).__init__()self.params=nn.ParameterList([nn.Parameter(torch.randn(10,10))foriinrange(10)])defforward(self,x):# ParameterList can act as an iterable, or be indexed using intsfori,pinenumerate(self.params):x=self.params[i//2].mm(x)+p.mm(x)returnx
",,,
"
 class torch.nn. ParameterDict ( parameters ) [source] ¶","Holds parameters in a dictionary. ParameterDict can be indexed like a regular Python dictionary, but Parameters it
contains are properly registered, and will be visible by all Module methods.
Other objects are treated as would be done by a regular Python dictionary ParameterDict  is an  ordered  dictionary.
 update()  with other unordered mapping
types (e.g., Python’s plain  dict ) does not preserve the order of the
merged mapping. On the other hand,  OrderedDict  or another  ParameterDict 
will preserve their ordering. Note that the constructor, assigning an element of the dictionary and the
 update()  method will convert any  Tensor  into
 Parameter . 
 Parameters 
 values 
 Example: 
 
 
 
 Remove all items from the ParameterDict. 
 
 
 Returns a copy of this  
 
 
 Return a new ParameterDict with the keys provided 
 
 
 Return the parameter associated with key if present.
Otherwise return default if provided, None if not. 
 
 
 Return an iterable of the ParameterDict key/value pairs. 
 
 
 Return an iterable of the ParameterDict keys. 
 
 
 Remove key from the ParameterDict and return its parameter. 
 
 
 Remove and return the last inserted  
 
 
 If key is in the ParameterDict, return its value.
If not, insert  
 
 
 Update the  
 
 
 Return an iterable of the ParameterDict values.","classMyModule(nn.Module):def__init__(self):super(MyModule,self).__init__()self.params=nn.ParameterDict({'left':nn.Parameter(torch.randn(5,10)),'right':nn.Parameter(torch.randn(5,10))})defforward(self,x,choice):x=self.params[choice].mm(x)returnx
",,,
"
 torch.nn.modules.module. register_module_forward_pre_hook ( hook ) [source] ¶","Registers a forward pre-hook common to all modules. 
 Warning 
 This adds global state to the  
 The hook will be called every time before  forward()  is invoked.
It should have the following signature: 
 The input contains only the positional arguments given to the module.
Keyword arguments won’t be passed to the hooks and only to the  forward .
The hook can modify the input. User can either return a tuple or a
single modified value in the hook. We will wrap the value into a tuple
if a single value is returned(unless that value is already a tuple). This hook has precedence over the specific module hooks registered with
 register_forward_pre_hook . 
 Returns 
 a handle that can be used to remove the added hook by calling
 
 Return type 
 torch.utils.hooks.RemovableHandle 
",,,,
"
 torch.nn.modules.module. register_module_forward_hook ( hook ) [source] ¶","Registers a global forward hook for all the modules 
 Warning 
 This adds global state to the  
 The hook will be called every time after  forward()  has computed an output.
It should have the following signature: 
 The input contains only the positional arguments given to the module.
Keyword arguments won’t be passed to the hooks and only to the  forward .
The hook can modify the output. It can modify the input inplace but
it will not have effect on forward since this is called after
 forward()  is called. 
 Returns 
 a handle that can be used to remove the added hook by calling
 
 Return type 
 torch.utils.hooks.RemovableHandle 
 This hook will be executed before specific module hooks registered with
 register_forward_hook .",,,,
"
 torch.nn.modules.module. register_module_backward_hook ( hook ) [source] ¶","Registers a backward hook common to all the modules. This function is deprecated in favor of
 torch.nn.modules.module.register_module_full_backward_hook() 
and the behavior of this function will change in future versions. 
 Returns 
 a handle that can be used to remove the added hook by calling
 
 Return type 
 torch.utils.hooks.RemovableHandle 
",,,,
"
 torch.nn.modules.module. register_module_full_backward_hook ( hook ) [source] ¶","Registers a backward hook common to all the modules. 
 Warning 
 This adds global state to the  
 The hook will be called every time the gradients with respect to module
inputs are computed. The hook should have the following signature: 
 The  grad_input  and  grad_output  are tuples. The hook should
not modify its arguments, but it can optionally return a new gradient with
respect to the input that will be used in place of  grad_input  in
subsequent computations.  grad_input  will only correspond to the inputs given
as positional arguments and all kwarg arguments will not appear in the hook. Entries
in  grad_input  and  grad_output  will be  None  for all non-Tensor
arguments. For technical reasons, when this hook is applied to a Module, its forward function will
receive a view of each Tensor passed to the Module. Similarly the caller will receive a view
of each Tensor returned by the Module’s forward function. Global hooks are called before hooks registered with  register_backward_hook 
 Returns 
 a handle that can be used to remove the added hook by calling
 
 Return type 
 torch.utils.hooks.RemovableHandle 
",,,,
"
 class torch.nn. Conv1d ( in_channels ,  out_channels ,  kernel_size ,  stride ,  padding ,  dilation ,  groups ,  bias ,  padding_mode ,  device ,  dtype ) [source] ¶","Applies a 1D convolution over an input signal composed of several input
planes. In the simplest case, the output value of the layer with input size
 (  and output  (  can be
precisely described as: 
 out where  ⋆  is the valid  cross-correlation  operator,
 N  is a batch size,  C  denotes a number of channels,
 L  is a length of signal sequence. This module supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 stride 
 padding 
 dilation 
 groups 
 
 Note 
 When  
 In other words, for an input of size  
 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Note 
 padding='valid' 
 
 Note 
 This module supports complex data types i.e.  
 
 Parameters 
 
 
 
 Shape: 
 
 
 Variables 
 
 
 Examples: 
",">>> m=nn.Conv1d(16,33,3,stride=2)
>>> input=torch.randn(20,16,50)
>>> output=m(input)
",,,
"
 class torch.nn. Conv2d ( in_channels ,  out_channels ,  kernel_size ,  stride ,  padding ,  dilation ,  groups ,  bias ,  padding_mode ,  device ,  dtype ) [source] ¶","Applies a 2D convolution over an input signal composed of several input
planes. In the simplest case, the output value of the layer with input size
 (  and output  ( 
can be precisely described as: 
 out where  ⋆  is the valid 2D  cross-correlation  operator,
 N  is a batch size,  C  denotes a number of channels,
 H  is a height of input planes in pixels, and  W  is
width in pixels. This module supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 stride 
 padding 
 dilation 
 groups 
 The parameters  kernel_size ,  stride ,  padding ,  dilation  can either be: 
 
 
 Note 
 When  
 In other words, for an input of size  
 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Note 
 padding='valid' 
 
 Note 
 This module supports complex data types i.e.  
 
 Parameters 
 
 
 
 Shape: 
 
 
 Variables 
 
 
 Examples 
",,,,
"
 class torch.nn. Conv3d ( in_channels ,  out_channels ,  kernel_size ,  stride ,  padding ,  dilation ,  groups ,  bias ,  padding_mode ,  device ,  dtype ) [source] ¶","Applies a 3D convolution over an input signal composed of several input
planes. In the simplest case, the output value of the layer with input size  ( 
and output  (  can be precisely described as: 
 o where  ⋆  is the valid 3D  cross-correlation  operator This module supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 stride 
 padding 
 dilation 
 groups 
 The parameters  kernel_size ,  stride ,  padding ,  dilation  can either be: 
 
 
 Note 
 When  
 In other words, for an input of size  
 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Note 
 padding='valid' 
 
 Note 
 This module supports complex data types i.e.  
 
 Parameters 
 
 
 
 Shape: 
 
 
 Variables 
 
 
 Examples: 
",">>> # With square kernels and equal stride
>>> m=nn.Conv3d(16,33,3,stride=2)
>>> # non-square kernels and unequal stride and with padding
>>> m=nn.Conv3d(16,33,(3,5,2),stride=(2,1,1),padding=(4,2,0))
>>> input=torch.randn(20,16,10,50,100)
>>> output=m(input)
",,,
"
 class torch.nn. ConvTranspose1d ( in_channels ,  out_channels ,  kernel_size ,  stride ,  padding ,  output_padding ,  groups ,  bias ,  dilation ,  padding_mode ,  device ,  dtype ) [source] ¶","Applies a 1D transposed convolution operator over an input image
composed of several input planes. This module can be seen as the gradient of Conv1d with respect to its input.
It is also known as a fractionally-strided convolution or
a deconvolution (although it is not an actual deconvolution operation as it does
not compute a true inverse of convolution). For more information, see the visualizations
 here  and the  Deconvolutional Networks  paper. This module supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 stride 
 padding 
 output_padding 
 dilation 
 groups 
 
 Note 
 The  
 
 Note 
 In some circumstances when using the CUDA backend with CuDNN, this operator
may select a nondeterministic algorithm to increase performance. If this is
undesirable, you can try to make the operation deterministic (potentially at
a performance cost) by setting  
 
 Parameters 
 
 
 
 Shape: 
 
 
 Variables 
 
 
",,,,
"
 class torch.nn. ConvTranspose2d ( in_channels ,  out_channels ,  kernel_size ,  stride ,  padding ,  output_padding ,  groups ,  bias ,  dilation ,  padding_mode ,  device ,  dtype ) [source] ¶","Applies a 2D transposed convolution operator over an input image
composed of several input planes. This module can be seen as the gradient of Conv2d with respect to its input.
It is also known as a fractionally-strided convolution or
a deconvolution (although it is not an actual deconvolution operation as it does
not compute a true inverse of convolution). For more information, see the visualizations
 here  and the  Deconvolutional Networks  paper. This module supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 stride 
 padding 
 output_padding 
 dilation 
 groups 
 The parameters  kernel_size ,  stride ,  padding ,  output_padding 
can either be: 
 
 
 Note 
 The  
 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Parameters 
 
 
 
 Shape: 
 
 
 Variables 
 
 
 Examples: 
",">>> # With square kernels and equal stride
>>> m=nn.ConvTranspose2d(16,33,3,stride=2)
>>> # non-square kernels and unequal stride and with padding
>>> m=nn.ConvTranspose2d(16,33,(3,5),stride=(2,1),padding=(4,2))
>>> input=torch.randn(20,16,50,100)
>>> output=m(input)
>>> # exact output size can be also specified as an argument
>>> input=torch.randn(1,16,12,12)
>>> downsample=nn.Conv2d(16,16,3,stride=2,padding=1)
>>> upsample=nn.ConvTranspose2d(16,16,3,stride=2,padding=1)
>>> h=downsample(input)
>>> h.size()
torch.Size([1, 16, 6, 6])
>>> output=upsample(h,output_size=input.size())
>>> output.size()
torch.Size([1, 16, 12, 12])
",,,
"
 class torch.nn. ConvTranspose3d ( in_channels ,  out_channels ,  kernel_size ,  stride ,  padding ,  output_padding ,  groups ,  bias ,  dilation ,  padding_mode ,  device ,  dtype ) [source] ¶","Applies a 3D transposed convolution operator over an input image composed of several input
planes.
The transposed convolution operator multiplies each input value element-wise by a learnable kernel,
and sums over the outputs from all input feature planes. This module can be seen as the gradient of Conv3d with respect to its input.
It is also known as a fractionally-strided convolution or
a deconvolution (although it is not an actual deconvolution operation as it does
not compute a true inverse of convolution). For more information, see the visualizations
 here  and the  Deconvolutional Networks  paper. This module supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 stride 
 padding 
 output_padding 
 dilation 
 groups 
 The parameters  kernel_size ,  stride ,  padding ,  output_padding 
can either be: 
 
 
 Note 
 The  
 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Parameters 
 
 
 
 Shape: 
 
 
 Variables 
 
 
 Examples: 
",">>> # With square kernels and equal stride
>>> m=nn.ConvTranspose3d(16,33,3,stride=2)
>>> # non-square kernels and unequal stride and with padding
>>> m=nn.ConvTranspose3d(16,33,(3,5,2),stride=(2,1,1),padding=(0,4,2))
>>> input=torch.randn(20,16,10,50,100)
>>> output=m(input)
",,,
"
 class torch.nn. LazyConv1d ( out_channels ,  kernel_size ,  stride ,  padding ,  dilation ,  groups ,  bias ,  padding_mode ,  device ,  dtype ) [source] ¶","A  torch.nn.Conv1d  module with lazy initialization of
the  in_channels  argument of the  Conv1d  that is inferred from
the  input.size(1) .
The attributes that will be lazily initialized are  weight  and  bias . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 See also 
 torch.nn.Conv1d 
 
 
 
 alias of ",,,,
"
 class torch.nn. LazyConv2d ( out_channels ,  kernel_size ,  stride ,  padding ,  dilation ,  groups ,  bias ,  padding_mode ,  device ,  dtype ) [source] ¶","A  torch.nn.Conv2d  module with lazy initialization of
the  in_channels  argument of the  Conv2d  that is inferred from
the  input.size(1) .
The attributes that will be lazily initialized are  weight  and  bias . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 See also 
 torch.nn.Conv2d 
 
 
 
 alias of ",,,,
"
 class torch.nn. LazyConv3d ( out_channels ,  kernel_size ,  stride ,  padding ,  dilation ,  groups ,  bias ,  padding_mode ,  device ,  dtype ) [source] ¶","A  torch.nn.Conv3d  module with lazy initialization of
the  in_channels  argument of the  Conv3d  that is inferred from
the  input.size(1) .
The attributes that will be lazily initialized are  weight  and  bias . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 See also 
 torch.nn.Conv3d 
 
 
 
 alias of ",,,,
"
 class torch.nn. LazyConvTranspose1d ( out_channels ,  kernel_size ,  stride ,  padding ,  output_padding ,  groups ,  bias ,  dilation ,  padding_mode ,  device ,  dtype ) [source] ¶","A  torch.nn.ConvTranspose1d  module with lazy initialization of
the  in_channels  argument of the  ConvTranspose1d  that is inferred from
the  input.size(1) .
The attributes that will be lazily initialized are  weight  and  bias . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 See also 
 torch.nn.ConvTranspose1d 
 
 
 
 alias of ",,,,
"
 class torch.nn. LazyConvTranspose2d ( out_channels ,  kernel_size ,  stride ,  padding ,  output_padding ,  groups ,  bias ,  dilation ,  padding_mode ,  device ,  dtype ) [source] ¶","A  torch.nn.ConvTranspose2d  module with lazy initialization of
the  in_channels  argument of the  ConvTranspose2d  that is inferred from
the  input.size(1) .
The attributes that will be lazily initialized are  weight  and  bias . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 See also 
 torch.nn.ConvTranspose2d 
 
 
 
 alias of ",,,,
"
 class torch.nn. LazyConvTranspose3d ( out_channels ,  kernel_size ,  stride ,  padding ,  output_padding ,  groups ,  bias ,  dilation ,  padding_mode ,  device ,  dtype ) [source] ¶","A  torch.nn.ConvTranspose3d  module with lazy initialization of
the  in_channels  argument of the  ConvTranspose3d  that is inferred from
the  input.size(1) .
The attributes that will be lazily initialized are  weight  and  bias . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 See also 
 torch.nn.ConvTranspose3d 
 
 
 
 alias of ",,,,
"
 class torch.nn. Unfold ( kernel_size ,  dilation ,  padding ,  stride ) [source] ¶","Extracts sliding local blocks from a batched input tensor. Consider a batched  input  tensor of shape  ( ,
where  N  is the batch dimension,  C  is the channel dimension,
and  ∗  represent arbitrary spatial dimensions. This operation flattens
each sliding  kernel_size -sized block within the spatial dimensions
of  input  into a column (i.e., last dimension) of a 3-D  output 
tensor of shape  ( , where
 C  is the total number of values
within each block (a block has  ∏  spatial
locations each containing a  C -channeled vector), and  L  is
the total number of such blocks: 
 L where  spatial_size  is formed by the spatial dimensions
of  input  ( ∗  above), and  d  is over all spatial
dimensions. Therefore, indexing  output  at the last dimension (column dimension)
gives all values within a certain block. The  padding ,  stride  and  dilation  arguments specify
how the sliding blocks are retrieved. 
 stride 
 padding 
 dilation 
 
 Parameters 
 
 
 
 If  
 For the case of two input spatial dimensions this operation is sometimes
called  
 
 Note 
 Fold 
 In general, folding and unfolding operations are related as
follows. Consider  
 
 Then for any (supported)  
 
 where  
 
 When the  
 
 Warning 
 Currently, only 4-D input tensors (batched image-like tensors) are
supported. 
 
 Shape: 
 
 Examples: 
",">>> unfold=nn.Unfold(kernel_size=(2,3))
>>> input=torch.randn(2,5,3,4)
>>> output=unfold(input)
>>> # each patch contains 30 values (2x3=6 vectors, each of 5 channels)
>>> # 4 blocks (2x3 kernels) in total in the 3x4 input
>>> output.size()
torch.Size([2, 30, 4])>>> # Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)
>>> inp=torch.randn(1,3,10,12)
>>> w=torch.randn(2,3,4,5)
>>> inp_unf=torch.nn.functional.unfold(inp,(4,5))
>>> out_unf=inp_unf.transpose(1,2).matmul(w.view(w.size(0),-1).t()).transpose(1,2)
>>> out=torch.nn.functional.fold(out_unf,(7,8),(1,1))
>>> # or equivalently (and avoiding a copy),
>>> # out = out_unf.view(1, 2, 7, 8)
>>> (torch.nn.functional.conv2d(inp,w)-out).abs().max()
tensor(1.9073e-06)
",,,
"
 class torch.nn. Fold ( output_size ,  kernel_size ,  dilation ,  padding ,  stride ) [source] ¶","Combines an array of sliding local blocks into a large containing
tensor. Consider a batched  input  tensor containing sliding local blocks,
e.g., patches of images, of shape  ( ,
where  N  is batch dimension,  C 
is the number of values within a block (a block has  ∏ 
spatial locations each containing a  C -channeled vector), and
 L  is the total number of blocks. (This is exactly the
same specification as the output shape of  Unfold .) This
operation combines these local blocks into the large  output  tensor
of shape  ( 
by summing the overlapping values. Similar to  Unfold , the
arguments must satisfy 
 L where  d  is over all spatial dimensions. 
 output_size 
 The  padding ,  stride  and  dilation  arguments specify
how the sliding blocks are retrieved. 
 stride 
 padding 
 dilation 
 
 Parameters 
 
 
 
 If  
 For the case of two output spatial dimensions this operation is sometimes
called  
 
 Note 
 Fold 
 In general, folding and unfolding operations are related as
follows. Consider  
 
 Then for any (supported)  
 
 where  
 
 When the  
 
 Warning 
 Currently, only unbatched (3D) or batched (4D) image-like output tensors are supported. 
 
 Shape: 
 
 Examples: 
",">>> fold=nn.Fold(output_size=(4,5),kernel_size=(2,2))
>>> input=torch.randn(1,3*2*2,12)
>>> output=fold(input)
>>> output.size()
torch.Size([1, 3, 4, 5])
",,,
"
 class torch.nn. MaxPool1d ( kernel_size ,  stride ,  padding ,  dilation ,  return_indices ,  ceil_mode ) [source] ¶","Applies a 1D max pooling over an input signal composed of several input
planes. In the simplest case, the output value of the layer with input size  ( 
and output  (  can be precisely described as: 
 o If  padding  is non-zero, then the input is implicitly padded with negative infinity on both sides
for  padding  number of points.  dilation  is the stride between the elements within the
sliding window. This  link  has a nice visualization of the pooling parameters. 
 Note 
 When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding
or the input. Sliding windows that would start in the right padded region are ignored. 
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # pool of size=3, stride=2
>>> m=nn.MaxPool1d(3,stride=2)
>>> input=torch.randn(20,16,50)
>>> output=m(input)
",,,
"
 class torch.nn. MaxPool2d ( kernel_size ,  stride ,  padding ,  dilation ,  return_indices ,  ceil_mode ) [source] ¶","Applies a 2D max pooling over an input signal composed of several input
planes. In the simplest case, the output value of the layer with input size  ( ,
output  (  and  kernel_size   ( 
can be precisely described as: 
 o If  padding  is non-zero, then the input is implicitly padded with negative infinity on both sides
for  padding  number of points.  dilation  controls the spacing between the kernel points.
It is harder to describe, but this  link  has a nice visualization of what  dilation  does. 
 Note 
 When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding
or the input. Sliding windows that would start in the right padded region are ignored. 
 The parameters  kernel_size ,  stride ,  padding ,  dilation  can either be: 
 
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # pool of square window of size=3, stride=2
>>> m=nn.MaxPool2d(3,stride=2)
>>> # pool of non-square window
>>> m=nn.MaxPool2d((3,2),stride=(2,1))
>>> input=torch.randn(20,16,50,32)
>>> output=m(input)
",,,
"
 class torch.nn. MaxPool3d ( kernel_size ,  stride ,  padding ,  dilation ,  return_indices ,  ceil_mode ) [source] ¶","Applies a 3D max pooling over an input signal composed of several input
planes. In the simplest case, the output value of the layer with input size  ( ,
output  (  and  kernel_size   ( 
can be precisely described as: 
 out If  padding  is non-zero, then the input is implicitly padded with negative infinity on both sides
for  padding  number of points.  dilation  controls the spacing between the kernel points.
It is harder to describe, but this  link  has a nice visualization of what  dilation  does. 
 Note 
 When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding
or the input. Sliding windows that would start in the right padded region are ignored. 
 The parameters  kernel_size ,  stride ,  padding ,  dilation  can either be: 
 
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # pool of square window of size=3, stride=2
>>> m=nn.MaxPool3d(3,stride=2)
>>> # pool of non-square window
>>> m=nn.MaxPool3d((3,2,2),stride=(2,1,2))
>>> input=torch.randn(20,16,50,44,31)
>>> output=m(input)
",,,
"
 class torch.nn. MaxUnpool1d ( kernel_size ,  stride ,  padding ) [source] ¶","Computes a partial inverse of  MaxPool1d . MaxPool1d  is not fully invertible, since the non-maximal values are lost. MaxUnpool1d  takes in as input the output of  MaxPool1d 
including the indices of the maximal values and computes a partial inverse
in which all non-maximal values are set to zero. 
 Note 
 MaxPool1d 
 
 Parameters 
 
 
 
 Inputs: 
 
 Shape: 
 
 Example: 
",">>> pool=nn.MaxPool1d(2,stride=2,return_indices=True)
>>> unpool=nn.MaxUnpool1d(2,stride=2)
>>> input=torch.tensor([[[1.,2,3,4,5,6,7,8]]])
>>> output,indices=pool(input)
>>> unpool(output,indices)
tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])>>> # Example showcasing the use of output_size
>>> input=torch.tensor([[[1.,2,3,4,5,6,7,8,9]]])
>>> output,indices=pool(input)
>>> unpool(output,indices,output_size=input.size())
tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.,  0.]]])>>> unpool(output,indices)
tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])
",,,
"
 class torch.nn. MaxUnpool2d ( kernel_size ,  stride ,  padding ) [source] ¶","Computes a partial inverse of  MaxPool2d . MaxPool2d  is not fully invertible, since the non-maximal values are lost. MaxUnpool2d  takes in as input the output of  MaxPool2d 
including the indices of the maximal values and computes a partial inverse
in which all non-maximal values are set to zero. 
 Note 
 MaxPool2d 
 
 Parameters 
 
 
 
 Inputs: 
 
 Shape: 
 
 Example: 
",">>> pool=nn.MaxPool2d(2,stride=2,return_indices=True)
>>> unpool=nn.MaxUnpool2d(2,stride=2)
>>> input=torch.tensor([[[[1.,2.,3.,4.],
                            [ 5.,  6.,  7.,  8.],
                            [ 9., 10., 11., 12.],
                            [13., 14., 15., 16.]]]])
>>> output,indices=pool(input)
>>> unpool(output,indices)
tensor([[[[  0.,   0.,   0.,   0.],
          [  0.,   6.,   0.,   8.],
          [  0.,   0.,   0.,   0.],
          [  0.,  14.,   0.,  16.]]]])
>>> # Now using output_size to resolve an ambiguous size for the inverse
>>> input=torch.torch.tensor([[[[1.,2.,3.,4.,5.],
                                  [ 6.,  7.,  8., 9., 10.],
                                  [11., 12., 13., 14., 15.],
                                  [16., 17., 18., 19., 20.]]]])
>>> output,indices=pool(input)
>>> # This call will not work without specifying output_size
>>> unpool(output,indices,output_size=input.size())
tensor([[[[ 0.,  0.,  0.,  0.,  0.],
          [ 0.,  7.,  0.,  9.,  0.],
          [ 0.,  0.,  0.,  0.,  0.],
          [ 0., 17.,  0., 19.,  0.]]]])
",,,
"
 class torch.nn. MaxUnpool3d ( kernel_size ,  stride ,  padding ) [source] ¶","Computes a partial inverse of  MaxPool3d . MaxPool3d  is not fully invertible, since the non-maximal values are lost.
 MaxUnpool3d  takes in as input the output of  MaxPool3d 
including the indices of the maximal values and computes a partial inverse
in which all non-maximal values are set to zero. 
 Note 
 MaxPool3d 
 
 Parameters 
 
 
 
 Inputs: 
 
 Shape: 
 
 Example: 
",">>> # pool of square window of size=3, stride=2
>>> pool=nn.MaxPool3d(3,stride=2,return_indices=True)
>>> unpool=nn.MaxUnpool3d(3,stride=2)
>>> output,indices=pool(torch.randn(20,16,51,33,15))
>>> unpooled_output=unpool(output,indices)
>>> unpooled_output.size()
torch.Size([20, 16, 51, 33, 15])
",,,
"
 class torch.nn. AvgPool1d ( kernel_size ,  stride ,  padding ,  ceil_mode ,  count_include_pad ) [source] ¶","Applies a 1D average pooling over an input signal composed of several
input planes. In the simplest case, the output value of the layer with input size  ( ,
output  (  and  kernel_size   k 
can be precisely described as: 
 out If  padding  is non-zero, then the input is implicitly zero-padded on both sides
for  padding  number of points. 
 Note 
 When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding
or the input. Sliding windows that would start in the right padded region are ignored. 
 The parameters  kernel_size ,  stride ,  padding  can each be
an  int  or a one-element tuple. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # pool with window of size=3, stride=2
>>> m=nn.AvgPool1d(3,stride=2)
>>> m(torch.tensor([[[1.,2,3,4,5,6,7]]]))
tensor([[[2., 4., 6.]]])
",,,
"
 class torch.nn. AvgPool2d ( kernel_size ,  stride ,  padding ,  ceil_mode ,  count_include_pad ,  divisor_override ) [source] ¶","Applies a 2D average pooling over an input signal composed of several input
planes. In the simplest case, the output value of the layer with input size  ( ,
output  (  and  kernel_size   ( 
can be precisely described as: 
 o If  padding  is non-zero, then the input is implicitly zero-padded on both sides
for  padding  number of points. 
 Note 
 When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding
or the input. Sliding windows that would start in the right padded region are ignored. 
 The parameters  kernel_size ,  stride ,  padding  can either be: 
 
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # pool of square window of size=3, stride=2
>>> m=nn.AvgPool2d(3,stride=2)
>>> # pool of non-square window
>>> m=nn.AvgPool2d((3,2),stride=(2,1))
>>> input=torch.randn(20,16,50,32)
>>> output=m(input)
",,,
"
 class torch.nn. AvgPool3d ( kernel_size ,  stride ,  padding ,  ceil_mode ,  count_include_pad ,  divisor_override ) [source] ¶","Applies a 3D average pooling over an input signal composed of several input
planes. In the simplest case, the output value of the layer with input size  ( ,
output  (  and  kernel_size   ( 
can be precisely described as: 
 out If  padding  is non-zero, then the input is implicitly zero-padded on all three sides
for  padding  number of points. 
 Note 
 When ceil_mode=True, sliding windows are allowed to go off-bounds if they start within the left padding
or the input. Sliding windows that would start in the right padded region are ignored. 
 The parameters  kernel_size ,  stride  can either be: 
 
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # pool of square window of size=3, stride=2
>>> m=nn.AvgPool3d(3,stride=2)
>>> # pool of non-square window
>>> m=nn.AvgPool3d((3,2,2),stride=(2,1,2))
>>> input=torch.randn(20,16,50,44,31)
>>> output=m(input)
",,,
"
 class torch.nn. FractionalMaxPool2d ( kernel_size ,  output_size ,  output_ratio ,  return_indices ,  _random_samples ) [source] ¶","Applies a 2D fractional max pooling over an input signal composed of several input planes. Fractional MaxPooling is described in detail in the paper  Fractional MaxPooling  by Ben Graham The max-pooling operation is applied in  k  regions by a stochastic
step size determined by the target output size.
The number of output features is equal to the number of input planes. 
 Parameters 
 
 
 
 Shape: 
 
 Examples 
",,,,
"
 class torch.nn. FractionalMaxPool3d ( kernel_size ,  output_size ,  output_ratio ,  return_indices ,  _random_samples ) [source] ¶","Applies a 3D fractional max pooling over an input signal composed of several input planes. Fractional MaxPooling is described in detail in the paper  Fractional MaxPooling  by Ben Graham The max-pooling operation is applied in  k  regions by a stochastic
step size determined by the target output size.
The number of output features is equal to the number of input planes. 
 Parameters 
 
 
 
 Shape: 
 
 Examples 
",,,,
"
 class torch.nn. LPPool1d ( norm_type ,  kernel_size ,  stride ,  ceil_mode ) [source] ¶","Applies a 1D power-average pooling over an input signal composed of several input
planes. On each window, the function computed is: 
 f 
 At p =  
 At p = 1, one gets Sum Pooling (which is proportional to Average Pooling) 
 
 Note 
 If the sum to the power of  
 
 Parameters 
 
 
 
 Shape: 
 
 Examples:: 
",,,,
"
 class torch.nn. LPPool2d ( norm_type ,  kernel_size ,  stride ,  ceil_mode ) [source] ¶","Applies a 2D power-average pooling over an input signal composed of several input
planes. On each window, the function computed is: 
 f 
 At p =  
 At p = 1, one gets Sum Pooling (which is proportional to average pooling) 
 The parameters  kernel_size ,  stride  can either be: 
 
 
 Note 
 If the sum to the power of  
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # power-2 pool of square window of size=3, stride=2
>>> m=nn.LPPool2d(2,3,stride=2)
>>> # pool of non-square window of power 1.2
>>> m=nn.LPPool2d(1.2,(3,2),stride=(2,1))
>>> input=torch.randn(20,16,50,32)
>>> output=m(input)
",,,
"
 class torch.nn. AdaptiveMaxPool1d ( output_size ,  return_indices ) [source] ¶","Applies a 1D adaptive max pooling over an input signal composed of several input planes. The output size is  L , for any input size.
The number of output features is equal to the number of input planes. 
 Parameters 
 
 
 
 Shape: 
 
 Examples 
",,,,
"
 class torch.nn. AdaptiveMaxPool2d ( output_size ,  return_indices ) [source] ¶","Applies a 2D adaptive max pooling over an input signal composed of several input planes. The output is of size  H , for any input size.
The number of output features is equal to the number of input planes. 
 Parameters 
 
 
 
 Shape: 
 
 Examples 
",,,,
"
 class torch.nn. AdaptiveMaxPool3d ( output_size ,  return_indices ) [source] ¶","Applies a 3D adaptive max pooling over an input signal composed of several input planes. The output is of size  D , for any input size.
The number of output features is equal to the number of input planes. 
 Parameters 
 
 
 
 Shape: 
 
 Examples 
",,,,
"
 class torch.nn. AdaptiveAvgPool1d ( output_size ) [source] ¶","Applies a 1D adaptive average pooling over an input signal composed of several input planes. The output size is  L , for any input size.
The number of output features is equal to the number of input planes. 
 Parameters 
 output_size 
 
 Shape: 
 
 Examples 
",,,,
"
 class torch.nn. AdaptiveAvgPool2d ( output_size ) [source] ¶","Applies a 2D adaptive average pooling over an input signal composed of several input planes. The output is of size H x W, for any input size.
The number of output features is equal to the number of input planes. 
 Parameters 
 output_size 
 
 Shape: 
 
 Examples 
",,,,
"
 class torch.nn. AdaptiveAvgPool3d ( output_size ) [source] ¶","Applies a 3D adaptive average pooling over an input signal composed of several input planes. The output is of size D x H x W, for any input size.
The number of output features is equal to the number of input planes. 
 Parameters 
 output_size 
 
 Shape: 
 
 Examples 
",,,,
"
 class torch.nn. ReflectionPad1d ( padding ) [source] ¶","Pads the input tensor using the reflection of the input boundary. For  N -dimensional padding, use  torch.nn.functional.pad() . 
 Parameters 
 padding 
 
 Shape: 
 
 Examples: 
",">>> m=nn.ReflectionPad1d(2)
>>> input=torch.arange(8,dtype=torch.float).reshape(1,2,4)
>>> input
tensor([[[0., 1., 2., 3.],
         [4., 5., 6., 7.]]])
>>> m(input)
tensor([[[2., 1., 0., 1., 2., 3., 2., 1.],
         [6., 5., 4., 5., 6., 7., 6., 5.]]])
>>> # using different paddings for different sides
>>> m=nn.ReflectionPad1d((3,1))
>>> m(input)
tensor([[[3., 2., 1., 0., 1., 2., 3., 2.],
         [7., 6., 5., 4., 5., 6., 7., 6.]]])
",,,
"
 class torch.nn. ReflectionPad2d ( padding ) [source] ¶","Pads the input tensor using the reflection of the input boundary. For  N -dimensional padding, use  torch.nn.functional.pad() . 
 Parameters 
 padding 
 
 Shape: 
 
 Examples: 
",">>> m=nn.ReflectionPad2d(2)
>>> input=torch.arange(9,dtype=torch.float).reshape(1,1,3,3)
>>> input
tensor([[[[0., 1., 2.],
          [3., 4., 5.],
          [6., 7., 8.]]]])
>>> m(input)
tensor([[[[8., 7., 6., 7., 8., 7., 6.],
          [5., 4., 3., 4., 5., 4., 3.],
          [2., 1., 0., 1., 2., 1., 0.],
          [5., 4., 3., 4., 5., 4., 3.],
          [8., 7., 6., 7., 8., 7., 6.],
          [5., 4., 3., 4., 5., 4., 3.],
          [2., 1., 0., 1., 2., 1., 0.]]]])
>>> # using different paddings for different sides
>>> m=nn.ReflectionPad2d((1,1,2,0))
>>> m(input)
tensor([[[[7., 6., 7., 8., 7.],
          [4., 3., 4., 5., 4.],
          [1., 0., 1., 2., 1.],
          [4., 3., 4., 5., 4.],
          [7., 6., 7., 8., 7.]]]])
",,,
"
 class torch.nn. ReflectionPad3d ( padding ) [source] ¶","Pads the input tensor using the reflection of the input boundary. For  N -dimensional padding, use  torch.nn.functional.pad() . 
 Parameters 
 padding 
 
 Shape: 
 
 Examples: 
",">>> m=nn.ReflectionPad3d(1)
>>> input=torch.arange(8,dtype=torch.float).reshape(1,1,2,2,2)
>>> m(input)
tensor([[[[[7., 6., 7., 6.],
           [5., 4., 5., 4.],
           [7., 6., 7., 6.],
           [5., 4., 5., 4.]],
          [[3., 2., 3., 2.],
           [1., 0., 1., 0.],
           [3., 2., 3., 2.],
           [1., 0., 1., 0.]],
          [[7., 6., 7., 6.],
           [5., 4., 5., 4.],
           [7., 6., 7., 6.],
           [5., 4., 5., 4.]],
          [[3., 2., 3., 2.],
           [1., 0., 1., 0.],
           [3., 2., 3., 2.],
           [1., 0., 1., 0.]]]]])
",,,
"
 class torch.nn. ReplicationPad1d ( padding ) [source] ¶","Pads the input tensor using replication of the input boundary. For  N -dimensional padding, use  torch.nn.functional.pad() . 
 Parameters 
 padding 
 
 Shape: 
 
 Examples: 
",">>> m=nn.ReplicationPad1d(2)
>>> input=torch.arange(8,dtype=torch.float).reshape(1,2,4)
>>> input
tensor([[[0., 1., 2., 3.],
         [4., 5., 6., 7.]]])
>>> m(input)
tensor([[[0., 0., 0., 1., 2., 3., 3., 3.],
         [4., 4., 4., 5., 6., 7., 7., 7.]]])
>>> # using different paddings for different sides
>>> m=nn.ReplicationPad1d((3,1))
>>> m(input)
tensor([[[0., 0., 0., 0., 1., 2., 3., 3.],
         [4., 4., 4., 4., 5., 6., 7., 7.]]])
",,,
"
 class torch.nn. ReplicationPad2d ( padding ) [source] ¶","Pads the input tensor using replication of the input boundary. For  N -dimensional padding, use  torch.nn.functional.pad() . 
 Parameters 
 padding 
 
 Shape: 
 
 Examples: 
",">>> m=nn.ReplicationPad2d(2)
>>> input=torch.arange(9,dtype=torch.float).reshape(1,1,3,3)
>>> input
tensor([[[[0., 1., 2.],
          [3., 4., 5.],
          [6., 7., 8.]]]])
>>> m(input)
tensor([[[[0., 0., 0., 1., 2., 2., 2.],
          [0., 0., 0., 1., 2., 2., 2.],
          [0., 0., 0., 1., 2., 2., 2.],
          [3., 3., 3., 4., 5., 5., 5.],
          [6., 6., 6., 7., 8., 8., 8.],
          [6., 6., 6., 7., 8., 8., 8.],
          [6., 6., 6., 7., 8., 8., 8.]]]])
>>> # using different paddings for different sides
>>> m=nn.ReplicationPad2d((1,1,2,0))
>>> m(input)
tensor([[[[0., 0., 1., 2., 2.],
          [0., 0., 1., 2., 2.],
          [0., 0., 1., 2., 2.],
          [3., 3., 4., 5., 5.],
          [6., 6., 7., 8., 8.]]]])
",,,
"
 class torch.nn. ReplicationPad3d ( padding ) [source] ¶","Pads the input tensor using replication of the input boundary. For  N -dimensional padding, use  torch.nn.functional.pad() . 
 Parameters 
 padding 
 
 Shape: 
 
 Examples: 
",">>> m=nn.ReplicationPad3d(3)
>>> input=torch.randn(16,3,8,320,480)
>>> output=m(input)
>>> # using different paddings for different sides
>>> m=nn.ReplicationPad3d((3,3,6,6,1,1))
>>> output=m(input)
",,,
"
 class torch.nn. ZeroPad2d ( padding ) [source] ¶","Pads the input tensor boundaries with zero. For  N -dimensional padding, use  torch.nn.functional.pad() . 
 Parameters 
 padding 
 
 Shape: 
 
 Examples: 
",">>> m=nn.ZeroPad2d(2)
>>> input=torch.randn(1,1,3,3)
>>> input
tensor([[[[-0.1678, -0.4418,  1.9466],
          [ 0.9604, -0.4219, -0.5241],
          [-0.9162, -0.5436, -0.6446]]]])
>>> m(input)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.1678, -0.4418,  1.9466,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.9604, -0.4219, -0.5241,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9162, -0.5436, -0.6446,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])
>>> # using different paddings for different sides
>>> m=nn.ZeroPad2d((1,1,2,0))
>>> m(input)
tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.1678, -0.4418,  1.9466,  0.0000],
          [ 0.0000,  0.9604, -0.4219, -0.5241,  0.0000],
          [ 0.0000, -0.9162, -0.5436, -0.6446,  0.0000]]]])
",,,
"
 class torch.nn. ConstantPad1d ( padding ,  value ) [source] ¶","Pads the input tensor boundaries with a constant value. For  N -dimensional padding, use  torch.nn.functional.pad() . 
 Parameters 
 padding 
 
 Shape: 
 
 Examples: 
",">>> m=nn.ConstantPad1d(2,3.5)
>>> input=torch.randn(1,2,4)
>>> input
tensor([[[-1.0491, -0.7152, -0.0749,  0.8530],
         [-1.3287,  1.8966,  0.1466, -0.2771]]])
>>> m(input)
tensor([[[ 3.5000,  3.5000, -1.0491, -0.7152, -0.0749,  0.8530,  3.5000,
           3.5000],
         [ 3.5000,  3.5000, -1.3287,  1.8966,  0.1466, -0.2771,  3.5000,
           3.5000]]])
>>> m=nn.ConstantPad1d(2,3.5)
>>> input=torch.randn(1,2,3)
>>> input
tensor([[[ 1.6616,  1.4523, -1.1255],
         [-3.6372,  0.1182, -1.8652]]])
>>> m(input)
tensor([[[ 3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000,  3.5000],
         [ 3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000,  3.5000]]])
>>> # using different paddings for different sides
>>> m=nn.ConstantPad1d((3,1),3.5)
>>> m(input)
tensor([[[ 3.5000,  3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000],
         [ 3.5000,  3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000]]])
",,,
"
 class torch.nn. ConstantPad2d ( padding ,  value ) [source] ¶","Pads the input tensor boundaries with a constant value. For  N -dimensional padding, use  torch.nn.functional.pad() . 
 Parameters 
 padding 
 
 Shape: 
 
 Examples: 
",">>> m=nn.ConstantPad2d(2,3.5)
>>> input=torch.randn(1,2,2)
>>> input
tensor([[[ 1.6585,  0.4320],
         [-0.8701, -0.4649]]])
>>> m(input)
tensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],
         [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],
         [ 3.5000,  3.5000,  1.6585,  0.4320,  3.5000,  3.5000],
         [ 3.5000,  3.5000, -0.8701, -0.4649,  3.5000,  3.5000],
         [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],
         [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])
>>> # using different paddings for different sides
>>> m=nn.ConstantPad2d((3,0,2,1),3.5)
>>> m(input)
tensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],
         [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],
         [ 3.5000,  3.5000,  3.5000,  1.6585,  0.4320],
         [ 3.5000,  3.5000,  3.5000, -0.8701, -0.4649],
         [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])
",,,
"
 class torch.nn. ConstantPad3d ( padding ,  value ) [source] ¶","Pads the input tensor boundaries with a constant value. For  N -dimensional padding, use  torch.nn.functional.pad() . 
 Parameters 
 padding 
 
 Shape: 
 
 Examples: 
",">>> m=nn.ConstantPad3d(3,3.5)
>>> input=torch.randn(16,3,10,20,30)
>>> output=m(input)
>>> # using different paddings for different sides
>>> m=nn.ConstantPad3d((3,3,6,6,0,1),3.5)
>>> output=m(input)
",,,
"
 class torch.nn. ELU ( alpha ,  inplace ) [source] ¶","Applies the Exponential Linear Unit (ELU) function, element-wise, as described
in the paper:  Fast and Accurate Deep Network Learning by Exponential Linear
Units (ELUs) . ELU is defined as: 
 ELU 
 Parameters 
 
 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. Hardshrink ( lambd ) [source] ¶","Applies the Hard Shrinkage (Hardshrink) function element-wise. Hardshrink is defined as: 
 HardShrink 
 Parameters 
 lambd 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. Hardsigmoid ( inplace ) [source] ¶","Applies the Hardsigmoid function element-wise. Hardsigmoid is defined as: 
 Hardsigmoid 
 Parameters 
 inplace 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. Hardtanh ( min_val ,  max_val ,  inplace ,  min_value ,  max_value ) [source] ¶","Applies the HardTanh function element-wise. HardTanh is defined as: 
 HardTanh 
 Parameters 
 
 
 Keyword arguments  min_value  and  max_value 
have been deprecated in favor of  min_val  and  max_val . 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. Hardswish ( inplace ) [source] ¶","Applies the Hardswish function, element-wise, as described in the paper:
 Searching for MobileNetV3 . Hardswish is defined as: 
 Hardswish 
 Parameters 
 inplace 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. LeakyReLU ( negative_slope ,  inplace ) [source] ¶","Applies the element-wise function: 
 LeakyReLU or 
 LeakyReLU 
 Parameters 
 
 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. LogSigmoid [source] ¶","Applies the element-wise function: 
 LogSigmoid 
 Shape: 
 
 
 Examples: 
 
 
 
",,,,
"
 class torch.nn. MultiheadAttention ( embed_dim ,  num_heads ,  dropout ,  bias ,  add_bias_kv ,  add_zero_attn ,  kdim ,  vdim ,  batch_first ,  device ,  dtype ) [source] ¶","Allows the model to jointly attend to information
from different representation subspaces as described in the paper:
 Attention Is All You Need . Multi-Head Attention is defined as: 
 MultiHead where  h . forward()  will use a special optimized implementation if all of the following
conditions are met: 
 self attention is being computed (i.e.,  
 Either autograd is disabled (using  
 training is disabled (using  
 dropout is 0 
 add_bias_kv 
 add_zero_attn 
 batch_first 
 kdim 
 at most one of  
 if a  
 If the optimized implementation is in use, a
 NestedTensor  can be passed for
 query / key / value  to represent padding more efficiently than using a
padding mask. In this case, a  NestedTensor 
will be returned, and an additional speedup proportional to the fraction of the input
that is padding can be expected. 
 Parameters 
 
 
 Examples: 
 
 
 
 
",">>> multihead_attn=nn.MultiheadAttention(embed_dim,num_heads)
>>> attn_output,attn_output_weights=multihead_attn(query,key,value)
",,,
"
 class torch.nn. PReLU ( num_parameters ,  init ,  device ,  dtype ) [source] ¶","Applies the element-wise function: 
 PReLU or 
 PReLU Here  a  is a learnable parameter. When called without arguments,  nn.PReLU()  uses a single
parameter  a  across all input channels. If called with  nn.PReLU(nChannels) ,
a separate  a  is used for each input channel. 
 Note 
 weight decay should not be used when learning  
 
 Note 
 Channel dim is the 2nd dim of input. When input has dims < 2, then there is
no channel dim and the number of channels = 1. 
 
 Parameters 
 
 
 
 Shape: 
 
 
 Variables 
 weight 
 
 Examples: 
 
",,,,
"
 class torch.nn. ReLU ( inplace ) [source] ¶","Applies the rectified linear unit function element-wise: ReLU 
 Parameters 
 inplace 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. ReLU6 ( inplace ) [source] ¶","Applies the element-wise function: 
 ReLU6 
 Parameters 
 inplace 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. RReLU ( lower ,  upper ,  inplace ) [source] ¶","Applies the randomized leaky rectified liner unit function, element-wise,
as described in the paper: Empirical Evaluation of Rectified Activations in Convolutional Network . The function is defined as: 
 RReLU where  a  is randomly sampled from uniform distribution
 U . 
 See:  
 Parameters 
 
 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. SELU ( inplace ) [source] ¶","Applied element-wise, as: 
 SELU with  α  and
 scale . 
 Warning 
 When using  
 More details can be found in the paper  Self-Normalizing Neural Networks  . 
 Parameters 
 inplace 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. CELU ( alpha ,  inplace ) [source] ¶","Applies the element-wise function: 
 CELU More details can be found in the paper  Continuously Differentiable Exponential Linear Units  . 
 Parameters 
 
 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. GELU ( approximate ) [source] ¶","Applies the Gaussian Error Linear Units function: 
 GELU where  Φ  is the Cumulative Distribution Function for Gaussian Distribution. When the approximate argument is ‘tanh’, Gelu is estimated with: 
 GELU 
 Parameters 
 approximate 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. Sigmoid [source] ¶","Applies the element-wise function: 
 Sigmoid 
 Shape: 
 
 
 Examples: 
 
 
 
",,,,
"
 class torch.nn. SiLU ( inplace ) [source] ¶","Applies the Sigmoid Linear Unit (SiLU) function, element-wise.
The SiLU function is also known as the swish function. 
 silu 
 Note 
 See  
 
 Shape: 
 
 
 Examples: 
 
 
 
",,,,
"
 class torch.nn. Mish ( inplace ) [source] ¶","Applies the Mish function, element-wise.
Mish: A Self Regularized Non-Monotonic Neural Activation Function. 
 Mish 
 Note 
 See  
 
 Shape: 
 
 
 Examples: 
 
 
 
",,,,
"
 class torch.nn. Softplus ( beta ,  threshold ) [source] ¶","Applies the Softplus function  Softplus  element-wise. SoftPlus is a smooth approximation to the ReLU function and can be used
to constrain the output of a machine to always be positive. For numerical stability the implementation reverts to the linear function
when  i . 
 Parameters 
 
 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. Softshrink ( lambd ) [source] ¶","Applies the soft shrinkage function elementwise: 
 SoftShrinkage 
 Parameters 
 lambd 
 
 Shape: 
 
 
 Examples: 
 
",,,,
"
 class torch.nn. Softsign [source] ¶","Applies the element-wise function: 
 SoftSign 
 Shape: 
 
 
 Examples: 
 
 
 
",,,,
"
 class torch.nn. Tanh [source] ¶","Applies the Hyperbolic Tangent (Tanh) function element-wise. Tanh is defined as: 
 Tanh 
 Shape: 
 
 
 Examples: 
 
 
 
",,,,
"
 class torch.nn. Tanhshrink [source] ¶","Applies the element-wise function: 
 Tanhshrink 
 Shape: 
 
 
 Examples: 
 
 
 
",,,,
"
 class torch.nn. Threshold ( threshold ,  value ,  inplace ) [source] ¶","Thresholds each element of the input Tensor. Threshold is defined as: 
 y 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> m=nn.Threshold(0.1,20)
>>> input=torch.randn(2)
>>> output=m(input)
",,,
"
 class torch.nn. GLU ( dim ) [source] ¶","Applies the gated linear unit function
 G  where  a  is the first half
of the input matrices and  b  is the second half. 
 Parameters 
 dim 
 
 Shape: 
 
 Examples: 
",">>> m=nn.GLU()
>>> input=torch.randn(4,2)
>>> output=m(input)
",,,
"
 class torch.nn. Softmin ( dim ) [source] ¶","Applies the Softmin function to an n-dimensional input Tensor
rescaling them so that the elements of the n-dimensional output Tensor
lie in the range  [0, 1]  and sum to 1. Softmin is defined as: 
 Softmin 
 Shape: 
 
 
 Parameters 
 dim 
 Returns 
 a Tensor of the same dimension and shape as the input, with
values in the range [0, 1] 
 Return type 
 None 
 Examples: 
",">>> m=nn.Softmin(dim=1)
>>> input=torch.randn(2,3)
>>> output=m(input)
",,,
"
 class torch.nn. Softmax ( dim ) [source] ¶","Applies the Softmax function to an n-dimensional input Tensor
rescaling them so that the elements of the n-dimensional output Tensor
lie in the range [0,1] and sum to 1. Softmax is defined as: 
 Softmax When the input Tensor is a sparse tensor then the unspecifed
values are treated as  -inf . 
 Shape: 
 
 
 Returns 
 a Tensor of the same dimension and shape as the input with
values in the range [0, 1] 
 Parameters 
 dim 
 Return type 
 None 
 
 Note 
 This module doesn’t work directly with NLLLoss,
which expects the Log to be computed between the Softmax and itself.
Use  
 Examples: 
",">>> m=nn.Softmax(dim=1)
>>> input=torch.randn(2,3)
>>> output=m(input)
",,,
"
 class torch.nn. Softmax2d [source] ¶","Applies SoftMax over features to each spatial location. When given an image of  Channels , it will
apply  Softmax  to each location  ( 
 Shape: 
 
 
 Returns 
 a Tensor of the same dimension and shape as the input with
values in the range [0, 1] 
 Return type 
 None 
 Examples: 
",">>> m=nn.Softmax2d()
>>> # you softmax over the 2nd dimension
>>> input=torch.randn(2,3,12,13)
>>> output=m(input)
",,,
"
 class torch.nn. LogSoftmax ( dim ) [source] ¶","Applies the  log  function to an n-dimensional
input Tensor. The LogSoftmax formulation can be simplified as: 
 LogSoftmax 
 Shape: 
 
 
 Parameters 
 dim 
 Returns 
 a Tensor of the same dimension and shape as the input with
values in the range [-inf, 0) 
 Return type 
 None 
 Examples: 
",">>> m=nn.LogSoftmax(dim=1)
>>> input=torch.randn(2,3)
>>> output=m(input)
",,,
"
 class torch.nn. AdaptiveLogSoftmaxWithLoss ( in_features ,  n_classes ,  cutoffs ,  div_value ,  head_bias ,  device ,  dtype ) [source] ¶","Efficient softmax approximation as described in
 Efficient softmax approximation for GPUs by Edouard Grave, Armand Joulin,
Moustapha Cissé, David Grangier, and Hervé Jégou . Adaptive softmax is an approximate strategy for training models with large
output spaces. It is most effective when the label distribution is highly
imbalanced, for example in natural language modelling, where the word
frequency distribution approximately follows the  Zipf’s law . Adaptive softmax partitions the labels into several clusters, according to
their frequency. These clusters may contain different number of targets
each.
Additionally, clusters containing less frequent labels assign lower
dimensional embeddings to those labels, which speeds up the computation.
For each minibatch, only clusters for which at least one target is
present are evaluated. The idea is that the clusters which are accessed frequently
(like the first one, containing most frequent labels), should also be cheap
to compute – that is, contain a small number of assigned labels. We highly recommend taking a look at the original paper for more details. 
 cutoffs 
 div_value 
 head_bias 
 
 Warning 
 Labels passed as inputs to this module should be sorted according to
their frequency. This means that the most frequent label should be
represented by the index  
 
 Note 
 This module returns a  
 
 Note 
 To compute log-probabilities for all classes, the  
 
 Parameters 
 
 
 Returns 
 
 
 Return type 
 NamedTuple 
 
 Shape: 
 
 
 
 
 Computes log probabilities for all  
 
 
 This is equivalent to ",,,,
"
 class torch.nn. BatchNorm1d ( num_features ,  eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","Applies Batch Normalization over a 2D or 3D input as described in the paper
 Batch Normalization: Accelerating Deep Network Training by Reducing
Internal Covariate Shift  . 
 y The mean and standard-deviation are calculated per-dimension over
the mini-batches and  γ  and  β  are learnable parameter vectors
of size  C  (where  C  is the number of features or channels of the input). By default, the
elements of  γ  are set to 1 and the elements of  β  are set to 0. The
standard-deviation is calculated via the biased estimator, equivalent to  torch.var(input, unbiased=False) . Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default  momentum 
of 0.1. If  track_running_stats  is set to  False , this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well. 
 Note 
 This  
 Because the Batch Normalization is done over the  C  dimension, computing statistics
on  (N, L)  slices, it’s common terminology to call this Temporal Batch Normalization. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # With Learnable Parameters
>>> m=nn.BatchNorm1d(100)
>>> # Without Learnable Parameters
>>> m=nn.BatchNorm1d(100,affine=False)
>>> input=torch.randn(20,100)
>>> output=m(input)
",,,
"
 class torch.nn. BatchNorm2d ( num_features ,  eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs
with additional channel dimension) as described in the paper
 Batch Normalization: Accelerating Deep Network Training by Reducing
Internal Covariate Shift  . 
 y The mean and standard-deviation are calculated per-dimension over
the mini-batches and  γ  and  β  are learnable parameter vectors
of size  C  (where  C  is the input size). By default, the elements of  γ  are set
to 1 and the elements of  β  are set to 0. The standard-deviation is calculated
via the biased estimator, equivalent to  torch.var(input, unbiased=False) . Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default  momentum 
of 0.1. If  track_running_stats  is set to  False , this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well. 
 Note 
 This  
 Because the Batch Normalization is done over the  C  dimension, computing statistics
on  (N, H, W)  slices, it’s common terminology to call this Spatial Batch Normalization. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # With Learnable Parameters
>>> m=nn.BatchNorm2d(100)
>>> # Without Learnable Parameters
>>> m=nn.BatchNorm2d(100,affine=False)
>>> input=torch.randn(20,100,35,45)
>>> output=m(input)
",,,
"
 class torch.nn. BatchNorm3d ( num_features ,  eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs
with additional channel dimension) as described in the paper
 Batch Normalization: Accelerating Deep Network Training by Reducing
Internal Covariate Shift  . 
 y The mean and standard-deviation are calculated per-dimension over
the mini-batches and  γ  and  β  are learnable parameter vectors
of size  C  (where  C  is the input size). By default, the elements of  γ  are set
to 1 and the elements of  β  are set to 0. The standard-deviation is calculated
via the biased estimator, equivalent to  torch.var(input, unbiased=False) . Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default  momentum 
of 0.1. If  track_running_stats  is set to  False , this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well. 
 Note 
 This  
 Because the Batch Normalization is done over the  C  dimension, computing statistics
on  (N, D, H, W)  slices, it’s common terminology to call this Volumetric Batch Normalization
or Spatio-temporal Batch Normalization. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # With Learnable Parameters
>>> m=nn.BatchNorm3d(100)
>>> # Without Learnable Parameters
>>> m=nn.BatchNorm3d(100,affine=False)
>>> input=torch.randn(20,100,35,45,10)
>>> output=m(input)
",,,
"
 class torch.nn. LazyBatchNorm1d ( eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","A  torch.nn.BatchNorm1d  module with lazy initialization of
the  num_features  argument of the  BatchNorm1d  that is inferred
from the  input.size(1) .
The attributes that will be lazily initialized are  weight ,  bias ,
 running_mean  and  running_var . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 
 
 alias of ",,,,
"
 class torch.nn. LazyBatchNorm2d ( eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","A  torch.nn.BatchNorm2d  module with lazy initialization of
the  num_features  argument of the  BatchNorm2d  that is inferred
from the  input.size(1) .
The attributes that will be lazily initialized are  weight ,  bias ,
 running_mean  and  running_var . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 
 
 alias of ",,,,
"
 class torch.nn. LazyBatchNorm3d ( eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","A  torch.nn.BatchNorm3d  module with lazy initialization of
the  num_features  argument of the  BatchNorm3d  that is inferred
from the  input.size(1) .
The attributes that will be lazily initialized are  weight ,  bias ,
 running_mean  and  running_var . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 
 
 alias of ",,,,
"
 class torch.nn. GroupNorm ( num_groups ,  num_channels ,  eps ,  affine ,  device ,  dtype ) [source] ¶","Applies Group Normalization over a mini-batch of inputs as described in
the paper  Group Normalization 
 y The input channels are separated into  num_groups  groups, each containing
 num_channels  channels.  num_channels  must be divisible by
 num_groups . The mean and standard-deviation are calculated
separately over the each group.  γ  and  β  are learnable
per-channel affine transform parameter vectors of size  num_channels  if
 affine  is  True .
The standard-deviation is calculated via the biased estimator, equivalent to
 torch.var(input, unbiased=False) . This layer uses statistics computed from input data in both training and
evaluation modes. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> input=torch.randn(20,6,10,10)
>>> # Separate 6 channels into 3 groups
>>> m=nn.GroupNorm(3,6)
>>> # Separate 6 channels into 6 groups (equivalent with InstanceNorm)
>>> m=nn.GroupNorm(6,6)
>>> # Put all 6 channels into a single group (equivalent with LayerNorm)
>>> m=nn.GroupNorm(1,6)
>>> # Activating the module
>>> output=m(input)
",,,
"
 class torch.nn. SyncBatchNorm ( num_features ,  eps ,  momentum ,  affine ,  track_running_stats ,  process_group ,  device ,  dtype ) [source] ¶","Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs
with additional channel dimension) as described in the paper
 Batch Normalization: Accelerating Deep Network Training by Reducing
Internal Covariate Shift  . 
 y The mean and standard-deviation are calculated per-dimension over all
mini-batches of the same process groups.  γ  and  β 
are learnable parameter vectors of size  C  (where  C  is the input size).
By default, the elements of  γ  are sampled from
 U  and the elements of  β  are set to 0.
The standard-deviation is calculated via the biased estimator, equivalent to
 torch.var(input, unbiased=False) . Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default  momentum 
of 0.1. If  track_running_stats  is set to  False , this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well. 
 Note 
 This  
 Because the Batch Normalization is done for each channel in the  C  dimension, computing
statistics on  (N,  slices, it’s common terminology to call this Volumetric Batch
Normalization or Spatio-temporal Batch Normalization. Currently  SyncBatchNorm  only supports
 DistributedDataParallel  (DDP) with single GPU per process. Use
 torch.nn.SyncBatchNorm.convert_sync_batchnorm()  to convert
 BatchNorm*D  layer to  SyncBatchNorm  before wrapping
Network with DDP. 
 Parameters 
 
 
 
 Shape: 
 
 
 Note 
 Synchronization of batchnorm statistics occurs only while training, i.e.
synchronization is disabled when  
 Examples: 
 
 
 
 Helper function to convert all ",">>> # With Learnable Parameters
>>> m=nn.SyncBatchNorm(100)
>>> # creating process group (optional)
>>> # ranks is a list of int identifying rank ids.
>>> ranks=list(range(8))
>>> r1,r2=ranks[:4],ranks[4:]
>>> # Note: every rank calls into new_group for every
>>> # process group created, even if that rank is not
>>> # part of the group.
>>> process_groups=[torch.distributed.new_group(pids)forpidsin[r1,r2]]
>>> process_group=process_groups[0ifdist.get_rank()<=3else1]
>>> # Without Learnable Parameters
>>> m=nn.BatchNorm3d(100,affine=False,process_group=process_group)
>>> input=torch.randn(20,100,35,45,10)
>>> output=m(input)>>> # network is nn.BatchNorm layer
>>> sync_bn_network=nn.SyncBatchNorm.convert_sync_batchnorm(network,process_group)
>>> # only single gpu per process is currently supported
>>> ddp_sync_bn_network=torch.nn.parallel.DistributedDataParallel(
>>> sync_bn_network,
>>> device_ids=[args.local_rank],
>>> output_device=args.local_rank)
",,,
"
 class torch.nn. InstanceNorm1d ( num_features ,  eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","Applies Instance Normalization over a 2D (unbatched) or 3D (batched) input
as described in the paper
 Instance Normalization: The Missing Ingredient for Fast Stylization . 
 y The mean and standard-deviation are calculated per-dimension separately
for each object in a mini-batch.  γ  and  β  are learnable parameter vectors
of size  C  (where  C  is the number of features or channels of the input) if  affine  is  True .
The standard-deviation is calculated via the biased estimator, equivalent to
 torch.var(input, unbiased=False) . By default, this layer uses instance statistics computed from input data in
both training and evaluation modes. If  track_running_stats  is set to  True , during training this
layer keeps running estimates of its computed mean and variance, which are
then used for normalization during evaluation. The running estimates are
kept with a default  momentum  of 0.1. 
 Note 
 This  
 
 Note 
 InstanceNorm1d 
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # Without Learnable Parameters
>>> m=nn.InstanceNorm1d(100)
>>> # With Learnable Parameters
>>> m=nn.InstanceNorm1d(100,affine=True)
>>> input=torch.randn(20,100,40)
>>> output=m(input)
",,,
"
 class torch.nn. InstanceNorm2d ( num_features ,  eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs
with additional channel dimension) as described in the paper
 Instance Normalization: The Missing Ingredient for Fast Stylization . 
 y The mean and standard-deviation are calculated per-dimension separately
for each object in a mini-batch.  γ  and  β  are learnable parameter vectors
of size  C  (where  C  is the input size) if  affine  is  True .
The standard-deviation is calculated via the biased estimator, equivalent to
 torch.var(input, unbiased=False) . By default, this layer uses instance statistics computed from input data in
both training and evaluation modes. If  track_running_stats  is set to  True , during training this
layer keeps running estimates of its computed mean and variance, which are
then used for normalization during evaluation. The running estimates are
kept with a default  momentum  of 0.1. 
 Note 
 This  
 
 Note 
 InstanceNorm2d 
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # Without Learnable Parameters
>>> m=nn.InstanceNorm2d(100)
>>> # With Learnable Parameters
>>> m=nn.InstanceNorm2d(100,affine=True)
>>> input=torch.randn(20,100,35,45)
>>> output=m(input)
",,,
"
 class torch.nn. InstanceNorm3d ( num_features ,  eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs
with additional channel dimension) as described in the paper
 Instance Normalization: The Missing Ingredient for Fast Stylization . 
 y The mean and standard-deviation are calculated per-dimension separately
for each object in a mini-batch.  γ  and  β  are learnable parameter vectors
of size C (where C is the input size) if  affine  is  True .
The standard-deviation is calculated via the biased estimator, equivalent to
 torch.var(input, unbiased=False) . By default, this layer uses instance statistics computed from input data in
both training and evaluation modes. If  track_running_stats  is set to  True , during training this
layer keeps running estimates of its computed mean and variance, which are
then used for normalization during evaluation. The running estimates are
kept with a default  momentum  of 0.1. 
 Note 
 This  
 
 Note 
 InstanceNorm3d 
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # Without Learnable Parameters
>>> m=nn.InstanceNorm3d(100)
>>> # With Learnable Parameters
>>> m=nn.InstanceNorm3d(100,affine=True)
>>> input=torch.randn(20,100,35,45,10)
>>> output=m(input)
",,,
"
 class torch.nn. LazyInstanceNorm1d ( eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","A  torch.nn.InstanceNorm1d  module with lazy initialization of
the  num_features  argument of the  InstanceNorm1d  that is inferred
from the  input.size(1) .
The attributes that will be lazily initialized are  weight ,  bias ,
 running_mean  and  running_var . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 Shape: 
 
 
 
 
 alias of ",,,,
"
 class torch.nn. LazyInstanceNorm2d ( eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","A  torch.nn.InstanceNorm2d  module with lazy initialization of
the  num_features  argument of the  InstanceNorm2d  that is inferred
from the  input.size(1) .
The attributes that will be lazily initialized are  weight ,  bias ,
 running_mean  and  running_var . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 Shape: 
 
 
 
 
 alias of ",,,,
"
 class torch.nn. LazyInstanceNorm3d ( eps ,  momentum ,  affine ,  track_running_stats ,  device ,  dtype ) [source] ¶","A  torch.nn.InstanceNorm3d  module with lazy initialization of
the  num_features  argument of the  InstanceNorm3d  that is inferred
from the  input.size(1) .
The attributes that will be lazily initialized are  weight ,  bias ,
 running_mean  and  running_var . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 
 Shape: 
 
 
 
 
 alias of ",,,,
"
 class torch.nn. LayerNorm ( normalized_shape ,  eps ,  elementwise_affine ,  device ,  dtype ) [source] ¶","Applies Layer Normalization over a mini-batch of inputs as described in
the paper  Layer Normalization 
 y The mean and standard-deviation are calculated over the last  D  dimensions, where  D 
is the dimension of  normalized_shape . For example, if  normalized_shape 
is  (3,  (a 2-dimensional shape), the mean and standard-deviation are computed over
the last 2 dimensions of the input (i.e.  input.mean((-2, ).
 γ  and  β  are learnable affine transform parameters of
 normalized_shape  if  elementwise_affine  is  True .
The standard-deviation is calculated via the biased estimator, equivalent to
 torch.var(input, unbiased=False) . 
 Note 
 Unlike Batch Normalization and Instance Normalization, which applies
scalar scale and bias for each entire channel/plane with the
 
 This layer uses statistics computed from input data in both training and
evaluation modes. 
 Parameters 
 
 
 Variables 
 
 
 
 Shape: 
 
 Examples: 
",">>> # NLP Example
>>> batch,sentence_length,embedding_dim=20,5,10
>>> embedding=torch.randn(batch,sentence_length,embedding_dim)
>>> layer_norm=nn.LayerNorm(embedding_dim)
>>> # Activate module
>>> layer_norm(embedding)
>>>
>>> # Image Example
>>> N,C,H,W=20,5,10,10
>>> input=torch.randn(N,C,H,W)
>>> # Normalize over the last three dimensions (i.e. the channel and spatial dimensions)
>>> # as shown in the image below
>>> layer_norm=nn.LayerNorm([C,H,W])
>>> output=layer_norm(input)
",,,
"
 class torch.nn. LocalResponseNorm ( size ,  alpha ,  beta ,  k ) [source] ¶","Applies local response normalization over an input signal composed
of several input planes, where channels occupy the second dimension.
Applies normalization across channels. 
 b 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> lrn=nn.LocalResponseNorm(2)
>>> signal_2d=torch.randn(32,5,24,24)
>>> signal_4d=torch.randn(16,5,7,7,7,7)
>>> output_2d=lrn(signal_2d)
>>> output_4d=lrn(signal_4d)
",,,
"
 class torch.nn. RNNBase ( mode ,  input_size ,  hidden_size ,  num_layers ,  bias ,  batch_first ,  dropout ,  bidirectional ,  proj_size ,  device ,  dtype ) [source] ¶","
 
 
 
 Resets parameter data pointer so that they can use faster code paths.",,,,
"
 class torch.nn. RNN ( * ,  ** ) [source] ¶","Applies a multi-layer Elman RNN with  tanh  or  ReLU  non-linearity to an
input sequence. For each element in the input sequence, each layer computes the following
function: 
 h where  h  is the hidden state at time  t ,  x  is
the input at time  t , and  h  is the hidden state of the
previous layer at time  t-1  or the initial hidden state at time  0 .
If  nonlinearity  is  'relu' , then  ReLU  is used instead of  tanh . 
 Parameters 
 
 
 
 Inputs: input, h_0 
 
 Outputs: output, h_n 
 
 
 Variables 
 
 
 
 Note 
 All the weights and biases are initialized from  
 
 Note 
 For bidirectional RNNs, forward and backward are directions 0 and 1 respectively.
Example of splitting the output layers when  
 
 Note 
 batch_first 
 
 Warning 
 There are known non-determinism issues for RNN functions on some versions of cuDNN and CUDA.
You can enforce deterministic behavior by setting the following environment variables: 
 On CUDA 10.1, set environment variable  
 On CUDA 10.2 or later, set environment variable
(note the leading colon symbol)
 
 See the  
 
 Note 
 If the following conditions are satisfied:
1) cudnn is enabled,
2) input data is on the GPU
3) input data has dtype  
 Examples: 
",">>> rnn=nn.RNN(10,20,2)
>>> input=torch.randn(5,3,10)
>>> h0=torch.randn(2,3,20)
>>> output,hn=rnn(input,h0)
",,,
"
 class torch.nn. LSTM ( * ,  ** ) [source] ¶","Applies a multi-layer long short-term memory (LSTM) RNN to an input
sequence. For each element in the input sequence, each layer computes the following
function: 
 where  h  is the hidden state at time  t ,  c  is the cell
state at time  t ,  x  is the input at time  t ,  h 
is the hidden state of the layer at time  t-1  or the initial hidden
state at time  0 , and  i ,  f ,  g ,
 o  are the input, forget, cell, and output gates, respectively.
 σ  is the sigmoid function, and  ⊙  is the Hadamard product. In a multilayer LSTM, the input  x  of the  l  -th layer
( l ) is the hidden state  h  of the previous layer multiplied by
dropout  δ  where each  δ  is a Bernoulli random
variable which is  0  with probability  dropout . If  proj_size  is specified, LSTM with projections will be used. This changes
the LSTM cell in the following way. First, the dimension of  h  will be changed from
 hidden_size  to  proj_size  (dimensions of  W  will be changed accordingly).
Second, the output hidden state of each layer will be multiplied by a learnable projection
matrix:  h . Note that as a consequence of this, the output
of LSTM network will be of different shape as well. See Inputs/Outputs sections below for exact
dimensions of all variables. You can find more details in  https://arxiv.org/abs/1402.1128 . 
 Parameters 
 
 
 
 Inputs: input, (h_0, c_0) 
 
 Outputs: output, (h_n, c_n) 
 
 
 Variables 
 
 
 
 Note 
 All the weights and biases are initialized from  
 
 Note 
 For bidirectional LSTMs, forward and backward are directions 0 and 1 respectively.
Example of splitting the output layers when  
 
 Note 
 For bidirectional LSTMs,  
 
 Note 
 batch_first 
 
 Warning 
 There are known non-determinism issues for RNN functions on some versions of cuDNN and CUDA.
You can enforce deterministic behavior by setting the following environment variables: 
 On CUDA 10.1, set environment variable  
 On CUDA 10.2 or later, set environment variable
(note the leading colon symbol)
 
 See the  
 
 Note 
 If the following conditions are satisfied:
1) cudnn is enabled,
2) input data is on the GPU
3) input data has dtype  
 Examples: 
",">>> rnn=nn.LSTM(10,20,2)
>>> input=torch.randn(5,3,10)
>>> h0=torch.randn(2,3,20)
>>> c0=torch.randn(2,3,20)
>>> output,(hn,cn)=rnn(input,(h0,c0))
",,,
"
 class torch.nn. GRU ( * ,  ** ) [source] ¶","Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence. For each element in the input sequence, each layer computes the following
function: 
 r where  h  is the hidden state at time  t ,  x  is the input
at time  t ,  h  is the hidden state of the layer
at time  t-1  or the initial hidden state at time  0 , and  r ,
 z ,  n  are the reset, update, and new gates, respectively.
 σ  is the sigmoid function, and  ∗  is the Hadamard product. In a multilayer GRU, the input  x  of the  l  -th layer
( l ) is the hidden state  h  of the previous layer multiplied by
dropout  δ  where each  δ  is a Bernoulli random
variable which is  0  with probability  dropout . 
 Parameters 
 
 
 
 Inputs: input, h_0 
 
 Outputs: output, h_n 
 
 
 Variables 
 
 
 
 Note 
 All the weights and biases are initialized from  
 
 Note 
 For bidirectional GRUs, forward and backward are directions 0 and 1 respectively.
Example of splitting the output layers when  
 
 Note 
 batch_first 
 
 Note 
 If the following conditions are satisfied:
1) cudnn is enabled,
2) input data is on the GPU
3) input data has dtype  
 Examples: 
",">>> rnn=nn.GRU(10,20,2)
>>> input=torch.randn(5,3,10)
>>> h0=torch.randn(2,3,20)
>>> output,hn=rnn(input,h0)
",,,
"
 class torch.nn. RNNCell ( input_size ,  hidden_size ,  bias ,  nonlinearity ,  device ,  dtype ) [source] ¶","An Elman RNN cell with tanh or ReLU non-linearity. 
 h If  nonlinearity  is  ‘relu’ , then ReLU is used in place of tanh. 
 Parameters 
 
 
 
 Inputs: input, hidden 
 
 Outputs: h’ 
 
 Shape: 
 
 
 Variables 
 
 
 
 Note 
 All the weights and biases are initialized from  
 Examples: 
",">>> rnn=nn.RNNCell(10,20)
>>> input=torch.randn(6,3,10)
>>> hx=torch.randn(3,20)
>>> output=[]
>>> foriinrange(6):
... hx=rnn(input[i],hx)
... output.append(hx)
",,,
"
 class torch.nn. LSTMCell ( input_size ,  hidden_size ,  bias ,  device ,  dtype ) [source] ¶","A long short-term memory (LSTM) cell. 
 i where  σ  is the sigmoid function, and  ∗  is the Hadamard product. 
 Parameters 
 
 
 
 Inputs: input, (h_0, c_0) 
 
 Outputs: (h_1, c_1) 
 
 
 Variables 
 
 
 
 Note 
 All the weights and biases are initialized from  
 On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. Examples: 
",">>> rnn=nn.LSTMCell(10,20)# (input_size, hidden_size)
>>> input=torch.randn(2,3,10)# (time_steps, batch, input_size)
>>> hx=torch.randn(3,20)# (batch, hidden_size)
>>> cx=torch.randn(3,20)
>>> output=[]
>>> foriinrange(input.size()[0]):
... hx,cx=rnn(input[i],(hx,cx))
... output.append(hx)
>>> output=torch.stack(output,dim=0)
",,,
"
 class torch.nn. GRUCell ( input_size ,  hidden_size ,  bias ,  device ,  dtype ) [source] ¶","A gated recurrent unit (GRU) cell 
 r where  σ  is the sigmoid function, and  ∗  is the Hadamard product. 
 Parameters 
 
 
 
 Inputs: input, hidden 
 
 Outputs: h’ 
 
 Shape: 
 
 
 Variables 
 
 
 
 Note 
 All the weights and biases are initialized from  
 On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. Examples: 
",">>> rnn=nn.GRUCell(10,20)
>>> input=torch.randn(6,3,10)
>>> hx=torch.randn(3,20)
>>> output=[]
>>> foriinrange(6):
... hx=rnn(input[i],hx)
... output.append(hx)
",,,
"
 class torch.nn. Transformer ( d_model=512 ,  nhead=8 ,  num_encoder_layers=6 ,  num_decoder_layers=6 ,  dim_feedforward=2048 ,  dropout=0.1 ,  activation=<function ,  custom_encoder=None ,  custom_decoder=None ,  layer_norm_eps=1e-05 ,  batch_first=False ,  norm_first=False ,  device=None ,  dtype=None ) [source] ¶","A transformer model. User is able to modify the attributes as needed. The architecture
is based on the paper “Attention Is All You Need”. Ashish Vaswani, Noam Shazeer,
Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and
Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information
Processing Systems, pages 6000-6010. 
 Parameters 
 
 
 
 Examples:: 
 Note: A full example to apply nn.Transformer module for the word language model is available in
 https://github.com/pytorch/examples/tree/master/word_language_model 
 
 
 Take in and process masked source/target sequences. 
 
 
 Generate a square mask for the sequence. The masked positions are filled with float(‘-inf’).
Unmasked positions are filled with float(0.0).",,,,
"
 class torch.nn. TransformerEncoder ( encoder_layer ,  num_layers ,  norm ,  enable_nested_tensor ,  mask_check ) [source] ¶","TransformerEncoder is a stack of N encoder layers. Users can build the
BERT( https://arxiv.org/abs/1810.04805 ) model with corresponding parameters. 
 Parameters 
 
 
 
 Examples:: 
 
 
 
 Pass the input through the encoder layers in turn.",,,,
"
 class torch.nn. TransformerDecoder ( decoder_layer ,  num_layers ,  norm ) [source] ¶","TransformerDecoder is a stack of N decoder layers 
 Parameters 
 
 
 
 Examples:: 
 
 
 
 Pass the inputs (and mask) through the decoder layer in turn.",,,,
"
 class torch.nn. TransformerEncoderLayer ( d_model ,  nhead ,  dim_feedforward=2048 ,  dropout=0.1 ,  activation=<function ,  layer_norm_eps=1e-05 ,  batch_first=False ,  norm_first=False ,  device=None ,  dtype=None ) [source] ¶","TransformerEncoderLayer is made up of self-attn and feedforward network.
This standard encoder layer is based on the paper “Attention Is All You Need”.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in
Neural Information Processing Systems, pages 6000-6010. Users may modify or implement
in a different way during application. 
 Parameters 
 
 
 
 Examples:: 
 Alternatively, when  
 Fast path: forward() will use a special optimized implementation if all of the following
conditions are met: 
 
 
 
 Pass the input through the encoder layer.",,,,
"
 class torch.nn. TransformerDecoderLayer ( d_model ,  nhead ,  dim_feedforward=2048 ,  dropout=0.1 ,  activation=<function ,  layer_norm_eps=1e-05 ,  batch_first=False ,  norm_first=False ,  device=None ,  dtype=None ) [source] ¶","TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.
This standard decoder layer is based on the paper “Attention Is All You Need”.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in
Neural Information Processing Systems, pages 6000-6010. Users may modify or implement
in a different way during application. 
 Parameters 
 
 
 
 Examples:: 
 Alternatively, when  
 
 
 
 Pass the inputs (and mask) through the decoder layer.",,,,
"
 class torch.nn. Identity ( * ,  ** ) [source] ¶","A placeholder identity operator that is argument-insensitive. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> m=nn.Identity(54,unused_argument1=0.1,unused_argument2=False)
>>> input=torch.randn(128,20)
>>> output=m(input)
>>> print(output.size())
torch.Size([128, 20])
",,,
"
 class torch.nn. Linear ( in_features ,  out_features ,  bias ,  device ,  dtype ) [source] ¶","Applies a linear transformation to the incoming data:  y This module supports  TensorFloat32 . On certain ROCm devices, when using float16 inputs this module will use  different precision  for backward. 
 Parameters 
 
 
 
 Shape: 
 
 
 Variables 
 
 
 Examples: 
",">>> m=nn.Linear(20,30)
>>> input=torch.randn(128,20)
>>> output=m(input)
>>> print(output.size())
torch.Size([128, 30])
",,,
"
 class torch.nn. Bilinear ( in1_features ,  in2_features ,  out_features ,  bias ,  device ,  dtype ) [source] ¶","Applies a bilinear transformation to the incoming data:
 y 
 Parameters 
 
 
 
 Shape: 
 
 
 Variables 
 
 
 Examples: 
",">>> m=nn.Bilinear(20,30,40)
>>> input1=torch.randn(128,20)
>>> input2=torch.randn(128,30)
>>> output=m(input1,input2)
>>> print(output.size())
torch.Size([128, 40])
",,,
"
 class torch.nn. LazyLinear ( out_features ,  bias ,  device ,  dtype ) [source] ¶","A  torch.nn.Linear  module where  in_features  is inferred. In this module, the  weight  and  bias  are of  torch.nn.UninitializedParameter 
class. They will be initialized after the first call to  forward  is done and the
module will become a regular  torch.nn.Linear  module. The  in_features  argument
of the  Linear  is inferred from the  input.shape[-1] . Check the  torch.nn.modules.lazy.LazyModuleMixin  for further documentation
on lazy modules and their limitations. 
 Parameters 
 
 
 Variables 
 
 
 
 
 
 alias of ",,,,
"
 class torch.nn. Dropout ( p ,  inplace ) [source] ¶","During training, randomly zeroes some of the elements of the input
tensor with probability  p  using samples from a Bernoulli
distribution. Each channel will be zeroed out independently on every forward
call. This has proven to be an effective technique for regularization and
preventing the co-adaptation of neurons as described in the paper
 Improving neural networks by preventing co-adaptation of feature
detectors  . Furthermore, the outputs are scaled by a factor of  1  during
training. This means that during evaluation the module simply computes an
identity function. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> m=nn.Dropout(p=0.2)
>>> input=torch.randn(20,16)
>>> output=m(input)
",,,
"
 class torch.nn. Dropout1d ( p ,  inplace ) [source] ¶","Randomly zero out entire channels (a channel is a 1D feature map,
e.g., the  j -th channel of the  i -th sample in the
batched input is a 1D tensor  input ).
Each channel will be zeroed out independently on every forward call with
probability  p  using samples from a Bernoulli distribution. Usually the input comes from  nn.Conv1d  modules. As described in the paper
 Efficient Object Localization Using Convolutional Networks  ,
if adjacent pixels within feature maps are strongly correlated
(as is normally the case in early convolution layers) then i.i.d. dropout
will not regularize the activations and will otherwise just result
in an effective learning rate decrease. In this case,  nn.Dropout1d()  will help promote independence between
feature maps and should be used instead. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> m=nn.Dropout1d(p=0.2)
>>> input=torch.randn(20,16,32)
>>> output=m(input)
",,,
"
 class torch.nn. Dropout2d ( p ,  inplace ) [source] ¶","Randomly zero out entire channels (a channel is a 2D feature map,
e.g., the  j -th channel of the  i -th sample in the
batched input is a 2D tensor  input ).
Each channel will be zeroed out independently on every forward call with
probability  p  using samples from a Bernoulli distribution. Usually the input comes from  nn.Conv2d  modules. As described in the paper
 Efficient Object Localization Using Convolutional Networks  ,
if adjacent pixels within feature maps are strongly correlated
(as is normally the case in early convolution layers) then i.i.d. dropout
will not regularize the activations and will otherwise just result
in an effective learning rate decrease. In this case,  nn.Dropout2d()  will help promote independence between
feature maps and should be used instead. 
 Parameters 
 
 
 
 Warning 
 Due to historical reasons, this class will perform 1D channel-wise dropout
for 3D inputs (as done by  
 
 Shape: 
 
 Examples: 
",">>> m=nn.Dropout2d(p=0.2)
>>> input=torch.randn(20,16,32,32)
>>> output=m(input)
",,,
"
 class torch.nn. Dropout3d ( p ,  inplace ) [source] ¶","Randomly zero out entire channels (a channel is a 3D feature map,
e.g., the  j -th channel of the  i -th sample in the
batched input is a 3D tensor  input ).
Each channel will be zeroed out independently on every forward call with
probability  p  using samples from a Bernoulli distribution. Usually the input comes from  nn.Conv3d  modules. As described in the paper
 Efficient Object Localization Using Convolutional Networks  ,
if adjacent pixels within feature maps are strongly correlated
(as is normally the case in early convolution layers) then i.i.d. dropout
will not regularize the activations and will otherwise just result
in an effective learning rate decrease. In this case,  nn.Dropout3d()  will help promote independence between
feature maps and should be used instead. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> m=nn.Dropout3d(p=0.2)
>>> input=torch.randn(20,16,4,32,32)
>>> output=m(input)
",,,
"
 class torch.nn. AlphaDropout ( p ,  inplace ) [source] ¶","Applies Alpha Dropout over the input. Alpha Dropout is a type of Dropout that maintains the self-normalizing
property.
For an input with zero mean and unit standard deviation, the output of
Alpha Dropout maintains the original mean and standard deviation of the
input.
Alpha Dropout goes hand-in-hand with SELU activation function, which ensures
that the outputs have zero mean and unit standard deviation. During training, it randomly masks some of the elements of the input
tensor with probability  p  using samples from a bernoulli distribution.
The elements to masked are randomized on every forward call, and scaled
and shifted to maintain zero mean and unit standard deviation. During evaluation the module simply computes an identity function. More details can be found in the paper  Self-Normalizing Neural Networks  . 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> m=nn.AlphaDropout(p=0.2)
>>> input=torch.randn(20,16)
>>> output=m(input)
",,,
"
 class torch.nn. FeatureAlphaDropout ( p ,  inplace ) [source] ¶","Randomly masks out entire channels (a channel is a feature map,
e.g. the  j -th channel of the  i -th sample in the batch input
is a tensor  input ) of the input tensor). Instead of
setting activations to zero, as in regular Dropout, the activations are set
to the negative saturation value of the SELU activation function. More details
can be found in the paper  Self-Normalizing Neural Networks  . Each element will be masked independently for each sample on every forward
call with probability  p  using samples from a Bernoulli distribution.
The elements to be masked are randomized on every forward call, and scaled
and shifted to maintain zero mean and unit variance. Usually the input comes from  nn.AlphaDropout  modules. As described in the paper
 Efficient Object Localization Using Convolutional Networks  ,
if adjacent pixels within feature maps are strongly correlated
(as is normally the case in early convolution layers) then i.i.d. dropout
will not regularize the activations and will otherwise just result
in an effective learning rate decrease. In this case,  nn.AlphaDropout()  will help promote independence between
feature maps and should be used instead. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> m=nn.FeatureAlphaDropout(p=0.2)
>>> input=torch.randn(20,16,4,32,32)
>>> output=m(input)
",,,
"
 class torch.nn. Embedding ( num_embeddings ,  embedding_dim ,  padding_idx ,  max_norm ,  norm_type ,  scale_grad_by_freq ,  sparse ,  _weight ,  device ,  dtype ) [source] ¶","A simple lookup table that stores embeddings of a fixed dictionary and size. This module is often used to store word embeddings and retrieve them using indices.
The input to the module is a list of indices, and the output is the corresponding
word embeddings. 
 Parameters 
 
 
 Variables 
 weight 
 
 Shape: 
 
 
 Note 
 Keep in mind that only a limited number of optimizers support
sparse gradients: currently it’s  
 
 Note 
 When  
 
 Examples: 
 
 
 
 Creates Embedding instance from given 2-dimensional FloatTensor.",">>> # an Embedding module containing 10 tensors of size 3
>>> embedding=nn.Embedding(10,3)
>>> # a batch of 2 samples of 4 indices each
>>> input=torch.LongTensor([[1,2,4,5],[4,3,2,9]])
>>> embedding(input)
tensor([[[-0.0251, -1.6902,  0.7172],
         [-0.6431,  0.0748,  0.6969],
         [ 1.4970,  1.3448, -0.9685],
         [-0.3677, -2.7265, -0.1685]],        [[ 1.4970,  1.3448, -0.9685],
         [ 0.4362, -0.4004,  0.9400],
         [-0.6431,  0.0748,  0.6969],
         [ 0.9124, -2.3616,  1.1151]]])>>> # example with padding_idx
>>> embedding=nn.Embedding(10,3,padding_idx=0)
>>> input=torch.LongTensor([[0,2,0,5]])
>>> embedding(input)
tensor([[[ 0.0000,  0.0000,  0.0000],
         [ 0.1535, -2.0309,  0.9315],
         [ 0.0000,  0.0000,  0.0000],
         [-0.1655,  0.9897,  0.0635]]])>>> # example of changing `pad` vector
>>> padding_idx=0
>>> embedding=nn.Embedding(3,3,padding_idx=padding_idx)
>>> embedding.weight
Parameter containing:
tensor([[ 0.0000,  0.0000,  0.0000],
        [-0.7895, -0.7089, -0.0364],
        [ 0.6778,  0.5803,  0.2678]], requires_grad=True)
>>> withtorch.no_grad():
... embedding.weight[padding_idx]=torch.ones(3)
>>> embedding.weight
Parameter containing:
tensor([[ 1.0000,  1.0000,  1.0000],
        [-0.7895, -0.7089, -0.0364],
        [ 0.6778,  0.5803,  0.2678]], requires_grad=True)
",,,
"
 class torch.nn. EmbeddingBag ( num_embeddings ,  embedding_dim ,  max_norm ,  norm_type ,  scale_grad_by_freq ,  mode ,  sparse ,  _weight ,  include_last_offset ,  padding_idx ,  device ,  dtype ) [source] ¶","Computes sums or means of ‘bags’ of embeddings, without instantiating the
intermediate embeddings. For bags of constant length, no  per_sample_weights , no indices equal to  padding_idx ,
and with 2D inputs, this class 
 
 However,  EmbeddingBag  is much more time and memory efficient than using a chain of these
operations. EmbeddingBag also supports per-sample weights as an argument to the forward
pass. This scales the output of the Embedding before performing a weighted
reduction as specified by  mode . If  per_sample_weights  is passed, the
only supported  mode  is  ""sum"" , which computes a weighted sum according to
 per_sample_weights . 
 Parameters 
 
 
 Variables 
 weight 
 Examples: 
 
 
 
 Forward pass of EmbeddingBag. 
 
 
 Creates EmbeddingBag instance from given 2-dimensional FloatTensor.",">>> # an EmbeddingBag module containing 10 tensors of size 3
>>> embedding_sum=nn.EmbeddingBag(10,3,mode='sum')
>>> # a batch of 2 samples of 4 indices each
>>> input=torch.tensor([1,2,4,5,4,3,2,9],dtype=torch.long)
>>> offsets=torch.tensor([0,4],dtype=torch.long)
>>> embedding_sum(input,offsets)
tensor([[-0.8861, -5.4350, -0.0523],
        [ 1.1306, -2.5798, -1.0044]])>>> # Example with padding_idx
>>> embedding_sum=nn.EmbeddingBag(10,3,mode='sum',padding_idx=2)
>>> input=torch.tensor([2,2,2,2,4,3,2,9],dtype=torch.long)
>>> offsets=torch.tensor([0,4],dtype=torch.long)
>>> embedding_sum(input,offsets)
tensor([[ 0.0000,  0.0000,  0.0000],
        [-0.7082,  3.2145, -2.6251]])>>> # An EmbeddingBag can be loaded from an Embedding like so
>>> embedding=nn.Embedding(10,3,padding_idx=2)
>>> embedding_sum=nn.EmbeddingBag.from_pretrained(
        embedding.weight,
        padding_idx=embedding.padding_idx,
        mode='sum')
",,,
"
 class torch.nn. CosineSimilarity ( dim ,  eps ) [source] ¶","Returns cosine similarity between  x  and  x , computed along  dim . 
 similarity 
 Parameters 
 
 
 
 Shape: 
 
 Examples:: 
",,,,
"
 class torch.nn. PairwiseDistance ( p ,  eps ,  keepdim ) [source] ¶","Computes the pairwise distance between input vectors, or between columns of input matrices. Distances are computed using  p -norm, with constant  eps  added to avoid division by zero
if  p  is negative, i.e.: 
 d where  e  is the vector of ones and the  p -norm is given by. 
 ∥ 
 Parameters 
 
 
 
 Shape: 
 
 Examples:: 
",,,,
"
 class torch.nn. L1Loss ( size_average ,  reduce ,  reduction ) [source] ¶","Creates a criterion that measures the mean absolute error (MAE) between each element in
the input  x  and target  y . The unreduced (i.e. with  reduction  set to  'none' ) loss can be described as: 
 ℓ where  N  is the batch size. If  reduction  is not  'none' 
(default  'mean' ), then: 
 ℓ x  and  y  are tensors of arbitrary shapes with a total
of  n  elements each. The sum operation still operates over all the elements, and divides by  n . The division by  n  can be avoided if one sets  reduction . Supports real-valued and complex-valued inputs. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> loss=nn.L1Loss()
>>> input=torch.randn(3,5,requires_grad=True)
>>> target=torch.randn(3,5)
>>> output=loss(input,target)
>>> output.backward()
",,,
"
 class torch.nn. MSELoss ( size_average ,  reduce ,  reduction ) [source] ¶","Creates a criterion that measures the mean squared error (squared L2 norm) between
each element in the input  x  and target  y . The unreduced (i.e. with  reduction  set to  'none' ) loss can be described as: 
 ℓ where  N  is the batch size. If  reduction  is not  'none' 
(default  'mean' ), then: 
 ℓ x  and  y  are tensors of arbitrary shapes with a total
of  n  elements each. The mean operation still operates over all the elements, and divides by  n . The division by  n  can be avoided if one sets  reduction . 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> loss=nn.MSELoss()
>>> input=torch.randn(3,5,requires_grad=True)
>>> target=torch.randn(3,5)
>>> output=loss(input,target)
>>> output.backward()
",,,
"
 class torch.nn. CrossEntropyLoss ( weight ,  size_average ,  ignore_index ,  reduce ,  reduction ,  label_smoothing ) [source] ¶","This criterion computes the cross entropy loss between input logits
and target. It is useful when training a classification problem with  C  classes.
If provided, the optional argument  weight  should be a 1D  Tensor 
assigning weight to each of the classes.
This is particularly useful when you have an unbalanced training set. The  input  is expected to contain the unnormalized logits for each class (which do  not  need
to be positive or sum to 1, in general).
 input  has to be a Tensor of size  (  for unbatched input,
 (  or  (  with  K  for the
 K -dimensional case. The last being useful for higher dimension inputs, such
as computing cross entropy loss per-pixel for 2D images. The  target  that this criterion expects should contain either: 
 Class indices in the range  
 Probabilities for each class; useful when labels beyond a single class per minibatch item
are required, such as for blended labels, label smoothing, etc. The unreduced (i.e. with
 
 
 Note 
 The performance of this criterion is generally better when  
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> # Example of target with class indices
>>> loss=nn.CrossEntropyLoss()
>>> input=torch.randn(3,5,requires_grad=True)
>>> target=torch.empty(3,dtype=torch.long).random_(5)
>>> output=loss(input,target)
>>> output.backward()
>>>
>>> # Example of target with class probabilities
>>> input=torch.randn(3,5,requires_grad=True)
>>> target=torch.randn(3,5).softmax(dim=1)
>>> output=loss(input,target)
>>> output.backward()
",,,
"
 class torch.nn. CTCLoss ( blank ,  reduction ,  zero_infinity ) [source] ¶","The Connectionist Temporal Classification loss. Calculates loss between a continuous (unsegmented) time series and a target sequence. CTCLoss sums over the
probability of possible alignments of input to target, producing a loss value which is differentiable
with respect to each input node. The alignment of input to target is assumed to be “many-to-one”, which
limits the length of the target sequence such that it must be  ≤  the input length. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
 
 Reference: A. Graves et al.: Connectionist Temporal Classification:
Labelling Unsegmented Sequence Data with Recurrent Neural Networks:
 
 
 Note 
 In order to use CuDNN, the following must be satisfied:  
 The regular implementation uses the (more common in PyTorch)  
 
 Note 
 In some circumstances when using the CUDA backend with CuDNN, this operator
may select a nondeterministic algorithm to increase performance. If this is
undesirable, you can try to make the operation deterministic (potentially at
a performance cost) by setting  
",">>> # Target are to be padded
>>> T=50# Input sequence length
>>> C=20# Number of classes (including blank)
>>> N=16# Batch size
>>> S=30# Target sequence length of longest target in batch (padding length)
>>> S_min=10# Minimum target length, for demonstration purposes
>>>
>>> # Initialize random batch of input vectors, for *size = (T,N,C)
>>> input=torch.randn(T,N,C).log_softmax(2).detach().requires_grad_()
>>>
>>> # Initialize random batch of targets (0 = blank, 1:C = classes)
>>> target=torch.randint(low=1,high=C,size=(N,S),dtype=torch.long)
>>>
>>> input_lengths=torch.full(size=(N,),fill_value=T,dtype=torch.long)
>>> target_lengths=torch.randint(low=S_min,high=S,size=(N,),dtype=torch.long)
>>> ctc_loss=nn.CTCLoss()
>>> loss=ctc_loss(input,target,input_lengths,target_lengths)
>>> loss.backward()
>>>
>>>
>>> # Target are to be un-padded
>>> T=50# Input sequence length
>>> C=20# Number of classes (including blank)
>>> N=16# Batch size
>>>
>>> # Initialize random batch of input vectors, for *size = (T,N,C)
>>> input=torch.randn(T,N,C).log_softmax(2).detach().requires_grad_()
>>> input_lengths=torch.full(size=(N,),fill_value=T,dtype=torch.long)
>>>
>>> # Initialize random batch of targets (0 = blank, 1:C = classes)
>>> target_lengths=torch.randint(low=1,high=T,size=(N,),dtype=torch.long)
>>> target=torch.randint(low=1,high=C,size=(sum(target_lengths),),dtype=torch.long)
>>> ctc_loss=nn.CTCLoss()
>>> loss=ctc_loss(input,target,input_lengths,target_lengths)
>>> loss.backward()
>>>
>>>
>>> # Target are to be un-padded and unbatched (effectively N=1)
>>> T=50# Input sequence length
>>> C=20# Number of classes (including blank)
>>>
>>> # Initialize random batch of input vectors, for *size = (T,C)
>>> input=torch.randn(T,C).log_softmax(2).detach().requires_grad_()
>>> input_lengths=torch.tensor(T,dtype=torch.long)
>>>
>>> # Initialize random batch of targets (0 = blank, 1:C = classes)
>>> target_lengths=torch.randint(low=1,high=T,size=(),dtype=torch.long)
>>> target=torch.randint(low=1,high=C,size=(target_lengths,),dtype=torch.long)
>>> ctc_loss=nn.CTCLoss()
>>> loss=ctc_loss(input,target,input_lengths,target_lengths)
>>> loss.backward()
",,,
"
 class torch.nn. NLLLoss ( weight ,  size_average ,  ignore_index ,  reduce ,  reduction ) [source] ¶","The negative log likelihood loss. It is useful to train a classification
problem with  C  classes. If provided, the optional argument  weight  should be a 1D Tensor assigning
weight to each of the classes. This is particularly useful when you have an
unbalanced training set. The  input  given through a forward call is expected to contain
log-probabilities of each class.  input  has to be a Tensor of size either
 (  or  ( 
with  K  for the  K -dimensional case. The latter is useful for
higher dimension inputs, such as computing NLL loss per-pixel for 2D images. Obtaining log-probabilities in a neural network is easily achieved by
adding a   LogSoftmax   layer in the last layer of your network.
You may use  CrossEntropyLoss  instead, if you prefer not to add an extra
layer. The  target  that this loss expects should be a class index in the range  [ 
where  C = number of classes ; if  ignore_index  is specified, this loss also accepts
this class index (this index may not necessarily be in the class range). The unreduced (i.e. with  reduction  set to  'none' ) loss can be described as: 
 ℓ where  x  is the input,  y  is the target,  w  is the weight, and
 N  is the batch size. If  reduction  is not  'none' 
(default  'mean' ), then 
 ℓ 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> m=nn.LogSoftmax(dim=1)
>>> loss=nn.NLLLoss()
>>> # input is of size N x C = 3 x 5
>>> input=torch.randn(3,5,requires_grad=True)
>>> # each element in target has to have 0 <= value < C
>>> target=torch.tensor([1,0,4])
>>> output=loss(m(input),target)
>>> output.backward()
>>>
>>>
>>> # 2D loss example (used, for example, with image inputs)
>>> N,C=5,4
>>> loss=nn.NLLLoss()
>>> # input is of size N x C x height x width
>>> data=torch.randn(N,16,10,10)
>>> conv=nn.Conv2d(16,C,(3,3))
>>> m=nn.LogSoftmax(dim=1)
>>> # each element in target has to have 0 <= value < C
>>> target=torch.empty(N,8,8,dtype=torch.long).random_(0,C)
>>> output=loss(m(conv(data)),target)
>>> output.backward()
",,,
"
 class torch.nn. PoissonNLLLoss ( log_input ,  full ,  size_average ,  eps ,  reduce ,  reduction ) [source] ¶","Negative log likelihood loss with Poisson distribution of target. The loss can be described as: 
 target The last term can be omitted or approximated with Stirling formula. The
approximation is used for target values more than 1. For targets less or
equal to 1 zeros are added to the loss. 
 Parameters 
 
 
 Examples: 
 
 Shape: 
 
",">>> loss=nn.PoissonNLLLoss()
>>> log_input=torch.randn(5,2,requires_grad=True)
>>> target=torch.randn(5,2)
>>> output=loss(log_input,target)
>>> output.backward()
",,,
"
 class torch.nn. GaussianNLLLoss ( * ,  full ,  eps ,  reduction ) [source] ¶","Gaussian negative log likelihood loss. The targets are treated as samples from Gaussian distributions with
expectations and variances predicted by the neural network. For a
 target  tensor modelled as having Gaussian distribution with a tensor
of expectations  input  and a tensor of positive variances  var  the loss is: 
 loss where  eps  is used for stability. By default, the constant term of
the loss function is omitted unless  full  is  True . If  var  is not the same
size as  input  (due to a homoscedastic assumption), it must either have a final dimension
of 1 or have one fewer dimension (with all other sizes being the same) for correct broadcasting. 
 Parameters 
 
 
 
 Shape: 
 
 Examples:: 
 
 Note 
 The clamping of  
 
 Reference: Nix, D. A. and Weigend, A. S., “Estimating the mean and variance of the
target probability distribution”, Proceedings of 1994 IEEE International
Conference on Neural Networks (ICNN’94), Orlando, FL, USA, 1994, pp. 55-60
vol.1, doi: 10.1109/ICNN.1994.374138. 
",,,,
"
 class torch.nn. KLDivLoss ( size_average ,  reduce ,  reduction ,  log_target ) [source] ¶","The Kullback-Leibler divergence loss. For tensors of the same shape  y ,
where  y  is the  input  and  y  is the
 target , we define the  pointwise KL-divergence  as 
 L To avoid underflow issues when computing this quantity, this loss expects the argument
 input  in the log-space. The argument  target  may also be provided in the
log-space if  log_target = True . To summarise, this function is roughly equivalent to computing 
 and then reducing this result depending on the argument  reduction  as 
 
 Note 
 As all the other losses in PyTorch, this function expects the first argument,
 
 
 Warning 
 reduction 
 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> importtorch.nn.functionalasF
>>> kl_loss=nn.KLDivLoss(reduction=""batchmean"")
>>> # input should be a distribution in the log space
>>> input=F.log_softmax(torch.randn(3,5,requires_grad=True),dim=1)
>>> # Sample a batch of distributions. Usually this would come from the dataset
>>> target=F.softmax(torch.rand(3,5),dim=1)
>>> output=kl_loss(input,target)>>> kl_loss=nn.KLDivLoss(reduction=""batchmean"",log_target=True)
>>> log_target=F.log_softmax(torch.rand(3,5),dim=1)
>>> output=kl_loss(input,log_target)
",,,
"
 class torch.nn. BCELoss ( weight ,  size_average ,  reduce ,  reduction ) [source] ¶","Creates a criterion that measures the Binary Cross Entropy between the target and
the input probabilities: The unreduced (i.e. with  reduction  set to  'none' ) loss can be described as: 
 ℓ where  N  is the batch size. If  reduction  is not  'none' 
(default  'mean' ), then 
 ℓ This is used for measuring the error of a reconstruction in for example
an auto-encoder. Note that the targets  y  should be numbers
between 0 and 1. Notice that if  x  is either 0 or 1, one of the log terms would be
mathematically undefined in the above loss equation. PyTorch chooses to set
 log , since  lim .
However, an infinite term in the loss equation is not desirable for several reasons. For one, if either  y  or  ( , then we would be
multiplying 0 with infinity. Secondly, if we have an infinite loss value, then
we would also have an infinite term in our gradient, since
 lim .
This would make BCELoss’s backward method nonlinear with respect to  x ,
and using it for things like linear regression would not be straight-forward. Our solution is that BCELoss clamps its log function outputs to be greater than
or equal to -100. This way, we can always have a finite loss value and a linear
backward method. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> m=nn.Sigmoid()
>>> loss=nn.BCELoss()
>>> input=torch.randn(3,requires_grad=True)
>>> target=torch.empty(3).random_(2)
>>> output=loss(m(input),target)
>>> output.backward()
",,,
"
 class torch.nn. BCEWithLogitsLoss ( weight ,  size_average ,  reduce ,  reduction ,  pos_weight ) [source] ¶","This loss combines a  Sigmoid  layer and the  BCELoss  in one single
class. This version is more numerically stable than using a plain  Sigmoid 
followed by a  BCELoss  as, by combining the operations into one layer,
we take advantage of the log-sum-exp trick for numerical stability. The unreduced (i.e. with  reduction  set to  'none' ) loss can be described as: 
 ℓ where  N  is the batch size. If  reduction  is not  'none' 
(default  'mean' ), then 
 ℓ This is used for measuring the error of a reconstruction in for example
an auto-encoder. Note that the targets  t[i]  should be numbers
between 0 and 1. It’s possible to trade off recall and precision by adding weights to positive examples.
In the case of multi-label classification the loss can be described as: 
 ℓ where  c  is the class number ( c  for multi-label binary classification,
 c  for single-label binary classification),
 n  is the number of the sample in the batch and
 p  is the weight of the positive answer for the class  c . p  increases the recall,  p  increases the precision. For example, if a dataset contains 100 positive and 300 negative examples of a single class,
then  pos_weight  for the class should be equal to  300 .
The loss would act as if the dataset contains  3  positive examples. Examples: 
 
 Parameters 
 
 
 
 Shape: 
 
",">>> target=torch.ones([10,64],dtype=torch.float32)# 64 classes, batch size = 10
>>> output=torch.full([10,64],1.5)# A prediction (logit)
>>> pos_weight=torch.ones([64])# All weights are equal to 1
>>> criterion=torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)
>>> criterion(output,target)# -log(sigmoid(1.5))
tensor(0.20...)
",,,
"
 class torch.nn. MarginRankingLoss ( margin ,  size_average ,  reduce ,  reduction ) [source] ¶","Creates a criterion that measures the loss given
inputs  x ,  x , two 1D mini-batch or 0D  Tensors ,
and a label 1D mini-batch or 0D  Tensor   y  (containing 1 or -1). If  y  then it assumed the first input should be ranked higher
(have a larger value) than the second input, and vice-versa for  y . The loss function for each pair of samples in the mini-batch is: 
 loss 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> loss=nn.MarginRankingLoss()
>>> input1=torch.randn(3,requires_grad=True)
>>> input2=torch.randn(3,requires_grad=True)
>>> target=torch.randn(3).sign()
>>> output=loss(input1,input2,target)
>>> output.backward()
",,,
"
 class torch.nn. HingeEmbeddingLoss ( margin ,  size_average ,  reduce ,  reduction ) [source] ¶","Measures the loss given an input tensor  x  and a labels tensor  y 
(containing 1 or -1).
This is usually used for measuring whether two inputs are similar or
dissimilar, e.g. using the L1 pairwise distance as  x , and is typically
used for learning nonlinear embeddings or semi-supervised learning. The loss function for  n -th sample in the mini-batch is 
 l and the total loss functions is 
 ℓ where  L . 
 Parameters 
 
 
 
 Shape: 
 
",,,,
"
 class torch.nn. MultiLabelMarginLoss ( size_average ,  reduce ,  reduction ) [source] ¶","Creates a criterion that optimizes a multi-class multi-classification
hinge loss (margin-based loss) between input  x  (a 2D mini-batch  Tensor )
and output  y  (which is a 2D  Tensor  of target class indices).
For each sample in the mini-batch: 
 loss where  x ,  y ,  0 , and  i  for all  i  and  j . y  and  x  must have the same size. The criterion only considers a contiguous block of non-negative targets that
starts at the front. This allows for different samples to have variable amounts of target classes. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> loss=nn.MultiLabelMarginLoss()
>>> x=torch.FloatTensor([[0.1,0.2,0.4,0.8]])
>>> # for target y, only consider labels 3 and 0, not after label -1
>>> y=torch.LongTensor([[3,0,-1,1]])
>>> # 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))
>>> loss(x,y)
tensor(0.85...)
",,,
"
 class torch.nn. HuberLoss ( reduction ,  delta ) [source] ¶","Creates a criterion that uses a squared term if the absolute
element-wise error falls below delta and a delta-scaled L1 term otherwise.
This loss combines advantages of both  L1Loss  and  MSELoss ; the
delta-scaled L1 region makes the loss less sensitive to outliers than  MSELoss ,
while the L2 region provides smoothness over  L1Loss  near 0. See
 Huber loss  for more information. For a batch of size  N , the unreduced loss can be described as: 
 ℓ with 
 l If  reduction  is not  none , then: 
 ℓ 
 Note 
 When delta is set to 1, this loss is equivalent to  
 
 Parameters 
 
 
 
 Shape: 
 
",,,,
"
 class torch.nn. SmoothL1Loss ( size_average ,  reduce ,  reduction ,  beta ) [source] ¶","Creates a criterion that uses a squared term if the absolute
element-wise error falls below beta and an L1 term otherwise.
It is less sensitive to outliers than  torch.nn.MSELoss  and in some cases
prevents exploding gradients (e.g. see the paper  Fast R-CNN  by Ross Girshick). For a batch of size  N , the unreduced loss can be described as: 
 ℓ with 
 l If  reduction  is not  none , then: 
 ℓ 
 Note 
 Smooth L1 loss can be seen as exactly  
 
 Note 
 Smooth L1 loss is closely related to  
 
 
 
 Parameters 
 
 
 
 Shape: 
 
",,,,
"
 class torch.nn. SoftMarginLoss ( size_average ,  reduce ,  reduction ) [source] ¶","Creates a criterion that optimizes a two-class classification
logistic loss between input tensor  x  and target tensor  y 
(containing 1 or -1). 
 loss 
 Parameters 
 
 
 
 Shape: 
 
",,,,
"
 class torch.nn. MultiLabelSoftMarginLoss ( weight ,  size_average ,  reduce ,  reduction ) [source] ¶","Creates a criterion that optimizes a multi-label one-versus-all
loss based on max-entropy, between input  x  and target  y  of size
 ( .
For each sample in the minibatch: 
 l where  i ,
 y . 
 Parameters 
 
 
 
 Shape: 
 
",,,,
"
 class torch.nn. CosineEmbeddingLoss ( margin ,  size_average ,  reduce ,  reduction ) [source] ¶","Creates a criterion that measures the loss given input tensors
 x ,  x  and a  Tensor  label  y  with values 1 or -1.
This is used for measuring whether two inputs are similar or dissimilar,
using the cosine similarity, and is typically used for learning nonlinear
embeddings or semi-supervised learning. The loss function for each sample is: 
 loss 
 Parameters 
 
 
 
 Shape: 
 
",,,,
"
 class torch.nn. MultiMarginLoss ( p ,  margin ,  weight ,  size_average ,  reduce ,  reduction ) [source] ¶","Creates a criterion that optimizes a multi-class classification hinge
loss (margin-based loss) between input  x  (a 2D mini-batch  Tensor ) and
output  y  (which is a 1D tensor of target class indices,
 0 ): For each mini-batch sample, the loss in terms of the 1D input  x  and scalar
output  y  is: 
 loss where  i 
and  i . Optionally, you can give non-equal weighting on the classes by passing
a 1D  weight  tensor into the constructor. The loss function then becomes: 
 loss 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> loss=nn.MultiMarginLoss()
>>> x=torch.tensor([[0.1,0.2,0.4,0.8]])
>>> y=torch.tensor([3])
>>> # 0.25 * ((1-(0.8-0.1)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))
>>> loss(x,y)
tensor(0.32...)
",,,
"
 class torch.nn. TripletMarginLoss ( margin ,  p ,  eps ,  swap ,  size_average ,  reduce ,  reduction ) [source] ¶","Creates a criterion that measures the triplet loss given an input
tensors  x ,  x ,  x  and a margin with a value greater than  0 .
This is used for measuring a relative similarity between samples. A triplet
is composed by  a ,  p  and  n  (i.e.,  anchor ,  positive examples  and  negative
examples  respectively). The shapes of all input tensors should be
 ( . The distance swap is described in detail in the paper  Learning shallow
convolutional feature descriptors with triplet losses  by
V. Balntas, E. Riba et al. The loss function for each sample in the mini-batch is: 
 L where 
 d See also  TripletMarginWithDistanceLoss , which computes the
triplet margin loss for input tensors using a custom distance function. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
",">>> triplet_loss=nn.TripletMarginLoss(margin=1.0,p=2)
>>> anchor=torch.randn(100,128,requires_grad=True)
>>> positive=torch.randn(100,128,requires_grad=True)
>>> negative=torch.randn(100,128,requires_grad=True)
>>> output=triplet_loss(anchor,positive,negative)
>>> output.backward()
",,,
"
 class torch.nn. TripletMarginWithDistanceLoss ( * ,  distance_function ,  margin ,  swap ,  reduction ) [source] ¶","Creates a criterion that measures the triplet loss given input
tensors  a ,  p , and  n  (representing anchor,
positive, and negative examples, respectively), and a nonnegative,
real-valued function (“distance function”) used to compute the relationship
between the anchor and positive example (“positive distance”) and the
anchor and negative example (“negative distance”). The unreduced loss (i.e., with  reduction  set to  'none' )
can be described as: 
 ℓ where  N  is the batch size;  d  is a nonnegative, real-valued function
quantifying the closeness of two tensors, referred to as the  distance_function ;
and  m  is a nonnegative margin representing the minimum difference
between the positive and negative distances that is required for the loss to
be 0.  The input tensors have  N  elements each and can be of any shape
that the distance function can handle. If  reduction  is not  'none' 
(default  'mean' ), then: 
 ℓ See also  TripletMarginLoss , which computes the triplet
loss for input tensors using the  l  distance as the distance function. 
 Parameters 
 
 
 
 Shape: 
 
 Examples: 
 
 Reference: V. Balntas, et al.: Learning shallow convolutional feature descriptors with triplet losses:
 
",">>> # Initialize embeddings
>>> embedding=nn.Embedding(1000,128)
>>> anchor_ids=torch.randint(0,1000,(1,))
>>> positive_ids=torch.randint(0,1000,(1,))
>>> negative_ids=torch.randint(0,1000,(1,))
>>> anchor=embedding(anchor_ids)
>>> positive=embedding(positive_ids)
>>> negative=embedding(negative_ids)
>>>
>>> # Built-in Distance Function
>>> triplet_loss=>>> nn.TripletMarginWithDistanceLoss(distance_function=nn.PairwiseDistance())
>>> output=triplet_loss(anchor,positive,negative)
>>> output.backward()
>>>
>>> # Custom Distance Function
>>> defl_infinity(x1,x2):
>>> returntorch.max(torch.abs(x1-x2),dim=1).values
>>>
>>> triplet_loss=(
>>> nn.TripletMarginWithDistanceLoss(distance_function=l_infinity,margin=1.5))
>>> output=triplet_loss(anchor,positive,negative)
>>> output.backward()
>>>
>>> # Custom Distance Function (Lambda)
>>> triplet_loss=(
>>> nn.TripletMarginWithDistanceLoss(
>>> distance_function=lambdax,y:1.0-F.cosine_similarity(x,y)))
>>> output=triplet_loss(anchor,positive,negative)
>>> output.backward()
",,,
"
 class torch.nn. PixelShuffle ( upscale_factor ) [source] ¶","Rearranges elements in a tensor of shape  ( 
to a tensor of shape  ( , where r is an upscale factor. This is useful for implementing efficient sub-pixel convolution
with a stride of  1 . See the paper:
 Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network 
by Shi et. al (2016) for more details. 
 Parameters 
 upscale_factor 
 
 Shape: 
 
 
 C 
 H 
 W Examples: 
",">>> pixel_shuffle=nn.PixelShuffle(3)
>>> input=torch.randn(1,9,4,4)
>>> output=pixel_shuffle(input)
>>> print(output.size())
torch.Size([1, 1, 12, 12])
",,,
"
 class torch.nn. PixelUnshuffle ( downscale_factor ) [source] ¶","Reverses the  PixelShuffle  operation by rearranging elements
in a tensor of shape  (  to a tensor of shape
 ( , where r is a downscale factor. See the paper:
 Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network 
by Shi et. al (2016) for more details. 
 Parameters 
 downscale_factor 
 
 Shape: 
 
 
 C 
 H 
 W Examples: 
",">>> pixel_unshuffle=nn.PixelUnshuffle(3)
>>> input=torch.randn(1,1,12,12)
>>> output=pixel_unshuffle(input)
>>> print(output.size())
torch.Size([1, 9, 4, 4])
",,,
"
 class torch.nn. Upsample ( size ,  scale_factor ,  mode ,  align_corners ,  recompute_scale_factor ) [source] ¶","Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data. The input data is assumed to be of the form
 minibatch x channels x [optional depth] x [optional height] x width .
Hence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor. The algorithms available for upsampling are nearest neighbor and linear,
bilinear, bicubic and trilinear for 3D, 4D and 5D input Tensor,
respectively. One can either give a  scale_factor  or the target output  size  to
calculate the output size. (You cannot give both, as it is ambiguous) 
 Parameters 
 
 
 
 Shape: 
 
 
 D 
 H 
 W 
 Warning 
 With  
 
 Note 
 If you want downsampling/general resizing, you should use  
 Examples: 
",">>> input=torch.arange(1,5,dtype=torch.float32).view(1,1,2,2)
>>> input
tensor([[[[1., 2.],
          [3., 4.]]]])>>> m=nn.Upsample(scale_factor=2,mode='nearest')
>>> m(input)
tensor([[[[1., 1., 2., 2.],
          [1., 1., 2., 2.],
          [3., 3., 4., 4.],
          [3., 3., 4., 4.]]]])>>> m=nn.Upsample(scale_factor=2,mode='bilinear')# align_corners=False
>>> m(input)
tensor([[[[1.0000, 1.2500, 1.7500, 2.0000],
          [1.5000, 1.7500, 2.2500, 2.5000],
          [2.5000, 2.7500, 3.2500, 3.5000],
          [3.0000, 3.2500, 3.7500, 4.0000]]]])>>> m=nn.Upsample(scale_factor=2,mode='bilinear',align_corners=True)
>>> m(input)
tensor([[[[1.0000, 1.3333, 1.6667, 2.0000],
          [1.6667, 2.0000, 2.3333, 2.6667],
          [2.3333, 2.6667, 3.0000, 3.3333],
          [3.0000, 3.3333, 3.6667, 4.0000]]]])>>> # Try scaling the same data in a larger tensor
>>> input_3x3=torch.zeros(3,3).view(1,1,3,3)
>>> input_3x3[:,:,:2,:2].copy_(input)
tensor([[[[1., 2.],
          [3., 4.]]]])
>>> input_3x3
tensor([[[[1., 2., 0.],
          [3., 4., 0.],
          [0., 0., 0.]]]])>>> m=nn.Upsample(scale_factor=2,mode='bilinear')# align_corners=False
>>> # Notice that values in top left corner are the same with the small input (except at boundary)
>>> m(input_3x3)
tensor([[[[1.0000, 1.2500, 1.7500, 1.5000, 0.5000, 0.0000],
          [1.5000, 1.7500, 2.2500, 1.8750, 0.6250, 0.0000],
          [2.5000, 2.7500, 3.2500, 2.6250, 0.8750, 0.0000],
          [2.2500, 2.4375, 2.8125, 2.2500, 0.7500, 0.0000],
          [0.7500, 0.8125, 0.9375, 0.7500, 0.2500, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])>>> m=nn.Upsample(scale_factor=2,mode='bilinear',align_corners=True)
>>> # Notice that values in top left corner are now changed
>>> m(input_3x3)
tensor([[[[1.0000, 1.4000, 1.8000, 1.6000, 0.8000, 0.0000],
          [1.8000, 2.2000, 2.6000, 2.2400, 1.1200, 0.0000],
          [2.6000, 3.0000, 3.4000, 2.8800, 1.4400, 0.0000],
          [2.4000, 2.7200, 3.0400, 2.5600, 1.2800, 0.0000],
          [1.2000, 1.3600, 1.5200, 1.2800, 0.6400, 0.0000],
          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])
",,,
"
 class torch.nn. UpsamplingNearest2d ( size ,  scale_factor ) [source] ¶","Applies a 2D nearest neighbor upsampling to an input signal composed of several input
channels. To specify the scale, it takes either the  size  or the  scale_factor 
as it’s constructor argument. When  size  is given, it is the output size of the image  (h, w) . 
 Parameters 
 
 
 
 Warning 
 This class is deprecated in favor of  
 
 Shape: 
 
 
 H 
 W Examples: 
",">>> input=torch.arange(1,5,dtype=torch.float32).view(1,1,2,2)
>>> input
tensor([[[[1., 2.],
          [3., 4.]]]])>>> m=nn.UpsamplingNearest2d(scale_factor=2)
>>> m(input)
tensor([[[[1., 1., 2., 2.],
          [1., 1., 2., 2.],
          [3., 3., 4., 4.],
          [3., 3., 4., 4.]]]])
",,,
"
 class torch.nn. UpsamplingBilinear2d ( size ,  scale_factor ) [source] ¶","Applies a 2D bilinear upsampling to an input signal composed of several input
channels. To specify the scale, it takes either the  size  or the  scale_factor 
as it’s constructor argument. When  size  is given, it is the output size of the image  (h, w) . 
 Parameters 
 
 
 
 Warning 
 This class is deprecated in favor of  
 
 Shape: 
 
 
 H 
 W Examples: 
",">>> input=torch.arange(1,5,dtype=torch.float32).view(1,1,2,2)
>>> input
tensor([[[[1., 2.],
          [3., 4.]]]])>>> m=nn.UpsamplingBilinear2d(scale_factor=2)
>>> m(input)
tensor([[[[1.0000, 1.3333, 1.6667, 2.0000],
          [1.6667, 2.0000, 2.3333, 2.6667],
          [2.3333, 2.6667, 3.0000, 3.3333],
          [3.0000, 3.3333, 3.6667, 4.0000]]]])
",,,
"
 class torch.nn. ChannelShuffle ( groups ) [source] ¶","Divide the channels in a tensor of shape  ( 
into g groups and rearrange them as  ( ,
while keeping the original tensor shape. 
 Parameters 
 groups 
 Examples: 
",">>> channel_shuffle=nn.ChannelShuffle(2)
>>> input=torch.randn(1,4,2,2)
>>> print(input)
[[[[1, 2],
   [3, 4]],
  [[5, 6],
   [7, 8]],
  [[9, 10],
   [11, 12]],
  [[13, 14],
   [15, 16]],
 ]]
>>> output=channel_shuffle(input)
>>> print(output)
[[[[1, 2],
   [3, 4]],
  [[9, 10],
   [11, 12]],
  [[5, 6],
   [7, 8]],
  [[13, 14],
   [15, 16]],
 ]]
",,,
"
 class torch.nn. DataParallel ( module ,  device_ids ,  output_device ,  dim ) [source] ¶","Implements data parallelism at the module level. This container parallelizes the application of the given  module  by
splitting the input across the specified devices by chunking in the batch
dimension (other objects will be copied once per device). In the forward
pass, the module is replicated on each device, and each replica handles a
portion of the input. During the backwards pass, gradients from each replica
are summed into the original module. The batch size should be larger than the number of GPUs used. 
 Warning 
 It is recommended to use  
 Arbitrary positional and keyword inputs are allowed to be passed into
DataParallel but some types are specially handled. tensors will be
 scattered  on dim specified (default 0). tuple, list and dict types will
be shallow copied. The other types will be shared among different threads
and can be corrupted if written to in the model’s forward pass. The parallelized  module  must have its parameters and buffers on
 device_ids[0]  before running this  DataParallel 
module. 
 Warning 
 In each forward,  
 
 Warning 
 Forward and backward hooks defined on  
 
 Warning 
 When  
 
 Note 
 There is a subtlety in using the
 
 
 Parameters 
 
 
 Variables 
 module 
 Example: 
",">>> net=torch.nn.DataParallel(model,device_ids=[0,1,2])
>>> output=net(input_var)# input_var can be on any device, including CPU
",,,
"
 class torch.nn.parallel. DistributedDataParallel ( module ,  device_ids ,  output_device ,  dim ,  broadcast_buffers ,  process_group ,  bucket_cap_mb ,  find_unused_parameters ,  check_reduction ,  gradient_as_bucket_view ,  static_graph ) [source] ¶","Implements distributed data parallelism that is based on
 torch.distributed  package at the module level. This container parallelizes the application of the given module by
splitting the input across the specified devices by chunking in the batch
dimension. The module is replicated on each machine and each device, and
each such replica handles a portion of the input. During the backwards
pass, gradients from each node are averaged. The batch size should be larger than the number of GPUs used locally. See also:  Basics  and  Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel .
The same constraints on input as in  torch.nn.DataParallel  apply. Creation of this class requires that  torch.distributed  to be already
initialized, by calling  torch.distributed.init_process_group() . DistributedDataParallel  is proven to be significantly faster than
 torch.nn.DataParallel  for single-node multi-GPU data
parallel training. To use  DistributedDataParallel  on a host with N GPUs, you should spawn
up  N  processes, ensuring that each process exclusively works on a single
GPU from 0 to N-1. This can be done by either setting
 CUDA_VISIBLE_DEVICES  for every process or by calling: 
 where i is from 0 to N-1. In each process, you should refer the following
to construct this module: 
 In order to spawn up multiple processes per node, you can use either
 torch.distributed.launch  or  torch.multiprocessing.spawn . 
 Note 
 Please refer to  
 
 Note 
 DistributedDataParallel 
 
 Note 
 nccl 
 
 Note 
 This module also supports mixed-precision distributed training.
This means that your model can have different types of parameters such
as mixed types of  
 
 Note 
 If you use  
 
 Note 
 When a model is trained on  
 
 Note 
 Parameters are never broadcast between processes. The module performs
an all-reduce step on gradients and assumes that they will be modified
by the optimizer in all processes in the same way. Buffers
(e.g. BatchNorm stats) are broadcast from the module in process of rank
0, to all other replicas in the system in every iteration. 
 
 Note 
 If you are using DistributedDataParallel in conjunction with the
 
 
 Note 
 DistributedDataParallel currently offers limited support for gradient
checkpointing with  
 Example: 
 
 
 Note 
 To let a non-DDP model load a state dict from a DDP model,
 
 
 Warning 
 Constructor, forward method, and differentiation of the output (or a
function of the output of this module) are distributed synchronization
points. Take that into account in case different processes might be
executing different code. 
 
 Warning 
 This module assumes all parameters are registered in the model by the
time it is created. No parameters should be added nor removed later.
Same applies to buffers. 
 
 Warning 
 This module assumes all parameters are registered in the model of each
distributed processes are in the same order. The module itself will
conduct gradient  
 
 Warning 
 This module allows parameters with non-rowmajor-contiguous strides.
For example, your model may contain some parameters whose
 
 
 Warning 
 This module doesn’t work with  
 
 Warning 
 If you plan on using this module with a  
 
 Warning 
 You should never try to change your model’s parameters after wrapping
up your model with  
 
 Warning 
 Using  
 
 Parameters 
 
 
 Variables 
 module 
 Example: 
 
 
 
 A context manager to be used in conjunction with an instance of
 
 
 
 Returns the DDP join hook, which enables training on uneven inputs by
shadowing the collective communications in the forward and backward
passes. 
 
 
 A context manager to disable gradient synchronizations across DDP
processes. Within this context, gradients will be accumulated on module
variables, which will later be synchronized in the first
forward-backward pass exiting the context. 
 
 
 Registers a communication hook which is an enhancement that provides a
flexible hook to users where they can specify how DDP aggregates gradients
across multiple workers.",">>> torch.distributed.init_process_group(backend='nccl',world_size=4,init_method='...')
>>> net=torch.nn.parallel.DistributedDataParallel(model)
",,,
"
 torch.nn.utils. clip_grad_norm_ ( parameters ,  max_norm ,  norm_type ,  error_if_nonfinite ) [source] ¶","Clips gradient norm of an iterable of parameters. The norm is computed over all gradients together, as if they were
concatenated into a single vector. Gradients are modified in-place. 
 Parameters 
 
 
 Returns 
 Total norm of the parameter gradients (viewed as a single vector). 
 Return type 
 Tensor 
",,,,
"
 torch.nn.utils. clip_grad_value_ ( parameters ,  clip_value ) [source] ¶","Clips gradient of an iterable of parameters at specified value. Gradients are modified in-place. 
 Parameters 
 
 
",,,,
"
 torch.nn.utils. parameters_to_vector ( parameters ) [source] ¶","Convert parameters to one vector 
 Parameters 
 parameters 
 Returns 
 The parameters represented by a single vector 
 Return type 
 Tensor 
",,,,
"
 torch.nn.utils. vector_to_parameters ( vec ,  parameters ) [source] ¶","Convert one vector to the parameters 
 Parameters 
 
 
",,,,
"
 class torch.nn.utils.prune. BasePruningMethod [source] ¶","Abstract base class for creation of new pruning techniques. Provides a skeleton for customization requiring the overriding of methods
such as  compute_mask()  and  apply() . 
 
 
 Adds the forward pre-hook that enables pruning on the fly and
the reparametrization of a tensor in terms of the original tensor
and the pruning mask. 
 
 
 Simply handles the multiplication between the parameter being
pruned and the generated mask.
Fetches the mask and the original tensor from the module
and returns the pruned version of the tensor. 
 
 
 Computes and returns a mask for the input tensor  
 
 
 Computes and returns a pruned version of input tensor  
 
 
 Removes the pruning reparameterization from a module. The pruned
parameter named ",,,,
"
 class torch.nn.utils.prune. PruningContainer ( * ) [source] ¶","Container holding a sequence of pruning methods for iterative pruning.
Keeps track of the order in which pruning methods are applied and handles
combining successive pruning calls. Accepts as argument an instance of a BasePruningMethod or an iterable of
them. 
 
 
 Adds a child pruning  
 
 
 Adds the forward pre-hook that enables pruning on the fly and
the reparametrization of a tensor in terms of the original tensor
and the pruning mask. 
 
 
 Simply handles the multiplication between the parameter being
pruned and the generated mask.
Fetches the mask and the original tensor from the module
and returns the pruned version of the tensor. 
 
 
 Applies the latest  
 
 
 Computes and returns a pruned version of input tensor  
 
 
 Removes the pruning reparameterization from a module. The pruned
parameter named ",,,,
"
 class torch.nn.utils.prune. Identity [source] ¶","Utility pruning method that does not prune any units but generates the
pruning parametrization with a mask of ones. 
 
 
 Adds the forward pre-hook that enables pruning on the fly and
the reparametrization of a tensor in terms of the original tensor
and the pruning mask. 
 
 
 Simply handles the multiplication between the parameter being
pruned and the generated mask.
Fetches the mask and the original tensor from the module
and returns the pruned version of the tensor. 
 
 
 Computes and returns a pruned version of input tensor  
 
 
 Removes the pruning reparameterization from a module. The pruned
parameter named ",,,,
"
 class torch.nn.utils.prune. RandomUnstructured ( amount ) [source] ¶","Prune (currently unpruned) units in a tensor at random. 
 Parameters 
 
 
 
 
 
 Adds the forward pre-hook that enables pruning on the fly and
the reparametrization of a tensor in terms of the original tensor
and the pruning mask. 
 
 
 Simply handles the multiplication between the parameter being
pruned and the generated mask.
Fetches the mask and the original tensor from the module
and returns the pruned version of the tensor. 
 
 
 Computes and returns a pruned version of input tensor  
 
 
 Removes the pruning reparameterization from a module. The pruned
parameter named ",,,,
"
 class torch.nn.utils.prune. L1Unstructured ( amount ) [source] ¶","Prune (currently unpruned) units in a tensor by zeroing out the ones
with the lowest L1-norm. 
 Parameters 
 amount 
 
 
 
 Adds the forward pre-hook that enables pruning on the fly and
the reparametrization of a tensor in terms of the original tensor
and the pruning mask. 
 
 
 Simply handles the multiplication between the parameter being
pruned and the generated mask.
Fetches the mask and the original tensor from the module
and returns the pruned version of the tensor. 
 
 
 Computes and returns a pruned version of input tensor  
 
 
 Removes the pruning reparameterization from a module. The pruned
parameter named ",,,,
"
 class torch.nn.utils.prune. RandomStructured ( amount ,  dim ) [source] ¶","Prune entire (currently unpruned) channels in a tensor at random. 
 Parameters 
 
 
 
 
 
 Adds the forward pre-hook that enables pruning on the fly and
the reparametrization of a tensor in terms of the original tensor
and the pruning mask. 
 
 
 Simply handles the multiplication between the parameter being
pruned and the generated mask.
Fetches the mask and the original tensor from the module
and returns the pruned version of the tensor. 
 
 
 Computes and returns a mask for the input tensor  
 
 
 Computes and returns a pruned version of input tensor  
 
 
 Removes the pruning reparameterization from a module. The pruned
parameter named ",,,,
"
 class torch.nn.utils.prune. LnStructured ( amount ,  n ,  dim ) [source] ¶","Prune entire (currently unpruned) channels in a tensor based on their
L n -norm. 
 Parameters 
 
 
 
 
 
 Adds the forward pre-hook that enables pruning on the fly and
the reparametrization of a tensor in terms of the original tensor
and the pruning mask. 
 
 
 Simply handles the multiplication between the parameter being
pruned and the generated mask.
Fetches the mask and the original tensor from the module
and returns the pruned version of the tensor. 
 
 
 Computes and returns a mask for the input tensor  
 
 
 Computes and returns a pruned version of input tensor  
 
 
 Removes the pruning reparameterization from a module. The pruned
parameter named ",,,,
"
 class torch.nn.utils.prune. CustomFromMask ( mask ) [source] ¶","
 
 
 Adds the forward pre-hook that enables pruning on the fly and
the reparametrization of a tensor in terms of the original tensor
and the pruning mask. 
 
 
 Simply handles the multiplication between the parameter being
pruned and the generated mask.
Fetches the mask and the original tensor from the module
and returns the pruned version of the tensor. 
 
 
 Computes and returns a pruned version of input tensor  
 
 
 Removes the pruning reparameterization from a module. The pruned
parameter named ",,,,
"
 torch.nn.utils.prune. identity ( module ,  name ) [source] ¶","Applies pruning reparametrization to the tensor corresponding to the
parameter called  name  in  module  without actually pruning any
units. Modifies module in place (and also return the modified module)
by: 
 adding a named buffer called  
 replacing the parameter  
 
 Note 
 The mask is a tensor of ones. 
 
 Parameters 
 
 
 Returns 
 modified (i.e. pruned) version of the input module 
 Return type 
 module ( 
 Examples 
",,,,
"
 torch.nn.utils.prune. random_unstructured ( module ,  name ,  amount ) [source] ¶","Prunes tensor corresponding to parameter called  name  in  module 
by removing the specified  amount  of (currently unpruned) units
selected at random.
Modifies module in place (and also return the modified module) by: 
 adding a named buffer called  
 replacing the parameter  
 
 Parameters 
 
 
 Returns 
 modified (i.e. pruned) version of the input module 
 Return type 
 module ( 
 Examples 
",,,,
"
 torch.nn.utils.prune. l1_unstructured ( module ,  name ,  amount ,  importance_scores ) [source] ¶","Prunes tensor corresponding to parameter called  name  in  module 
by removing the specified  amount  of (currently unpruned) units with the
lowest L1-norm.
Modifies module in place (and also return the modified module)
by: 
 adding a named buffer called  
 replacing the parameter  
 
 Parameters 
 
 
 Returns 
 modified (i.e. pruned) version of the input module 
 Return type 
 module ( 
 Examples 
",,,,
"
 torch.nn.utils.prune. random_structured ( module ,  name ,  amount ,  dim ) [source] ¶","Prunes tensor corresponding to parameter called  name  in  module 
by removing the specified  amount  of (currently unpruned) channels
along the specified  dim  selected at random.
Modifies module in place (and also return the modified module)
by: 
 adding a named buffer called  
 replacing the parameter  
 
 Parameters 
 
 
 Returns 
 modified (i.e. pruned) version of the input module 
 Return type 
 module ( 
 Examples 
",,,,
"
 torch.nn.utils.prune. ln_structured ( module ,  name ,  amount ,  n ,  dim ,  importance_scores ) [source] ¶","Prunes tensor corresponding to parameter called  name  in  module 
by removing the specified  amount  of (currently unpruned) channels
along the specified  dim  with the lowest L n -norm.
Modifies module in place (and also return the modified module)
by: 
 adding a named buffer called  
 replacing the parameter  
 
 Parameters 
 
 
 Returns 
 modified (i.e. pruned) version of the input module 
 Return type 
 module ( 
 Examples 
",,,,
"
 torch.nn.utils.prune. global_unstructured ( parameters ,  pruning_method ,  importance_scores ,  ** ) [source] ¶","Globally prunes tensors corresponding to all parameters in  parameters 
by applying the specified  pruning_method .
Modifies modules in place by: 
 adding a named buffer called  
 replacing the parameter  
 
 Parameters 
 
 
 Raises 
 TypeError 
 
 Note 
 Since global structured pruning doesn’t make much sense unless the
norm is normalized by the size of the parameter, we now limit the
scope of global pruning to unstructured methods. 
 Examples 
",,,,
"
 torch.nn.utils.prune. custom_from_mask ( module ,  name ,  mask ) [source] ¶","Prunes tensor corresponding to parameter called  name  in  module 
by applying the pre-computed mask in  mask .
Modifies module in place (and also return the modified module)
by: 
 adding a named buffer called  
 replacing the parameter  
 
 Parameters 
 
 
 Returns 
 modified (i.e. pruned) version of the input module 
 Return type 
 module ( 
 Examples 
",,,,
"
 torch.nn.utils.prune. remove ( module ,  name ) [source] ¶","Removes the pruning reparameterization from a module and the
pruning method from the forward hook. The pruned
parameter named  name  remains permanently pruned, and the parameter
named  name+'_orig'  is removed from the parameter list. Similarly,
the buffer named  name+'_mask'  is removed from the buffers. 
 Note 
 Pruning itself is NOT undone or reversed! 
 
 Parameters 
 
 
 Examples 
",,,,
"
 torch.nn.utils.prune. is_pruned ( module ) [source] ¶","Check whether  module  is pruned by looking for
 forward_pre_hooks  in its modules that inherit from the
 BasePruningMethod . 
 Parameters 
 module 
 Returns 
 binary answer to whether  
 Examples 
",,,,
"
 torch.nn.utils. weight_norm ( module ,  name ,  dim ) [source] ¶","Applies weight normalization to a parameter in the given module. 
 w Weight normalization is a reparameterization that decouples the magnitude
of a weight tensor from its direction. This replaces the parameter specified
by  name  (e.g.  'weight' ) with two parameters: one specifying the magnitude
(e.g.  'weight_g' ) and one specifying the direction (e.g.  'weight_v' ).
Weight normalization is implemented via a hook that recomputes the weight
tensor from the magnitude and direction before every  forward() 
call. By default, with  dim=0 , the norm is computed independently per output
channel/plane. To compute a norm over the entire weight tensor, use
 dim=None . See  https://arxiv.org/abs/1602.07868 
 Parameters 
 
 
 Returns 
 The original module with the weight norm hook 
 Return type 
 T_module 
 Example: 
",">>> m=weight_norm(nn.Linear(20,40),name='weight')
>>> m
Linear(in_features=20, out_features=40, bias=True)
>>> m.weight_g.size()
torch.Size([40, 1])
>>> m.weight_v.size()
torch.Size([40, 20])
",,,
"
 torch.nn.utils. remove_weight_norm ( module ,  name ) [source] ¶","Removes the weight normalization reparameterization from a module. 
 Parameters 
 
 
 Return type 
 T_module 
 Example 
",,,,
"
 torch.nn.utils. spectral_norm ( module ,  name ,  n_power_iterations ,  eps ,  dim ) [source] ¶","Applies spectral normalization to a parameter in the given module. 
 W Spectral normalization stabilizes the training of discriminators (critics)
in Generative Adversarial Networks (GANs) by rescaling the weight tensor
with spectral norm  σ  of the weight matrix calculated using
power iteration method. If the dimension of the weight tensor is greater
than 2, it is reshaped to 2D in power iteration method to get spectral
norm. This is implemented via a hook that calculates spectral norm and
rescales weight before every  forward()  call. See  Spectral Normalization for Generative Adversarial Networks  . 
 Parameters 
 
 
 Returns 
 The original module with the spectral norm hook 
 Return type 
 T_module 
 
 Note 
 This function has been reimplemented as
 
 Example: 
",">>> m=spectral_norm(nn.Linear(20,40))
>>> m
Linear(in_features=20, out_features=40, bias=True)
>>> m.weight_u.size()
torch.Size([40])
",,,
"
 torch.nn.utils. remove_spectral_norm ( module ,  name ) [source] ¶","Removes the spectral normalization reparameterization from a module. 
 Parameters 
 
 
 Return type 
 T_module 
 Example 
",,,,
"
 torch.nn.utils. skip_init ( module_cls ,  * ,  ** ) [source] ¶","Given a module class object and args / kwargs, instantiates the module without initializing
parameters / buffers.  This can be useful if initialization is slow or if custom initialization will
be performed, making the default initialization unnecessary. There are some caveats to this, due to
the way this function is implemented: 1. The module must accept a  device  arg in its constructor that is passed to any parameters
or buffers created during construction. 2. The module must not perform any computation on parameters in its constructor except
initialization (i.e. functions from  torch.nn.init ). If these conditions are satisfied, the module can be instantiated with parameter / buffer values
uninitialized, as if having been created using  torch.empty() . 
 Parameters 
 
 
 Returns 
 Instantiated module with uninitialized parameters / buffers 
 Example: 
",">>> importtorch
>>> m=torch.nn.utils.skip_init(torch.nn.Linear,5,1)
>>> m.weight
Parameter containing:
tensor([[0.0000e+00, 1.5846e+29, 7.8307e+00, 2.5250e-29, 1.1210e-44]],
       requires_grad=True)
>>> m2=torch.nn.utils.skip_init(torch.nn.Linear,in_features=6,out_features=1)
>>> m2.weight
Parameter containing:
tensor([[-1.4677e+24,  4.5915e-41,  1.4013e-45,  0.0000e+00, -1.4677e+24,
          4.5915e-41]], requires_grad=True)
",,,
"
 torch.nn.utils.parametrizations. orthogonal ( module ,  name ,  orthogonal_map ,  * ,  use_trivialization ) [source] ¶","Applies an orthogonal or unitary parametrization to a matrix or a batch of matrices. Letting  K  be  R  or  C , the parametrized
matrix  Q  is  orthogonal  as 
 Q where  Q  is the conjugate transpose when  Q  is complex
and the transpose when  Q  is real-valued, and
 I  is the  n -dimensional identity matrix.
In plain words,  Q  will have orthonormal columns whenever  m 
and orthonormal rows otherwise. If the tensor has more than two dimensions, we consider it as a batch of matrices of shape  (…, m, n) . The matrix  Q  may be parametrized via three different  orthogonal_map  in terms of the original tensor: 
 ""matrix_exp"" 
 ""householder"" 
 ""matrix_exp"" / ""cayley""  often make the parametrized weight converge faster than
 ""householder"" , but they are slower to compute for very thin or very wide matrices. If  use_trivialization=True  (default), the parametrization implements the “Dynamic Trivialization Framework”,
where an extra matrix  B  is stored under
 module.parametrizations.weight[0].base . This helps the
convergence of the parametrized layer at the expense of some extra memory use.
See  Trivializations for Gradient-Based Optimization on Manifolds  . Initial value of  Q :
If the original tensor is not parametrized and  use_trivialization=True  (default), the initial value
of  Q  is that of the original tensor if it is orthogonal (or unitary in the complex case)
and it is orthogonalized via the QR decomposition otherwise (see  torch.linalg.qr() ).
Same happens when it is not parametrized and  orthogonal_map=""householder""  even when  use_trivialization=False .
Otherwise, the initial value is the result of the composition of all the registered
parametrizations applied to the original tensor. 
 Note 
 This function is implemented using the parametrization functionality
in  
 
 Parameters 
 
 
 Returns 
 The original module with an orthogonal parametrization registered to the specified
weight 
 Return type 
 Module 
 Example: 
",">>> orth_linear=orthogonal(nn.Linear(20,40))
>>> orth_linear
ParametrizedLinear(
in_features=20, out_features=40, bias=True
(parametrizations): ModuleDict(
    (weight): ParametrizationList(
    (0): _Orthogonal()
    )
)
)
>>> Q=orth_linear.weight
>>> torch.dist(Q.T@Q,torch.eye(20))
tensor(4.9332e-07)
",,,
"
 torch.nn.utils.parametrizations. spectral_norm ( module ,  name ,  n_power_iterations ,  eps ,  dim ) [source] ¶","Applies spectral normalization to a parameter in the given module. 
 W When applied on a vector, it simplifies to 
 x Spectral normalization stabilizes the training of discriminators (critics)
in Generative Adversarial Networks (GANs) by reducing the Lipschitz constant
of the model.  σ  is approximated performing one iteration of the
 power method  every time the weight is accessed. If the dimension of the
weight tensor is greater than 2, it is reshaped to 2D in power iteration
method to get spectral norm. See  Spectral Normalization for Generative Adversarial Networks  . 
 Note 
 This function is implemented using the parametrization functionality
in  
 
 Note 
 When this constraint is registered, the singular vectors associated to the largest
singular value are estimated rather than sampled at random. These are then updated
performing  
 
 Note 
 If the  
 
 Parameters 
 
 
 Returns 
 The original module with a new parametrization registered to the specified
weight 
 Return type 
 Module 
 Example: 
",">>> snm=spectral_norm(nn.Linear(20,40))
>>> snm
ParametrizedLinear(
  in_features=20, out_features=40, bias=True
  (parametrizations): ModuleDict(
    (weight): ParametrizationList(
      (0): _SpectralNorm()
    )
  )
)
>>> torch.linalg.matrix_norm(snm.weight,2)
tensor(1.0081, grad_fn=<AmaxBackward0>)
",,,
"
 torch.nn.utils.parametrize. register_parametrization ( module ,  tensor_name ,  parametrization ,  * ,  unsafe ) [source] ¶","Adds a parametrization to a tensor in a module. Assume that  tensor_name=""weight""  for simplicity. When accessing  module.weight ,
the module will return the parametrized version  parametrization(module.weight) .
If the original tensor requires a gradient, the backward pass will differentiate
through  parametrization , and the optimizer will update the tensor accordingly. The first time that a module registers a parametrization, this function will add an attribute
 parametrizations  to the module of type  ParametrizationList . The list of parametrizations on the tensor  weight  will be accessible under
 module.parametrizations.weight . The original tensor will be accessible under
 module.parametrizations.weight.original . Parametrizations may be concatenated by registering several parametrizations
on the same attribute. The training mode of a registered parametrization is updated on registration
to match the training mode of the host module Parametrized parameters and buffers have an inbuilt caching system that can be activated
using the context manager  cached() . A  parametrization  may optionally implement a method with signature 
 This method is called on the unparametrized tensor when the first parametrization
is registered to compute the initial value of the original tensor.
If this method is not implemented, the original tensor will be just the unparametrized tensor. If all the parametrizations registered on a tensor implement  right_inverse  it is possible
to initialize a parametrized tensor by assigning to it, as shown in the example below. It is possible for the first parametrization to depend on several inputs.
This may be implemented returning a tuple of tensors from  right_inverse 
(see the example implementation of a  RankOne  parametrization below). In this case, the unconstrained tensors are also located under  module.parametrizations.weight 
with names  original0 ,  original1 ,… 
 Note 
 If unsafe=False (default) both the forward and right_inverse methods will be called
once to perform a number of consistency checks.
If unsafe=True, then right_inverse will be called if the tensor is not parametrized,
and nothing will be called otherwise. 
 
 Note 
 In most situations,  
 
 Warning 
 If a parametrization depends on several inputs,  
 
 Parameters 
 
 
 Keyword Arguments 
 unsafe 
 Raises 
 ValueError 
 Return type 
 Module 
 Examples 
 
",,,,
"
 torch.nn.utils.parametrize. remove_parametrizations ( module ,  tensor_name ,  leave_parametrized ) [source] ¶","Removes the parametrizations on a tensor in a module. 
 If  
 If  
 
 Parameters 
 
 
 Returns 
 module 
 Return type 
 Module 
 Raises 
 
 
",,,,
"
 torch.nn.utils.parametrize. cached ( ) [source] ¶","Context manager that enables the caching system within parametrizations
registered with  register_parametrization() . The value of the parametrized objects is computed and cached the first time
they are required when this context manager is active. The cached values are
discarded when leaving the context manager. This is useful when using a parametrized parameter more than once in the forward pass.
An example of this is when parametrizing the recurrent kernel of an RNN or when
sharing weights. The simplest way to activate the cache is by wrapping the forward pass of the neural network 
 in training and evaluation. One may also wrap the parts of the modules that use
several times the parametrized tensors. For example, the loop of an RNN with a
parametrized recurrent kernel: 
",,,,
"
 torch.nn.utils.parametrize. is_parametrized ( module ,  tensor_name ) [source] ¶","Returns  True  if module has an active parametrization. If the argument  tensor_name  is specified, returns  True  if
 module[tensor_name]  is parametrized. 
 Parameters 
 
 
 Return type 
 bool 
",,,,
"
 class torch.nn.utils.parametrize. ParametrizationList ( modules ,  original ,  unsafe ) [source] ¶","A sequential container that holds and manages the  original  or  original0 ,  original1 , …
parameters or buffers of a parametrized  torch.nn.Module . It is the type of  module.parametrizations[tensor_name]  when  module[tensor_name] 
has been parametrized with  register_parametrization() . If the first registered parmetrization has a  right_inverse  that returns one tensor or
does not have a  right_inverse  (in which case we assume that  right_inverse  is the identity),
it will hold the tensor under the name  original .
If it has a  right_inverse  that returns more than one tensor, these will be registered as
 original0 ,  original1 , … 
 Warning 
 This class is used internally by  
 
 Parameters 
 
 
 
 
 
 Calls the methods ",,,,
"
 torch.nn.utils.stateless. functional_call ( module ,  parameters_and_buffers ,  args ,  kwargs ) [source] ¶","Performs a functional call on the module by replacing the module parameters
and buffers with the provided ones. 
 Note 
 If the module has active parametrizations, passing a value in the
 
 
 Note 
 If the module performs in-place operations on parameters/buffers, these will be reflected
in the  
 Example: 
 
 
 Parameters 
 
 
 Returns 
 the result of calling  
 Return type 
 Any 
",,,,
"
 class torch.nn.utils.rnn. PackedSequence ( data ,  batch_sizes ,  sorted_indices ,  unsorted_indices ) [source] ¶","Holds the data and list of  batch_sizes  of a packed sequence. All RNN modules accept packed sequences as inputs. 
 Note 
 Instances of this class should never be created manually. They are meant
to be instantiated by functions like  
 Batch sizes represent the number elements at each sequence step in
the batch, not the varying sequence lengths passed to
 
 
 Variables 
 
 
 
 Note 
 data 
 However,  
 This invariant is maintained throughout  
 
 
 
 Alias for field number 1 
 
 
 Return number of occurrences of value. 
 
 
 Alias for field number 0 
 
 
 Return first index of value. 
 
 
 Returns true if  
 
 
 Returns true if  
 
 
 Alias for field number 2 
 
 
 Performs dtype and/or device conversion on  
 
 
 Alias for field number 3",,,,
"
 torch.nn.utils.rnn. pack_padded_sequence ( input ,  lengths ,  batch_first ,  enforce_sorted ) [source] ¶","Packs a Tensor containing padded sequences of variable length. input  can be of size  T  where  T  is the length of the
longest sequence (equal to  lengths[0] ),  B  is the batch size, and
 *  is any number of dimensions (including 0). If  batch_first  is
 True ,  B   input  is expected. For unsorted sequences, use  enforce_sorted = False . If  enforce_sorted  is
 True , the sequences should be sorted by length in a decreasing order, i.e.
 input[:,0]  should be the longest sequence, and  input[:,B-1]  the shortest
one.  enforce_sorted = True  is only necessary for ONNX export. 
 Note 
 This function accepts any input that has at least two dimensions. You
can apply it to pack the labels, and use the output of the RNN with
them to compute the loss directly. A Tensor can be retrieved from
a  
 
 Parameters 
 
 
 Returns 
 a  
 Return type 
 PackedSequence 
",,,,
"
 torch.nn.utils.rnn. pad_packed_sequence ( sequence ,  batch_first ,  padding_value ,  total_length ) [source] ¶","Pads a packed batch of variable length sequences. It is an inverse operation to  pack_padded_sequence() . The returned Tensor’s data will be of size  T , where  T  is the length
of the longest sequence and  B  is the batch size. If  batch_first  is True,
the data will be transposed into  B  format. Example 
 
 Note 
 total_length 
 
 Parameters 
 
 
 Returns 
 Tuple of Tensor containing the padded sequence, and a Tensor
containing the list of lengths of each sequence in the batch.
Batch elements will be re-ordered as they were ordered originally when
the batch was passed to  
 Return type 
 Tuple 
",,,,
"
 torch.nn.utils.rnn. pad_sequence ( sequences ,  batch_first ,  padding_value ) [source] ¶","Pad a list of variable length Tensors with  padding_value pad_sequence  stacks a list of Tensors along a new dimension,
and pads them to equal length. For example, if the input is list of
sequences with size  L  and if batch_first is False, and  T 
otherwise. B  is batch size. It is equal to the number of elements in  sequences .
 T  is length of the longest sequence.
 L  is length of the sequence.
 *  is any number of trailing dimensions, including none. Example 
 
 Note 
 This function returns a Tensor of size  
 
 Parameters 
 
 
 Returns 
 Tensor of size  
 Return type 
 Tensor 
",,,,
"
 torch.nn.utils.rnn. pack_sequence ( sequences ,  enforce_sorted ) [source] ¶","Packs a list of variable length Tensors Consecutive call of the next functions:  pad_sequence ,  pack_padded_sequence . sequences  should be a list of Tensors of size  L , where  L  is
the length of a sequence and  *  is any number of trailing dimensions,
including zero. For unsorted sequences, use  enforce_sorted = False . If  enforce_sorted 
is  True , the sequences should be sorted in the order of decreasing length.
 enforce_sorted  is only necessary for ONNX export. Example 
 
 Parameters 
 
 
 Returns 
 a  
 Return type 
 PackedSequence 
",,,,
"
 class torch.nn. Flatten ( start_dim ,  end_dim ) [source] ¶","Flattens a contiguous range of dims into a tensor. For use with  Sequential . 
 Shape: 
 
 
 Parameters 
 
 
 
 Examples:: 
",,,,
"
 class torch.nn. Unflatten ( dim ,  unflattened_size ) [source] ¶","Unflattens a tensor dim expanding it to a desired shape. For use with  Sequential . 
 dim 
 unflattened_size 
 
 Shape: 
 
 
 Parameters 
 
 
 Examples 
",,,,
"
 class torch.nn.modules.lazy. LazyModuleMixin ( * ,  ** ) [source] ¶","A mixin for modules that lazily initialize parameters, also known as “lazy modules.” Modules that lazily initialize parameters, or “lazy modules”,
derive the shapes of their parameters from the first input(s)
to their forward method. Until that first forward they contain
 torch.nn.UninitializedParameter  s that should not be accessed
or used, and afterward they contain regular  torch.nn.Parameter  s.
Lazy modules are convenient since they don’t require computing some
module arguments, like the  in_features  argument of a
typical  torch.nn.Linear . After construction, networks with lazy modules should first
be converted to the desired dtype and placed on the expected device.
This is because lazy modules only perform shape inference so the usual dtype
and device placement behavior applies.
The lazy modules should then perform “dry runs” to initialize all the components in the module.
These “dry runs” send inputs of the correct size, dtype, and device through
the network and to each one of its lazy modules. After this the network can be used as usual. 
 A final caveat when using lazy modules is that the order of initialization of a network’s
parameters may change, since the lazy modules are always initialized after other modules.
For example, if the LazyMLP class defined above had a  torch.nn.LazyLinear  module
first and then a regular  torch.nn.Linear  second, the second module would be
initialized on construction and the first module would be initialized during the first dry run.
This can cause the parameters of a network using lazy modules to be initialized differently
than the parameters of a network without lazy modules as the order of parameter initializations,
which often depends on a stateful random number generator, is different.
Check  Reproducibility  for more details. Lazy modules can be serialized with a state dict like other modules. For example: 
 Lazy modules can load regular  torch.nn.Parameter  s (i.e. you can serialize/deserialize
initialized LazyModules and they will remain initialized) 
 Note, however, that the loaded parameters will not be replaced when doing a “dry run” if they are initialized
when the state is loaded. This prevents using initialized modules in different contexts. 
 
 
 Check if a module has parameters that are not initialized 
 
 
 Initialize parameters according to the input batch properties.
This adds an interface to isolate parameter initialization from the
forward pass when doing parameter shape inference.",,,,
"
 torch.nn.functional. conv1d ( input ,  weight ,  bias ,  stride ,  padding ,  dilation ,  groups )   → ¶","Applies a 1D convolution over an input signal composed of several input
planes. This operator supports  TensorFloat32 . See  Conv1d  for details and output shape. 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Note 
 This operator supports complex data types i.e.  
 
 Parameters 
 
 
 Examples: 
",">>> inputs=torch.randn(33,16,30)
>>> filters=torch.randn(20,16,5)
>>> F.conv1d(inputs,filters)
",,,
"
 torch.nn.functional. conv2d ( input ,  weight ,  bias ,  stride ,  padding ,  dilation ,  groups )   → ¶","Applies a 2D convolution over an input image composed of several input
planes. This operator supports  TensorFloat32 . See  Conv2d  for details and output shape. 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Note 
 This operator supports complex data types i.e.  
 
 Parameters 
 
 
 Examples: 
",">>> # With square kernels and equal stride
>>> filters=torch.randn(8,4,3,3)
>>> inputs=torch.randn(1,4,5,5)
>>> F.conv2d(inputs,filters,padding=1)
",,,
"
 torch.nn.functional. conv3d ( input ,  weight ,  bias ,  stride ,  padding ,  dilation ,  groups )   → ¶","Applies a 3D convolution over an input image composed of several input
planes. This operator supports  TensorFloat32 . See  Conv3d  for details and output shape. 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Note 
 This operator supports complex data types i.e.  
 
 Parameters 
 
 
 Examples: 
",">>> filters=torch.randn(33,16,3,3,3)
>>> inputs=torch.randn(20,16,50,10,20)
>>> F.conv3d(inputs,filters)
",,,
"
 torch.nn.functional. conv_transpose1d ( input ,  weight ,  bias ,  stride ,  padding ,  output_padding ,  groups ,  dilation )   → ¶","Applies a 1D transposed convolution operator over an input signal
composed of several input planes, sometimes also called “deconvolution”. This operator supports  TensorFloat32 . See  ConvTranspose1d  for details and output shape. 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Parameters 
 
 
 Examples: 
",">>> inputs=torch.randn(20,16,50)
>>> weights=torch.randn(16,33,5)
>>> F.conv_transpose1d(inputs,weights)
",,,
"
 torch.nn.functional. conv_transpose2d ( input ,  weight ,  bias ,  stride ,  padding ,  output_padding ,  groups ,  dilation )   → ¶","Applies a 2D transposed convolution operator over an input image
composed of several input planes, sometimes also called “deconvolution”. This operator supports  TensorFloat32 . See  ConvTranspose2d  for details and output shape. 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Parameters 
 
 
 Examples: 
",">>> # With square kernels and equal stride
>>> inputs=torch.randn(1,4,5,5)
>>> weights=torch.randn(4,8,3,3)
>>> F.conv_transpose2d(inputs,weights,padding=1)
",,,
"
 torch.nn.functional. conv_transpose3d ( input ,  weight ,  bias ,  stride ,  padding ,  output_padding ,  groups ,  dilation )   → ¶","Applies a 3D transposed convolution operator over an input image
composed of several input planes, sometimes also called “deconvolution” This operator supports  TensorFloat32 . See  ConvTranspose3d  for details and output shape. 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Parameters 
 
 
 Examples: 
",">>> inputs=torch.randn(20,16,50,10,20)
>>> weights=torch.randn(16,33,3,3,3)
>>> F.conv_transpose3d(inputs,weights)
",,,
"
 torch.nn.functional. unfold ( input ,  kernel_size ,  dilation ,  padding ,  stride ) [source] ¶","Extracts sliding local blocks from a batched input tensor. 
 Warning 
 Currently, only 4-D input tensors (batched image-like tensors) are
supported. 
 
 Warning 
 More than one element of the unfolded tensor may refer to a single
memory location. As a result, in-place operations (especially ones that
are vectorized) may result in incorrect behavior. If you need to write
to the tensor, please clone it first. 
 See  torch.nn.Unfold  for details 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. fold ( input ,  output_size ,  kernel_size ,  dilation ,  padding ,  stride ) [source] ¶","Combines an array of sliding local blocks into a large containing
tensor. 
 Warning 
 Currently, only unbatched (3D) or batched (4D) image-like output tensors are supported. 
 See  torch.nn.Fold  for details 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. avg_pool1d ( input ,  kernel_size ,  stride ,  padding ,  ceil_mode ,  count_include_pad )   → ¶","Applies a 1D average pooling over an input signal composed of several
input planes. See  AvgPool1d  for details and output shape. 
 Parameters 
 
 
 Examples: 
",">>> # pool of square window of size=3, stride=2
>>> input=torch.tensor([[[1,2,3,4,5,6,7]]],dtype=torch.float32)
>>> F.avg_pool1d(input,kernel_size=3,stride=2)
tensor([[[ 2.,  4.,  6.]]])
",,,
"
 torch.nn.functional. avg_pool2d ( input ,  kernel_size ,  stride ,  padding ,  ceil_mode ,  count_include_pad ,  divisor_override )   → ¶","Applies 2D average-pooling operation in  k  regions by step size
 s  steps. The number of output features is equal to the number of
input planes. See  AvgPool2d  for details and output shape. 
 Parameters 
 
 
",,,,
"
 torch.nn.functional. avg_pool3d ( input ,  kernel_size ,  stride ,  padding ,  ceil_mode ,  count_include_pad ,  divisor_override )   → ¶","Applies 3D average-pooling operation in  k  regions by step
size  s  steps. The number of output features is equal to
 ⌊ . See  AvgPool3d  for details and output shape. 
 Parameters 
 
 
",,,,
"
 torch.nn.functional. max_pool1d ( input ,  kernel_size ,  stride ,  padding ,  dilation ,  ceil_mode ,  return_indices ) ¶","Applies a 1D max pooling over an input signal composed of several input
planes. 
 Note 
 The order of  
 See  MaxPool1d  for details. 
 Parameters 
 
 
",,,,
"
 torch.nn.functional. max_pool2d ( input ,  kernel_size ,  stride ,  padding ,  dilation ,  ceil_mode ,  return_indices ) ¶","Applies a 2D max pooling over an input signal composed of several input
planes. 
 Note 
 The order of  
 See  MaxPool2d  for details. 
 Parameters 
 
 
",,,,
"
 torch.nn.functional. max_pool3d ( input ,  kernel_size ,  stride ,  padding ,  dilation ,  ceil_mode ,  return_indices ) ¶","Applies a 3D max pooling over an input signal composed of several input
planes. 
 Note 
 The order of  
 See  MaxPool3d  for details. 
 Parameters 
 
 
",,,,
"
 torch.nn.functional. max_unpool1d ( input ,  indices ,  kernel_size ,  stride ,  padding ,  output_size ) [source] ¶","Computes a partial inverse of  MaxPool1d . See  MaxUnpool1d  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. max_unpool2d ( input ,  indices ,  kernel_size ,  stride ,  padding ,  output_size ) [source] ¶","Computes a partial inverse of  MaxPool2d . See  MaxUnpool2d  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. max_unpool3d ( input ,  indices ,  kernel_size ,  stride ,  padding ,  output_size ) [source] ¶","Computes a partial inverse of  MaxPool3d . See  MaxUnpool3d  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. lp_pool1d ( input ,  norm_type ,  kernel_size ,  stride ,  ceil_mode ) [source] ¶","Applies a 1D power-average pooling over an input signal composed of
several input planes. If the sum of all inputs to the power of  p  is
zero, the gradient is set to zero as well. See  LPPool1d  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. lp_pool2d ( input ,  norm_type ,  kernel_size ,  stride ,  ceil_mode ) [source] ¶","Applies a 2D power-average pooling over an input signal composed of
several input planes. If the sum of all inputs to the power of  p  is
zero, the gradient is set to zero as well. See  LPPool2d  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. adaptive_max_pool1d ( * ,  ** ) ¶","Applies a 1D adaptive max pooling over an input signal composed of
several input planes. See  AdaptiveMaxPool1d  for details and output shape. 
 Parameters 
 
 
",,,,
"
 torch.nn.functional. adaptive_max_pool2d ( * ,  ** ) ¶","Applies a 2D adaptive max pooling over an input signal composed of
several input planes. See  AdaptiveMaxPool2d  for details and output shape. 
 Parameters 
 
 
",,,,
"
 torch.nn.functional. adaptive_max_pool3d ( * ,  ** ) ¶","Applies a 3D adaptive max pooling over an input signal composed of
several input planes. See  AdaptiveMaxPool3d  for details and output shape. 
 Parameters 
 
 
",,,,
"
 torch.nn.functional. adaptive_avg_pool1d ( input ,  output_size )   → ¶","Applies a 1D adaptive average pooling over an input signal composed of
several input planes. See  AdaptiveAvgPool1d  for details and output shape. 
 Parameters 
 output_size 
",,,,
"
 torch.nn.functional. adaptive_avg_pool2d ( input ,  output_size ) [source] ¶","Applies a 2D adaptive average pooling over an input signal composed of
several input planes. See  AdaptiveAvgPool2d  for details and output shape. 
 Parameters 
 output_size 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. adaptive_avg_pool3d ( input ,  output_size ) [source] ¶","Applies a 3D adaptive average pooling over an input signal composed of
several input planes. See  AdaptiveAvgPool3d  for details and output shape. 
 Parameters 
 output_size 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. fractional_max_pool2d ( * ,  ** ) ¶","Applies 2D fractional max pooling over an input signal composed of several input planes. Fractional MaxPooling is described in detail in the paper  Fractional MaxPooling  by Ben Graham The max-pooling operation is applied in  k  regions by a stochastic
step size determined by the target output size.
The number of output features is equal to the number of input planes. 
 Parameters 
 
 
 
 Examples:: 
",,,,
"
 torch.nn.functional. fractional_max_pool3d ( * ,  ** ) ¶","Applies 3D fractional max pooling over an input signal composed of several input planes. Fractional MaxPooling is described in detail in the paper  Fractional MaxPooling  by Ben Graham The max-pooling operation is applied in  k  regions by a stochastic
step size determined by the target output size.
The number of output features is equal to the number of input planes. 
 Parameters 
 
 
 
 Shape: 
 
 Examples:: 
",,,,
"
 torch.nn.functional. threshold ( input ,  threshold ,  value ,  inplace ) ¶","Thresholds each element of the input Tensor. See  Threshold  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. threshold_ ( input ,  threshold ,  value )   → ¶",In-place version of  threshold() .,,,,
"
 torch.nn.functional. relu ( input ,  inplace )   → [source] ¶","Applies the rectified linear unit function element-wise. See
 ReLU  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. relu_ ( input )   → ¶",In-place version of  relu() .,,,,
"
 torch.nn.functional. hardtanh ( input ,  min_val ,  max_val ,  inplace )   → [source] ¶","Applies the HardTanh function element-wise. See  Hardtanh  for more
details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. hardtanh_ ( input ,  min_val ,  max_val )   → ¶",In-place version of  hardtanh() .,,,,
"
 torch.nn.functional. hardswish ( input ,  inplace ) [source] ¶","Applies the hardswish function, element-wise, as described in the paper: Searching for MobileNetV3 . 
 Hardswish See  Hardswish  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. relu6 ( input ,  inplace )   → [source] ¶","Applies the element-wise function  ReLU6 . See  ReLU6  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. elu ( input ,  alpha ,  inplace ) [source] ¶","Applies the Exponential Linear Unit (ELU) function element-wise. See  ELU  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. elu_ ( input ,  alpha )   → ¶",In-place version of  elu() .,,,,
"
 torch.nn.functional. selu ( input ,  inplace )   → [source] ¶","Applies element-wise,
 SELU ,
with  α  and
 s . See  SELU  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. celu ( input ,  alpha ,  inplace )   → [source] ¶","Applies element-wise,
 CELU . See  CELU  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. leaky_relu ( input ,  negative_slope ,  inplace )   → [source] ¶","Applies element-wise,
 LeakyReLU See  LeakyReLU  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. leaky_relu_ ( input ,  negative_slope )   → ¶",In-place version of  leaky_relu() .,,,,
"
 torch.nn.functional. prelu ( input ,  weight )   → ¶","Applies element-wise the function
 PReLU  where weight is a
learnable parameter. 
 Note 
 weight 
 See  PReLU  for more details.",,,,
"
 torch.nn.functional. rrelu ( input ,  lower ,  upper ,  training ,  inplace )   → [source] ¶","Randomized leaky ReLU. See  RReLU  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. rrelu_ ( input ,  lower ,  upper ,  training )   → ¶",In-place version of  rrelu() .,,,,
"
 torch.nn.functional. glu ( input ,  dim )   → [source] ¶","The gated linear unit. Computes: 
 GLU where  input  is split in half along  dim  to form  a  and  b ,  σ 
is the sigmoid function and  ⊗  is the element-wise product between matrices. See  Language Modeling with Gated Convolutional Networks . 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. gelu ( input ,  approximate )   → ¶","When the approximate argument is ‘none’, it applies element-wise the function
 GELU where  Φ  is the Cumulative Distribution Function for Gaussian Distribution. 
 When the approximate argument is ‘tanh’, Gelu is estimated with: 
 
 See  Gaussian Error Linear Units (GELUs) .",,,,
"
 torch.nn.functional. logsigmoid ( input )   → ¶",Applies element-wise  LogSigmoid See  LogSigmoid  for more details.,,,,
"
 torch.nn.functional. hardshrink ( input ,  lambd )   → ¶",Applies the hard shrinkage function element-wise See  Hardshrink  for more details.,,,,
"
 torch.nn.functional. tanhshrink ( input )   → [source] ¶","Applies element-wise,  Tanhshrink See  Tanhshrink  for more details.",,,,
"
 torch.nn.functional. softsign ( input )   → [source] ¶","Applies element-wise, the function  SoftSign See  Softsign  for more details.",,,,
"
 torch.nn.functional. softplus ( input ,  beta ,  threshold )   → ¶","Applies element-wise, the function  Softplus . For numerical stability the implementation reverts to the linear function
when  i . See  Softplus  for more details.",,,,
"
 torch.nn.functional. softmin ( input ,  dim ,  _stacklevel ,  dtype ) [source] ¶","Applies a softmin function. Note that  Softmin . See softmax definition for mathematical formula. See  Softmin  for more details. 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. softmax ( input ,  dim ,  _stacklevel ,  dtype ) [source] ¶","Applies a softmax function. Softmax is defined as: Softmax It is applied to all slices along dim, and will re-scale them so that the elements
lie in the range  [0, 1]  and sum to 1. See  Softmax  for more details. 
 Parameters 
 
 
 Return type 
 Tensor 
 
 Note 
 This function doesn’t work directly with NLLLoss,
which expects the Log to be computed between the Softmax and itself.
Use log_softmax instead (it’s faster and has better numerical properties). 
",,,,
"
 torch.nn.functional. softshrink ( input ,  lambd )   → ¶",Applies the soft shrinkage function elementwise See  Softshrink  for more details.,,,,
"
 torch.nn.functional. gumbel_softmax ( logits ,  tau ,  hard ,  eps ,  dim ) [source] ¶","Samples from the Gumbel-Softmax distribution ( Link 1   Link 2 ) and optionally discretizes. 
 Parameters 
 
 
 Returns 
 Sampled tensor of same shape as  
 Return type 
 Tensor 
 
 Note 
 This function is here for legacy reasons, may be removed from nn.Functional in the future. 
 
 Note 
 The main trick for  
 It achieves two things:
- makes the output value exactly one-hot
(since we add then subtract y_soft value)
- makes the gradient equal to y_soft gradient
(since we strip all other gradients) 
 
 Examples:: 
",,,,
"
 torch.nn.functional. log_softmax ( input ,  dim ,  _stacklevel ,  dtype ) [source] ¶","Applies a softmax followed by a logarithm. While mathematically equivalent to log(softmax(x)), doing these two
operations separately is slower and numerically unstable. This function
uses an alternative formulation to compute the output and gradient correctly. See  LogSoftmax  for more details. 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. tanh ( input )   → [source] ¶","Applies element-wise,
 Tanh See  Tanh  for more details.",,,,
"
 torch.nn.functional. sigmoid ( input )   → [source] ¶",Applies the element-wise function  Sigmoid See  Sigmoid  for more details.,,,,
"
 torch.nn.functional. hardsigmoid ( input ,  inplace ) [source] ¶","Applies the element-wise function 
 Hardsigmoid 
 Parameters 
 inplace 
 Return type 
 Tensor 
 See  Hardsigmoid  for more details.",,,,
"
 torch.nn.functional. silu ( input ,  inplace ) [source] ¶","Applies the Sigmoid Linear Unit (SiLU) function, element-wise.
The SiLU function is also known as the swish function. 
 silu 
 Note 
 See  
 See  SiLU  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. mish ( input ,  inplace ) [source] ¶","Applies the Mish function, element-wise.
Mish: A Self Regularized Non-Monotonic Neural Activation Function. 
 Mish 
 Note 
 See  
 See  Mish  for more details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. batch_norm ( input ,  running_mean ,  running_var ,  weight ,  bias ,  training ,  momentum ,  eps ) [source] ¶","Applies Batch Normalization for each channel across a batch of data. See  BatchNorm1d ,  BatchNorm2d ,
 BatchNorm3d  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. group_norm ( input ,  num_groups ,  weight ,  bias ,  eps ) [source] ¶","Applies Group Normalization for last certain number of dimensions. See  GroupNorm  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. instance_norm ( input ,  running_mean ,  running_var ,  weight ,  bias ,  use_input_stats ,  momentum ,  eps ) [source] ¶","Applies Instance Normalization for each channel in each data sample in a
batch. See  InstanceNorm1d ,  InstanceNorm2d ,
 InstanceNorm3d  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. layer_norm ( input ,  normalized_shape ,  weight ,  bias ,  eps ) [source] ¶","Applies Layer Normalization for last certain number of dimensions. See  LayerNorm  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. local_response_norm ( input ,  size ,  alpha ,  beta ,  k ) [source] ¶","Applies local response normalization over an input signal composed of
several input planes, where channels occupy the second dimension.
Applies normalization across channels. See  LocalResponseNorm  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. normalize ( input ,  p ,  dim ,  eps ,  out ) [source] ¶","Performs  L  normalization of inputs over specified dimension. For a tensor  input  of sizes  ( , each
 n  -element vector  v  along dimension  dim  is transformed as 
 v With the default arguments it uses the Euclidean norm over vectors along dimension  1  for normalization. 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. linear ( input ,  weight ,  bias )   → ¶","Applies a linear transformation to the incoming data:  y . This opperation supports 2-D  weight  with  sparse layout 
 Warning 
 Sparse support is a beta feature and some layout(s)/dtype/device combinations may not be supported,
or may not have autograd support. If you notice missing functionality please
open a feature request. 
 This operator supports  TensorFloat32 . Shape: 
 
",,,,
"
 torch.nn.functional. bilinear ( input1 ,  input2 ,  weight ,  bias )   → ¶","Applies a bilinear transformation to the incoming data:
 y Shape: 
 
",,,,
"
 torch.nn.functional. dropout ( input ,  p ,  training ,  inplace ) [source] ¶","During training, randomly zeroes some of the elements of the input
tensor with probability  p  using samples from a Bernoulli
distribution. See  Dropout  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. alpha_dropout ( input ,  p ,  training ,  inplace ) [source] ¶","Applies alpha dropout to the input. See  AlphaDropout  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. feature_alpha_dropout ( input ,  p ,  training ,  inplace ) [source] ¶","Randomly masks out entire channels (a channel is a feature map,
e.g. the  j -th channel of the  i -th sample in the batch input
is a tensor  input ) of the input tensor). Instead of
setting activations to zero, as in regular Dropout, the activations are set
to the negative saturation value of the SELU activation function. Each element will be masked independently on every forward call with
probability  p  using samples from a Bernoulli distribution.
The elements to be masked are randomized on every forward call, and scaled
and shifted to maintain zero mean and unit variance. See  FeatureAlphaDropout  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. dropout1d ( input ,  p ,  training ,  inplace ) [source] ¶","Randomly zero out entire channels (a channel is a 1D feature map,
e.g., the  j -th channel of the  i -th sample in the
batched input is a 1D tensor  input ) of the input tensor).
Each channel will be zeroed out independently on every forward call with
probability  p  using samples from a Bernoulli distribution. See  Dropout1d  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. dropout2d ( input ,  p ,  training ,  inplace ) [source] ¶","Randomly zero out entire channels (a channel is a 2D feature map,
e.g., the  j -th channel of the  i -th sample in the
batched input is a 2D tensor  input ) of the input tensor).
Each channel will be zeroed out independently on every forward call with
probability  p  using samples from a Bernoulli distribution. See  Dropout2d  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. dropout3d ( input ,  p ,  training ,  inplace ) [source] ¶","Randomly zero out entire channels (a channel is a 3D feature map,
e.g., the  j -th channel of the  i -th sample in the
batched input is a 3D tensor  input ) of the input tensor).
Each channel will be zeroed out independently on every forward call with
probability  p  using samples from a Bernoulli distribution. See  Dropout3d  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. embedding ( input ,  weight ,  padding_idx ,  max_norm ,  norm_type ,  scale_grad_by_freq ,  sparse ) [source] ¶","A simple lookup table that looks up embeddings in a fixed dictionary and size. This module is often used to retrieve word embeddings using indices.
The input to the module is a list of indices, and the embedding matrix,
and the output is the corresponding word embeddings. See  torch.nn.Embedding  for more details. 
 Parameters 
 
 
 Return type 
 Tensor 
 
 Shape: 
 
 Examples: 
",">>> # a batch of 2 samples of 4 indices each
>>> input=torch.tensor([[1,2,4,5],[4,3,2,9]])
>>> # an embedding matrix containing 10 tensors of size 3
>>> embedding_matrix=torch.rand(10,3)
>>> F.embedding(input,embedding_matrix)
tensor([[[ 0.8490,  0.9625,  0.6753],
         [ 0.9666,  0.7761,  0.6108],
         [ 0.6246,  0.9751,  0.3618],
         [ 0.4161,  0.2419,  0.7383]],        [[ 0.6246,  0.9751,  0.3618],
         [ 0.0237,  0.7794,  0.0528],
         [ 0.9666,  0.7761,  0.6108],
         [ 0.3385,  0.8612,  0.1867]]])>>> # example with padding_idx
>>> weights=torch.rand(10,3)
>>> weights[0,:].zero_()
>>> embedding_matrix=weights
>>> input=torch.tensor([[0,2,0,5]])
>>> F.embedding(input,embedding_matrix,padding_idx=0)
tensor([[[ 0.0000,  0.0000,  0.0000],
         [ 0.5609,  0.5384,  0.8720],
         [ 0.0000,  0.0000,  0.0000],
         [ 0.6262,  0.2438,  0.7471]]])
",,,
"
 torch.nn.functional. embedding_bag ( input ,  weight ,  offsets ,  max_norm ,  norm_type ,  scale_grad_by_freq ,  mode ,  sparse ,  per_sample_weights ,  include_last_offset ,  padding_idx ) [source] ¶","Computes sums, means or maxes of  bags  of embeddings, without instantiating the
intermediate embeddings. See  torch.nn.EmbeddingBag  for more details. 
 Note 
 This operation may produce nondeterministic gradients when given tensors on a CUDA device. See  
 
 Parameters 
 
 
 Return type 
 Tensor 
 
 Shape: 
 
 Examples: 
",">>> # an Embedding module containing 10 tensors of size 3
>>> embedding_matrix=torch.rand(10,3)
>>> # a batch of 2 samples of 4 indices each
>>> input=torch.tensor([1,2,4,5,4,3,2,9])
>>> offsets=torch.tensor([0,4])
>>> F.embedding_bag(input,embedding_matrix,offsets)
tensor([[ 0.3397,  0.3552,  0.5545],
        [ 0.5893,  0.4386,  0.5882]])>>> # example with padding_idx
>>> embedding_matrix=torch.rand(10,3)
>>> input=torch.tensor([2,2,2,2,4,3,2,9])
>>> offsets=torch.tensor([0,4])
>>> F.embedding_bag(input,embedding_matrix,offsets,padding_idx=2,mode='sum')
tensor([[ 0.0000,  0.0000,  0.0000],
        [-0.7082,  3.2145, -2.6251]])
",,,
"
 torch.nn.functional. one_hot ( tensor ,  num_classes )   → ¶","Takes LongTensor with index values of shape  (*)  and returns a tensor
of shape  (*,  that have zeros everywhere except where the
index of last dimension matches the corresponding value of the input tensor,
in which case it will be 1. See also  One-hot on Wikipedia  . 
 Parameters 
 
 
 Returns 
 LongTensor that has one more dimension with 1 values at the
index of last dimension indicated by the input, and 0 everywhere
else. 
 Examples 
",,,,
"
 torch.nn.functional. pairwise_distance ( x1 ,  x2 ,  p ,  eps ,  keepdim )   → ¶",See  torch.nn.PairwiseDistance  for details,,,,
"
 torch.nn.functional. cosine_similarity ( x1 ,  x2 ,  dim ,  eps )   → ¶","Returns cosine similarity between  x1  and  x2 , computed along dim.  x1  and  x2  must be broadcastable
to a common shape.  dim  refers to the dimension in this common shape. Dimension  dim  of the output is
squeezed (see  torch.squeeze() ), resulting in the
output tensor having 1 fewer dimension. 
 similarity Supports  type promotion . 
 Parameters 
 
 
 Example: 
",">>> input1=torch.randn(100,128)
>>> input2=torch.randn(100,128)
>>> output=F.cosine_similarity(input1,input2)
>>> print(output)
",,,
"
 torch.nn.functional. pdist ( input ,  p )   → ¶","Computes the p-norm distance between every pair of row vectors in the input.
This is identical to the upper triangular portion, excluding the diagonal, of
 torch.norm(input[:, None] - input, dim=2, p=p) . This function will be faster
if the rows are contiguous. If input has shape  N  then the output will have shape
 1 . This function is equivalent to  scipy.spatial.distance.pdist(input,  if  p . When  p  it is
equivalent to  scipy.spatial.distance.pdist(input, .
When  p , the closest scipy function is
 scipy.spatial.distance.pdist(xn, . 
 Parameters 
 
 
",,,,
"
 torch.nn.functional. binary_cross_entropy ( input ,  target ,  weight ,  size_average ,  reduce ,  reduction ) [source] ¶","Function that measures the Binary Cross Entropy between the target and input
probabilities. See  BCELoss  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
 Examples: 
",">>> input=torch.randn(3,2,requires_grad=True)
>>> target=torch.rand(3,2,requires_grad=False)
>>> loss=F.binary_cross_entropy(torch.sigmoid(input),target)
>>> loss.backward()
",,,
"
 torch.nn.functional. binary_cross_entropy_with_logits ( input ,  target ,  weight ,  size_average ,  reduce ,  reduction ,  pos_weight ) [source] ¶","Function that measures Binary Cross Entropy between target and input
logits. See  BCEWithLogitsLoss  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
 Examples: 
",">>> input=torch.randn(3,requires_grad=True)
>>> target=torch.empty(3).random_(2)
>>> loss=F.binary_cross_entropy_with_logits(input,target)
>>> loss.backward()
",,,
"
 torch.nn.functional. poisson_nll_loss ( input ,  target ,  log_input ,  full ,  size_average ,  eps ,  reduce ,  reduction ) [source] ¶","Poisson negative log likelihood loss. See  PoissonNLLLoss  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. cosine_embedding_loss ( input1 ,  input2 ,  target ,  margin ,  size_average ,  reduce ,  reduction )   → [source] ¶","See  CosineEmbeddingLoss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. cross_entropy ( input ,  target ,  weight ,  size_average ,  ignore_index ,  reduce ,  reduction ,  label_smoothing ) [source] ¶","This criterion computes the cross entropy loss between input logits and target. See  CrossEntropyLoss  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
 
 Shape: 
 
 Examples: 
",">>> # Example of target with class indices
>>> input=torch.randn(3,5,requires_grad=True)
>>> target=torch.randint(5,(3,),dtype=torch.int64)
>>> loss=F.cross_entropy(input,target)
>>> loss.backward()
>>>
>>> # Example of target with class probabilities
>>> input=torch.randn(3,5,requires_grad=True)
>>> target=torch.randn(3,5).softmax(dim=1)
>>> loss=F.cross_entropy(input,target)
>>> loss.backward()
",,,
"
 torch.nn.functional. ctc_loss ( log_probs ,  targets ,  input_lengths ,  target_lengths ,  blank ,  reduction ,  zero_infinity ) [source] ¶","The Connectionist Temporal Classification loss. See  CTCLoss  for details. 
 Note 
 In some circumstances when given tensors on a CUDA device and using CuDNN, this operator may select a nondeterministic algorithm to increase performance. If this is undesirable, you can try to make the operation deterministic (potentially at a performance cost) by setting  
 
 Note 
 This operation may produce nondeterministic gradients when given tensors on a CUDA device. See  
 
 Parameters 
 
 
 Return type 
 Tensor 
 Example: 
",">>> log_probs=torch.randn(50,16,20).log_softmax(2).detach().requires_grad_()
>>> targets=torch.randint(1,20,(16,30),dtype=torch.long)
>>> input_lengths=torch.full((16,),50,dtype=torch.long)
>>> target_lengths=torch.randint(10,30,(16,),dtype=torch.long)
>>> loss=F.ctc_loss(log_probs,targets,input_lengths,target_lengths)
>>> loss.backward()
",,,
"
 torch.nn.functional. gaussian_nll_loss ( input ,  target ,  var ,  full ,  eps ,  reduction ) [source] ¶","Gaussian negative log likelihood loss. See  GaussianNLLLoss  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. hinge_embedding_loss ( input ,  target ,  margin ,  size_average ,  reduce ,  reduction )   → [source] ¶","See  HingeEmbeddingLoss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. kl_div ( input ,  target ,  size_average ,  reduce ,  reduction ,  log_target ) [source] ¶","The  Kullback-Leibler divergence Loss See  KLDivLoss  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
 
 Note 
 size_average 
 
 Note 
 reduction 
",,,,
"
 torch.nn.functional. l1_loss ( input ,  target ,  size_average ,  reduce ,  reduction )   → [source] ¶","Function that takes the mean element-wise absolute value difference. See  L1Loss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. mse_loss ( input ,  target ,  size_average ,  reduce ,  reduction )   → [source] ¶","Measures the element-wise mean squared error. See  MSELoss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. margin_ranking_loss ( input1 ,  input2 ,  target ,  margin ,  size_average ,  reduce ,  reduction )   → [source] ¶","See  MarginRankingLoss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. multilabel_margin_loss ( input ,  target ,  size_average ,  reduce ,  reduction )   → [source] ¶","See  MultiLabelMarginLoss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. multilabel_soft_margin_loss ( input ,  target ,  weight ,  size_average ,  reduce ,  reduction )   → [source] ¶","See  MultiLabelSoftMarginLoss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. multi_margin_loss ( input ,  target ,  p ,  margin ,  weight ,  size_average ,  reduce ,  reduction )   → [source] ¶","See  MultiMarginLoss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. nll_loss ( input ,  target ,  weight ,  size_average ,  ignore_index ,  reduce ,  reduction ) [source] ¶","The negative log likelihood loss. See  NLLLoss  for details. 
 Parameters 
 
 
 Return type 
 Tensor 
 Example: 
",">>> # input is of size N x C = 3 x 5
>>> input=torch.randn(3,5,requires_grad=True)
>>> # each element in target has to have 0 <= value < C
>>> target=torch.tensor([1,0,4])
>>> output=F.nll_loss(F.log_softmax(input,dim=1),target)
>>> output.backward()
",,,
"
 torch.nn.functional. huber_loss ( input ,  target ,  reduction ,  delta ) [source] ¶","Function that uses a squared term if the absolute
element-wise error falls below delta and a delta-scaled L1 term otherwise. See  HuberLoss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. smooth_l1_loss ( input ,  target ,  size_average ,  reduce ,  reduction ,  beta ) [source] ¶","Function that uses a squared term if the absolute
element-wise error falls below beta and an L1 term otherwise. See  SmoothL1Loss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. soft_margin_loss ( input ,  target ,  size_average ,  reduce ,  reduction )   → [source] ¶","See  SoftMarginLoss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. triplet_margin_loss ( anchor ,  positive ,  negative ,  margin ,  p ,  eps ,  swap ,  size_average ,  reduce ,  reduction ) [source] ¶","See  TripletMarginLoss  for details 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. triplet_margin_with_distance_loss ( anchor ,  positive ,  negative ,  * ,  distance_function ,  margin ,  swap ,  reduction ) [source] ¶","See  TripletMarginWithDistanceLoss  for details. 
 Return type 
 Tensor 
",,,,
"
 torch.nn.functional. pixel_shuffle ( input ,  upscale_factor )   → ¶","Rearranges elements in a tensor of shape  (  to a
tensor of shape  ( , where r is the  upscale_factor . See  PixelShuffle  for details. 
 Parameters 
 
 
 Examples: 
",">>> input=torch.randn(1,9,4,4)
>>> output=torch.nn.functional.pixel_shuffle(input,3)
>>> print(output.size())
torch.Size([1, 1, 12, 12])
",,,
"
 torch.nn.functional. pixel_unshuffle ( input ,  downscale_factor )   → ¶","Reverses the  PixelShuffle  operation by rearranging elements in a
tensor of shape  (  to a tensor of shape
 ( , where r is the  downscale_factor . See  PixelUnshuffle  for details. 
 Parameters 
 
 
 Examples: 
",">>> input=torch.randn(1,1,12,12)
>>> output=torch.nn.functional.pixel_unshuffle(input,3)
>>> print(output.size())
torch.Size([1, 9, 4, 4])
",,,
"
 torch.nn.functional. pad ( input ,  pad ,  mode ,  value )   → ¶","Pads tensor. 
 Padding size: The padding size by which to pad some dimensions of  
 Padding mode: See  
 
 Note 
 When using the CUDA backend, this operation may induce nondeterministic
behaviour in its backward pass that is not easily switched off.
Please see the notes on  
 
 Parameters 
 
 
 Examples: 
",">>> t4d=torch.empty(3,3,4,2)
>>> p1d=(1,1)# pad last dim by 1 on each side
>>> out=F.pad(t4d,p1d,""constant"",0)# effectively zero padding
>>> print(out.size())
torch.Size([3, 3, 4, 4])
>>> p2d=(1,1,2,2)# pad last dim by (1, 1) and 2nd to last by (2, 2)
>>> out=F.pad(t4d,p2d,""constant"",0)
>>> print(out.size())
torch.Size([3, 3, 8, 4])
>>> t4d=torch.empty(3,3,4,2)
>>> p3d=(0,1,2,1,3,3)# pad by (0, 1), (2, 1), and (3, 3)
>>> out=F.pad(t4d,p3d,""constant"",0)
>>> print(out.size())
torch.Size([3, 9, 7, 3])
",,,
"
 torch.nn.functional. interpolate ( input ,  size ,  scale_factor ,  mode ,  align_corners ,  recompute_scale_factor ,  antialias ) [source] ¶","Down/up samples the input to either the given  size  or the given
 scale_factor The algorithm used for interpolation is determined by  mode . Currently temporal, spatial and volumetric sampling are supported, i.e.
expected inputs are 3-D, 4-D or 5-D in shape. The input dimensions are interpreted in the form:
 mini-batch x channels x [optional depth] x [optional height] x width . The modes available for resizing are:  nearest ,  linear  (3D-only),
 bilinear ,  bicubic  (4D-only),  trilinear  (5D-only),  area ,  nearest-exact 
 Parameters 
 
 
 Return type 
 Tensor 
 
 Note 
 With  
 
 Note 
 Mode  
 
 Note 
 This operation may produce nondeterministic gradients when given tensors on a CUDA device. See  
",,,,
"
 torch.nn.functional. upsample ( input ,  size ,  scale_factor ,  mode ,  align_corners ) [source] ¶","Upsamples the input to either the given  size  or the given
 scale_factor 
 Warning 
 This function is deprecated in favor of  
 
 Note 
 This operation may produce nondeterministic gradients when given tensors on a CUDA device. See  
 The algorithm used for upsampling is determined by  mode . Currently temporal, spatial and volumetric upsampling are supported, i.e.
expected inputs are 3-D, 4-D or 5-D in shape. The input dimensions are interpreted in the form:
 mini-batch x channels x [optional depth] x [optional height] x width . The modes available for upsampling are:  nearest ,  linear  (3D-only),
 bilinear ,  bicubic  (4D-only),  trilinear  (5D-only) 
 Parameters 
 
 
 
 Note 
 With  
 
 Warning 
 With  
",,,,
"
 torch.nn.functional. upsample_nearest ( input ,  size ,  scale_factor ) [source] ¶","Upsamples the input, using nearest neighbours’ pixel values. 
 Warning 
 This function is deprecated in favor of  
 Currently spatial and volumetric upsampling are supported (i.e. expected
inputs are 4 or 5 dimensional). 
 Parameters 
 
 
 
 Note 
 This operation may produce nondeterministic gradients when given tensors on a CUDA device. See  
",,,,
"
 torch.nn.functional. upsample_bilinear ( input ,  size ,  scale_factor ) [source] ¶","Upsamples the input, using bilinear upsampling. 
 Warning 
 This function is deprecated in favor of  
 Expected inputs are spatial (4 dimensional). Use  upsample_trilinear  fo
volumetric (5 dimensional) inputs. 
 Parameters 
 
 
 
 Note 
 This operation may produce nondeterministic gradients when given tensors on a CUDA device. See  
",,,,
"
 torch.nn.functional. grid_sample ( input ,  grid ,  mode ,  padding_mode ,  align_corners ) [source] ¶","Given an  input  and a flow-field  grid , computes the
 output  using  input  values and pixel locations from  grid . Currently, only spatial (4-D) and volumetric (5-D)  input  are
supported. In the spatial (4-D) case, for  input  with shape
 (  and  grid  with shape
 ( , the output will have shape
 ( . For each output location  output[n, , the size-2 vector
 grid[n,  specifies  input  pixel locations  x  and  y ,
which are used to interpolate the output value  output[n, .
In the case of 5D inputs,  grid[n,  specifies the
 x ,  y ,  z  pixel locations for interpolating
 output[n, .  mode  argument specifies  nearest  or
 bilinear  interpolation method to sample the input pixels. grid  specifies the sampling pixel locations normalized by the
 input  spatial dimensions. Therefore, it should have most values in
the range of  [-1, . For example, values  x  is the
left-top pixel of  input , and values   x  is the
right-bottom pixel of  input . If  grid  has values outside the range of  [-1, , the corresponding
outputs are handled as defined by  padding_mode . Options are 
 
 
 Note 
 This function is often used in conjunction with  
 
 Note 
 When using the CUDA backend, this operation may induce nondeterministic
behaviour in its backward pass that is not easily switched off.
Please see the notes on  
 
 Note 
 NaN values in  
 
 Parameters 
 
 
 Returns 
 output Tensor 
 Return type 
 output ( 
 
 Warning 
 When  
 
 Note 
 mode='bicubic' 
",,,,
"
 torch.nn.functional. affine_grid ( theta ,  size ,  align_corners ) [source] ¶","Generates a 2D or 3D flow field (sampling grid), given a batch of
affine matrices  theta . 
 Note 
 This function is often used in conjunction with  
 
 Parameters 
 
 
 Returns 
 output Tensor of size ( 
 Return type 
 output ( 
 
 Warning 
 When  
 
 Warning 
 When  
",,,,
"
 Tensor. new_tensor ( data ,  * ,  dtype ,  device ,  requires_grad ,  layout ,  pin_memory )   → ¶","Returns a new Tensor with  data  as the tensor data.
By default, the returned Tensor has the same  torch.dtype  and
 torch.device  as this tensor. 
 Warning 
 new_tensor() 
 
 Warning 
 When data is a tensor  
 
 Parameters 
 data 
 Keyword Arguments 
 
 
 Example: 
",">>> tensor=torch.ones((2,),dtype=torch.int8)
>>> data=[[0,1],[2,3]]
>>> tensor.new_tensor(data)
tensor([[ 0,  1],
        [ 2,  3]], dtype=torch.int8)
",,,
"
 torch.nn.parallel. data_parallel ( module ,  inputs ,  device_ids ,  output_device ,  dim ,  module_kwargs ) [source] ¶","Evaluates module(input) in parallel across the GPUs given in device_ids. This is the functional version of the DataParallel module. 
 Parameters 
 
 
 Returns 
 a Tensor containing the result of module(input) located on
output_device 
",,,,
"
 Tensor. requires_grad_ ( requires_grad )   → ¶","Change if autograd should record operations on this tensor: sets this tensor’s
 requires_grad  attribute in-place. Returns this tensor. requires_grad_() ’s main use case is to tell autograd to begin recording
operations on a Tensor  tensor . If  tensor  has  requires_grad=False 
(because it was obtained through a DataLoader, or required preprocessing or
initialization),  tensor.requires_grad_()  makes it so that autograd will
begin to record operations on  tensor . 
 Parameters 
 requires_grad 
 Example: 
",">>> # Let's say we want to preprocess some saved weights and use
>>> # the result as new weights.
>>> saved_weights=[0.1,0.2,0.3,0.25]
>>> loaded_weights=torch.tensor(saved_weights)
>>> weights=preprocess(loaded_weights)# some function
>>> weights
tensor([-0.5503,  0.4926, -2.1158, -0.8303])>>> # Now, start to record operations done to weights
>>> weights.requires_grad_()
>>> out=weights.pow(2).sum()
>>> out.backward()
>>> weights.grad
tensor([-1.1007,  0.9853, -4.2316, -1.6606])
",,,
"
 Tensor. detach ( ) ¶","Returns a new Tensor, detached from the current graph. The result will never require gradient. This method also affects forward mode AD gradients and the result will never
have forward mode AD gradients. 
 Note 
 Returned Tensor shares the same storage with the original one.
In-place modifications on either of them will be seen, and may trigger
errors in correctness checks.
IMPORTANT NOTE: Previously, in-place size / stride / storage changes
(such as  
",,,,
"
 Tensor. item ( )   → ¶","Returns the value of this tensor as a standard Python number. This only works
for tensors with one element. For other cases, see  tolist() . This operation is not differentiable. Example: 
",">>> x=torch.tensor([1.0])
>>> x.item()
1.0
",,,
"
 Tensor. to ( * ,  ** )   → ¶","Performs Tensor dtype and/or device conversion. A  torch.dtype  and  torch.device  are
inferred from the arguments of  self.to(*args, . 
 Note 
 If the  
 Here are the ways to call  to : 
 
 
 
 
 
 
 
 
 
 
 
 Example: 
",">>> tensor=torch.randn(2,2)# Initially dtype=float32, device=cpu
>>> tensor.to(torch.float64)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64)>>> cuda0=torch.device('cuda:0')
>>> tensor.to(cuda0)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], device='cuda:0')>>> tensor.to(cuda0,dtype=torch.float64)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')>>> other=torch.randn((),dtype=torch.float64,device=cuda0)
>>> tensor.to(other,non_blocking=True)
tensor([[-0.5044,  0.0005],
        [ 0.3310, -0.0584]], dtype=torch.float64, device='cuda:0')
",,,
"
 Tensor. new_full ( size ,  fill_value ,  * ,  dtype ,  device ,  requires_grad ,  layout ,  pin_memory )   → ¶","Returns a Tensor of size  size  filled with  fill_value .
By default, the returned Tensor has the same  torch.dtype  and
 torch.device  as this tensor. 
 Parameters 
 fill_value 
 Keyword Arguments 
 
 
 Example: 
",">>> tensor=torch.ones((2,),dtype=torch.float64)
>>> tensor.new_full((3,4),3.141592)
tensor([[ 3.1416,  3.1416,  3.1416,  3.1416],
        [ 3.1416,  3.1416,  3.1416,  3.1416],
        [ 3.1416,  3.1416,  3.1416,  3.1416]], dtype=torch.float64)
",,,
"
 Tensor. new_empty ( size ,  * ,  dtype ,  device ,  requires_grad ,  layout ,  pin_memory )   → ¶","Returns a Tensor of size  size  filled with uninitialized data.
By default, the returned Tensor has the same  torch.dtype  and
 torch.device  as this tensor. 
 Parameters 
 size 
 Keyword Arguments 
 
 
 Example: 
",">>> tensor=torch.ones(())
>>> tensor.new_empty((2,3))
tensor([[ 5.8182e-18,  4.5765e-41, -1.0545e+30],
        [ 3.0949e-41,  4.4842e-44,  0.0000e+00]])
",,,
"
 Tensor. new_ones ( size ,  * ,  dtype ,  device ,  requires_grad ,  layout ,  pin_memory )   → ¶","Returns a Tensor of size  size  filled with  1 .
By default, the returned Tensor has the same  torch.dtype  and
 torch.device  as this tensor. 
 Parameters 
 size 
 Keyword Arguments 
 
 
 Example: 
",">>> tensor=torch.tensor((),dtype=torch.int32)
>>> tensor.new_ones((2,3))
tensor([[ 1,  1,  1],
        [ 1,  1,  1]], dtype=torch.int32)
",,,
"
 Tensor. new_zeros ( size ,  * ,  dtype ,  device ,  requires_grad ,  layout ,  pin_memory )   → ¶","Returns a Tensor of size  size  filled with  0 .
By default, the returned Tensor has the same  torch.dtype  and
 torch.device  as this tensor. 
 Parameters 
 size 
 Keyword Arguments 
 
 
 Example: 
",">>> tensor=torch.tensor((),dtype=torch.float64)
>>> tensor.new_zeros((2,3))
tensor([[ 0.,  0.,  0.],
        [ 0.,  0.,  0.]], dtype=torch.float64)
",,,
"
 Tensor. is_cuda ¶","Is  True  if the Tensor is stored on the GPU,  False  otherwise.",,,,
"
 Tensor. is_quantized ¶","Is  True  if the Tensor is quantized,  False  otherwise.",,,,
"
 Tensor. is_meta ¶","Is  True  if the Tensor is a meta tensor,  False  otherwise.  Meta tensors
are like normal tensors, but they carry no data.",,,,
"
 Tensor. device ¶",Is the  torch.device  where this Tensor is.,,,,
"
 Tensor. grad ¶","This attribute is  None  by default and becomes a Tensor the first time a call to
 backward()  computes gradients for  self .
The attribute will then contain the gradients computed and future calls to
 backward()  will accumulate (add) gradients into it.",,,,
"
 Tensor. ndim ¶",Alias for  dim(),,,,
"
 Tensor. dim ( )   → ¶",Returns the number of dimensions of  self  tensor.,,,,
"
 Tensor. real ¶","Returns a new tensor containing real values of the  self  tensor for a complex-valued input tensor.
The returned tensor and  self  share the same underlying storage. Returns  self  if  self  is a real-valued tensor tensor. 
 Example:: 
",,,,
"
 Tensor. imag ¶","Returns a new tensor containing imaginary values of the  self  tensor.
The returned tensor and  self  share the same underlying storage. 
 Warning 
 imag() 
 
 Example:: 
",,,,
"
 Tensor. abs ( )   → ¶",See  torch.abs(),,,,
"
 Tensor. abs_ ( )   → ¶",In-place version of  abs(),,,,
"
 Tensor. absolute ( )   → ¶",Alias for  abs(),,,,
"
 Tensor. absolute_ ( )   → ¶","In-place version of  absolute() 
Alias for  abs_()",,,,
"
 Tensor. acos ( )   → ¶",See  torch.acos(),,,,
"
 Tensor. acos_ ( )   → ¶",In-place version of  acos(),,,,
"
 Tensor. arccos ( )   → ¶",See  torch.arccos(),,,,
"
 Tensor. arccos_ ( )   → ¶",In-place version of  arccos(),,,,
"
 Tensor. add ( other ,  * ,  alpha )   → ¶","Add a scalar or tensor to  self  tensor. If both  alpha 
and  other  are specified, each element of  other  is scaled by
 alpha  before being used. When  other  is a tensor, the shape of  other  must be
 broadcastable  with the shape of the underlying
tensor See  torch.add()",,,,
"
 Tensor. add_ ( other ,  * ,  alpha )   → ¶",In-place version of  add(),,,,
"
 Tensor. addbmm ( batch1 ,  batch2 ,  * ,  beta ,  alpha )   → ¶",See  torch.addbmm(),,,,
"
 Tensor. addbmm_ ( batch1 ,  batch2 ,  * ,  beta ,  alpha )   → ¶",In-place version of  addbmm(),,,,
"
 Tensor. addcdiv ( tensor1 ,  tensor2 ,  * ,  value )   → ¶",See  torch.addcdiv(),,,,
"
 Tensor. addcdiv_ ( tensor1 ,  tensor2 ,  * ,  value )   → ¶",In-place version of  addcdiv(),,,,
"
 Tensor. addcmul ( tensor1 ,  tensor2 ,  * ,  value )   → ¶",See  torch.addcmul(),,,,
"
 Tensor. addcmul_ ( tensor1 ,  tensor2 ,  * ,  value )   → ¶",In-place version of  addcmul(),,,,
"
 Tensor. addmm ( mat1 ,  mat2 ,  * ,  beta ,  alpha )   → ¶",See  torch.addmm(),,,,
"
 Tensor. addmm_ ( mat1 ,  mat2 ,  * ,  beta ,  alpha )   → ¶",In-place version of  addmm(),,,,
"
 Tensor. sspaddmm ( mat1 ,  mat2 ,  * ,  beta ,  alpha )   → ¶",See  torch.sspaddmm(),,,,
"
 torch. sspaddmm ( input ,  mat1 ,  mat2 ,  * ,  beta ,  alpha ,  out )   → ¶","Matrix multiplies a sparse tensor  mat1  with a dense tensor
 mat2 , then adds the sparse tensor  input  to the result. Note: This function is equivalent to  torch.addmm() , except
 input  and  mat1  are sparse. 
 Parameters 
 
 
 Keyword Arguments 
 
 
",,,,
"
 Tensor. addmv ( mat ,  vec ,  * ,  beta ,  alpha )   → ¶",See  torch.addmv(),,,,
"
 Tensor. addmv_ ( mat ,  vec ,  * ,  beta ,  alpha )   → ¶",In-place version of  addmv(),,,,
"
 Tensor. addr ( vec1 ,  vec2 ,  * ,  beta ,  alpha )   → ¶",See  torch.addr(),,,,
"
 Tensor. addr_ ( vec1 ,  vec2 ,  * ,  beta ,  alpha )   → ¶",In-place version of  addr(),,,,
"
 Tensor. adjoint ( )   → ¶",Alias for  adjoint(),,,,
"
 Tensor. allclose ( other ,  rtol ,  atol ,  equal_nan )   → ¶",See  torch.allclose(),,,,
"
 Tensor. amax ( dim ,  keepdim )   → ¶",See  torch.amax(),,,,
"
 Tensor. amin ( dim ,  keepdim )   → ¶",See  torch.amin(),,,,
"
 Tensor. aminmax ( * ,  dim=None ,  keepdim=False) ,  Tensor ) ¶",See  torch.aminmax(),,,,
"
 Tensor. angle ( )   → ¶",See  torch.angle(),,,,
"
 Tensor. apply_ ( callable )   → ¶","Applies the function  callable  to each element in the tensor, replacing
each element with the value returned by  callable . 
 Note 
 This function only works with CPU tensors and should not be used in code
sections that require high performance. 
",,,,
"
 Tensor. argmax ( dim ,  keepdim )   → ¶",See  torch.argmax(),,,,
"
 Tensor. argmin ( dim ,  keepdim )   → ¶",See  torch.argmin(),,,,
"
 Tensor. argsort ( dim ,  descending )   → ¶",See  torch.argsort(),,,,
"
 Tensor. argwhere ( )   → ¶",See  torch.argwhere(),,,,
"
 Tensor. asin ( )   → ¶",See  torch.asin(),,,,
"
 Tensor. asin_ ( )   → ¶",In-place version of  asin(),,,,
"
 Tensor. arcsin ( )   → ¶",See  torch.arcsin(),,,,
"
 Tensor. arcsin_ ( )   → ¶",In-place version of  arcsin(),,,,
"
 Tensor. as_strided ( size ,  stride ,  storage_offset )   → ¶",See  torch.as_strided(),,,,
"
 Tensor. atan ( )   → ¶",See  torch.atan(),,,,
"
 Tensor. atan_ ( )   → ¶",In-place version of  atan(),,,,
"
 Tensor. arctan ( )   → ¶",See  torch.arctan(),,,,
"
 Tensor. arctan_ ( )   → ¶",In-place version of  arctan(),,,,
"
 Tensor. atan2 ( other )   → ¶",See  torch.atan2(),,,,
"
 Tensor. atan2_ ( other )   → ¶",In-place version of  atan2(),,,,
"
 Tensor. arctan2 ( other )   → ¶",See  torch.arctan2(),,,,
"
 Tensor. arctan2_ ( ) ¶",atan2_(other) -> Tensor In-place version of  arctan2(),,,,
"
 Tensor. all ( dim ,  keepdim )   → ¶",See  torch.all(),,,,
"
 Tensor. any ( dim ,  keepdim )   → ¶",See  torch.any(),,,,
"
 Tensor. backward ( gradient ,  retain_graph ,  create_graph ,  inputs ) [source] ¶","Computes the gradient of current tensor w.r.t. graph leaves. The graph is differentiated using the chain rule. If the tensor is
non-scalar (i.e. its data has more than one element) and requires
gradient, the function additionally requires specifying  gradient .
It should be a tensor of matching type and location, that contains
the gradient of the differentiated function w.r.t.  self . This function accumulates gradients in the leaves - you might need to zero
 .grad  attributes or set them to  None  before calling it.
See  Default gradient layouts 
for details on the memory layout of accumulated gradients. 
 Note 
 If you run any forward ops, create  
 
 Note 
 When  
 
 Parameters 
 
 
",,,,
"
 Tensor. baddbmm ( batch1 ,  batch2 ,  * ,  beta ,  alpha )   → ¶",See  torch.baddbmm(),,,,
"
 Tensor. baddbmm_ ( batch1 ,  batch2 ,  * ,  beta ,  alpha )   → ¶",In-place version of  baddbmm(),,,,
"
 Tensor. bernoulli ( * ,  generator )   → ¶","Returns a result tensor where each  result[i]  is independently
sampled from  Bernoulli .  self  must have
floating point  dtype , and the result will have the same  dtype . See  torch.bernoulli()",,,,
"
 Tensor. bfloat16 ( memory_format )   → ¶","self.bfloat16()  is equivalent to  self.to(torch.bfloat16) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. bincount ( weights ,  minlength )   → ¶",See  torch.bincount(),,,,
"
 Tensor. bitwise_not ( )   → ¶",See  torch.bitwise_not(),,,,
"
 Tensor. bitwise_not_ ( )   → ¶",In-place version of  bitwise_not(),,,,
"
 Tensor. bitwise_and ( )   → ¶",See  torch.bitwise_and(),,,,
"
 Tensor. bitwise_and_ ( )   → ¶",In-place version of  bitwise_and(),,,,
"
 Tensor. bitwise_or ( )   → ¶",See  torch.bitwise_or(),,,,
"
 Tensor. bitwise_or_ ( )   → ¶",In-place version of  bitwise_or(),,,,
"
 Tensor. bitwise_xor ( )   → ¶",See  torch.bitwise_xor(),,,,
"
 Tensor. bitwise_xor_ ( )   → ¶",In-place version of  bitwise_xor(),,,,
"
 Tensor. bitwise_left_shift ( other )   → ¶",See  torch.bitwise_left_shift(),,,,
"
 Tensor. bitwise_left_shift_ ( other )   → ¶",In-place version of  bitwise_left_shift(),,,,
"
 Tensor. bitwise_right_shift ( other )   → ¶",See  torch.bitwise_right_shift(),,,,
"
 Tensor. bitwise_right_shift_ ( other )   → ¶",In-place version of  bitwise_right_shift(),,,,
"
 Tensor. bmm ( batch2 )   → ¶",See  torch.bmm(),,,,
"
 Tensor. bool ( memory_format )   → ¶","self.bool()  is equivalent to  self.to(torch.bool) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. byte ( memory_format )   → ¶","self.byte()  is equivalent to  self.to(torch.uint8) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. broadcast_to ( shape )   → ¶",See  torch.broadcast_to() .,,,,
"
 Tensor. ceil ( )   → ¶",See  torch.ceil(),,,,
"
 Tensor. ceil_ ( )   → ¶",In-place version of  ceil(),,,,
"
 Tensor. char ( memory_format )   → ¶","self.char()  is equivalent to  self.to(torch.int8) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. cholesky ( upper )   → ¶",See  torch.cholesky(),,,,
"
 Tensor. cholesky_inverse ( upper )   → ¶",See  torch.cholesky_inverse(),,,,
"
 Tensor. cholesky_solve ( input2 ,  upper )   → ¶",See  torch.cholesky_solve(),,,,
"
 Tensor. chunk ( chunks ,  dim )   → ¶",See  torch.chunk(),,,,
"
 Tensor. clamp ( min ,  max )   → ¶",See  torch.clamp(),,,,
"
 Tensor. clamp_ ( min ,  max )   → ¶",In-place version of  clamp(),,,,
"
 Tensor. clip ( min ,  max )   → ¶",Alias for  clamp() .,,,,
"
 Tensor. clip_ ( min ,  max )   → ¶",Alias for  clamp_() .,,,,
"
 Tensor. clone ( * ,  memory_format )   → ¶",See  torch.clone(),,,,
"
 Tensor. contiguous ( memory_format )   → ¶","Returns a contiguous in memory tensor containing the same data as  self  tensor. If
 self  tensor is already in the specified memory format, this function returns the
 self  tensor. 
 Parameters 
 memory_format 
",,,,
"
 Tensor. copy_ ( src ,  non_blocking )   → ¶","Copies the elements from  src  into  self  tensor and returns
 self . The  src  tensor must be  broadcastable 
with the  self  tensor. It may be of a different data type or reside on a
different device. 
 Parameters 
 
 
",,,,
"
 Tensor. conj ( )   → ¶",See  torch.conj(),,,,
"
 Tensor. conj_physical ( )   → ¶",See  torch.conj_physical(),,,,
"
 Tensor. conj_physical_ ( )   → ¶",In-place version of  conj_physical(),,,,
"
 Tensor. resolve_conj ( )   → ¶",See  torch.resolve_conj(),,,,
"
 Tensor. resolve_neg ( )   → ¶",See  torch.resolve_neg(),,,,
"
 Tensor. copysign ( other )   → ¶",See  torch.copysign(),,,,
"
 Tensor. copysign_ ( other )   → ¶",In-place version of  copysign(),,,,
"
 Tensor. cos ( )   → ¶",See  torch.cos(),,,,
"
 Tensor. cos_ ( )   → ¶",In-place version of  cos(),,,,
"
 Tensor. cosh ( )   → ¶",See  torch.cosh(),,,,
"
 Tensor. cosh_ ( )   → ¶",In-place version of  cosh(),,,,
"
 Tensor. corrcoef ( )   → ¶",See  torch.corrcoef(),,,,
"
 Tensor. count_nonzero ( dim )   → ¶",See  torch.count_nonzero(),,,,
"
 Tensor. cov ( * ,  correction ,  fweights ,  aweights )   → ¶",See  torch.cov(),,,,
"
 Tensor. acosh ( )   → ¶",See  torch.acosh(),,,,
"
 Tensor. acosh_ ( )   → ¶",In-place version of  acosh(),,,,
"
 Tensor. arccosh ( ) ¶",acosh() -> Tensor See  torch.arccosh(),,,,
"
 Tensor. arccosh_ ( ) ¶",acosh_() -> Tensor In-place version of  arccosh(),,,,
"
 Tensor. cpu ( memory_format )   → ¶","Returns a copy of this object in CPU memory. If this object is already in CPU memory and on the correct device,
then no copy is performed and the original object is returned. 
 Parameters 
 memory_format 
",,,,
"
 Tensor. cross ( other ,  dim )   → ¶",See  torch.cross(),,,,
"
 Tensor. cuda ( device ,  non_blocking ,  memory_format )   → ¶","Returns a copy of this object in CUDA memory. If this object is already in CUDA memory and on the correct device,
then no copy is performed and the original object is returned. 
 Parameters 
 
 
",,,,
"
 Tensor. logcumsumexp ( dim )   → ¶",See  torch.logcumsumexp(),,,,
"
 Tensor. cummax ( dim ) ¶",See  torch.cummax(),,,,
"
 Tensor. cummin ( dim ) ¶",See  torch.cummin(),,,,
"
 Tensor. cumprod ( dim ,  dtype )   → ¶",See  torch.cumprod(),,,,
"
 Tensor. cumprod_ ( dim ,  dtype )   → ¶",In-place version of  cumprod(),,,,
"
 Tensor. cumsum ( dim ,  dtype )   → ¶",See  torch.cumsum(),,,,
"
 Tensor. cumsum_ ( dim ,  dtype )   → ¶",In-place version of  cumsum(),,,,
"
 Tensor. chalf ( memory_format )   → ¶","self.chalf()  is equivalent to  self.to(torch.complex32) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. cfloat ( memory_format )   → ¶","self.cfloat()  is equivalent to  self.to(torch.complex64) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. cdouble ( memory_format )   → ¶","self.cdouble()  is equivalent to  self.to(torch.complex128) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. data_ptr ( )   → ¶",Returns the address of the first element of  self  tensor.,,,,
"
 Tensor. deg2rad ( )   → ¶",See  torch.deg2rad(),,,,
"
 Tensor. dequantize ( )   → ¶","Given a quantized Tensor, dequantize it and return the dequantized float Tensor.",,,,
"
 Tensor. det ( )   → ¶",See  torch.det(),,,,
"
 Tensor. dense_dim ( )   → ¶","Return the number of dense dimensions in a  sparse tensor   self . 
 Warning 
 Throws an error if  
 See also  Tensor.sparse_dim()  and  hybrid tensors .",,,,
"
 Tensor. detach_ ( ) ¶","Detaches the Tensor from the graph that created it, making it a leaf.
Views cannot be detached in-place. This method also affects forward mode AD gradients and the result will never
have forward mode AD gradients.",,,,
"
 Tensor. diag ( diagonal )   → ¶",See  torch.diag(),,,,
"
 Tensor. diag_embed ( offset ,  dim1 ,  dim2 )   → ¶",See  torch.diag_embed(),,,,
"
 Tensor. diagflat ( offset )   → ¶",See  torch.diagflat(),,,,
"
 Tensor. diagonal ( offset ,  dim1 ,  dim2 )   → ¶",See  torch.diagonal(),,,,
"
 Tensor. diagonal_scatter ( src ,  offset ,  dim1 ,  dim2 )   → ¶",See  torch.diagonal_scatter(),,,,
"
 Tensor. fill_diagonal_ ( fill_value ,  wrap )   → ¶","Fill the main diagonal of a tensor that has at least 2-dimensions.
When dims>2, all dimensions of input must be of equal length.
This function modifies the input tensor in-place, and returns the input tensor. 
 Parameters 
 
 
 Example: 
",">>> a=torch.zeros(3,3)
>>> a.fill_diagonal_(5)
tensor([[5., 0., 0.],
        [0., 5., 0.],
        [0., 0., 5.]])
>>> b=torch.zeros(7,3)
>>> b.fill_diagonal_(5)
tensor([[5., 0., 0.],
        [0., 5., 0.],
        [0., 0., 5.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
>>> c=torch.zeros(7,3)
>>> c.fill_diagonal_(5,wrap=True)
tensor([[5., 0., 0.],
        [0., 5., 0.],
        [0., 0., 5.],
        [0., 0., 0.],
        [5., 0., 0.],
        [0., 5., 0.],
        [0., 0., 5.]])
",,,
"
 Tensor. fmax ( other )   → ¶",See  torch.fmax(),,,,
"
 Tensor. fmin ( other )   → ¶",See  torch.fmin(),,,,
"
 Tensor. diff ( n ,  dim ,  prepend ,  append )   → ¶",See  torch.diff(),,,,
"
 Tensor. digamma ( )   → ¶",See  torch.digamma(),,,,
"
 Tensor. digamma_ ( )   → ¶",In-place version of  digamma(),,,,
"
 Tensor. dist ( other ,  p )   → ¶",See  torch.dist(),,,,
"
 Tensor. div ( value ,  * ,  rounding_mode )   → ¶",See  torch.div(),,,,
"
 Tensor. div_ ( value ,  * ,  rounding_mode )   → ¶",In-place version of  div(),,,,
"
 Tensor. divide ( value ,  * ,  rounding_mode )   → ¶",See  torch.divide(),,,,
"
 Tensor. divide_ ( value ,  * ,  rounding_mode )   → ¶",In-place version of  divide(),,,,
"
 Tensor. dot ( other )   → ¶",See  torch.dot(),,,,
"
 Tensor. double ( memory_format )   → ¶","self.double()  is equivalent to  self.to(torch.float64) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. dsplit ( split_size_or_sections )   → ¶",See  torch.dsplit(),,,,
"
 Tensor. element_size ( )   → ¶","Returns the size in bytes of an individual element. Example: 
",">>> torch.tensor([]).element_size()
4
>>> torch.tensor([],dtype=torch.uint8).element_size()
1
",,,
"
 Tensor. eq ( other )   → ¶",See  torch.eq(),,,,
"
 Tensor. eq_ ( other )   → ¶",In-place version of  eq(),,,,
"
 Tensor. equal ( other )   → ¶",See  torch.equal(),,,,
"
 Tensor. erf ( )   → ¶",See  torch.erf(),,,,
"
 Tensor. erf_ ( )   → ¶",In-place version of  erf(),,,,
"
 Tensor. erfc ( )   → ¶",See  torch.erfc(),,,,
"
 Tensor. erfc_ ( )   → ¶",In-place version of  erfc(),,,,
"
 Tensor. erfinv ( )   → ¶",See  torch.erfinv(),,,,
"
 Tensor. erfinv_ ( )   → ¶",In-place version of  erfinv(),,,,
"
 Tensor. exp ( )   → ¶",See  torch.exp(),,,,
"
 Tensor. exp_ ( )   → ¶",In-place version of  exp(),,,,
"
 Tensor. expm1 ( )   → ¶",See  torch.expm1(),,,,
"
 Tensor. expm1_ ( )   → ¶",In-place version of  expm1(),,,,
"
 Tensor. expand ( * )   → ¶","Returns a new view of the  self  tensor with singleton dimensions expanded
to a larger size. Passing -1 as the size for a dimension means not changing the size of
that dimension. Tensor can be also expanded to a larger number of dimensions, and the
new ones will be appended at the front. For the new dimensions, the
size cannot be set to -1. Expanding a tensor does not allocate new memory, but only creates a
new view on the existing tensor where a dimension of size one is
expanded to a larger size by setting the  stride  to 0. Any dimension
of size 1 can be expanded to an arbitrary value without allocating new
memory. 
 Parameters 
 *sizes 
 
 Warning 
 More than one element of an expanded tensor may refer to a single
memory location. As a result, in-place operations (especially ones that
are vectorized) may result in incorrect behavior. If you need to write
to the tensors, please clone them first. 
 Example: 
",">>> x=torch.tensor([[1],[2],[3]])
>>> x.size()
torch.Size([3, 1])
>>> x.expand(3,4)
tensor([[ 1,  1,  1,  1],
        [ 2,  2,  2,  2],
        [ 3,  3,  3,  3]])
>>> x.expand(-1,4)# -1 means not changing the size of that dimension
tensor([[ 1,  1,  1,  1],
        [ 2,  2,  2,  2],
        [ 3,  3,  3,  3]])
",,,
"
 Tensor. expand_as ( other )   → ¶","Expand this tensor to the same size as  other .
 self.expand_as(other)  is equivalent to  self.expand(other.size()) . Please see  expand()  for more information about  expand . 
 Parameters 
 other 
",,,,
"
 Tensor. fix ( )   → ¶",See  torch.fix() .,,,,
"
 Tensor. fix_ ( )   → ¶",In-place version of  fix(),,,,
"
 Tensor. fill_ ( value )   → ¶",Fills  self  tensor with the specified value.,,,,
"
 Tensor. flatten ( start_dim ,  end_dim )   → ¶",See  torch.flatten(),,,,
"
 Tensor. flip ( dims )   → ¶",See  torch.flip(),,,,
"
 Tensor. fliplr ( )   → ¶",See  torch.fliplr(),,,,
"
 Tensor. flipud ( )   → ¶",See  torch.flipud(),,,,
"
 Tensor. float ( memory_format )   → ¶","self.float()  is equivalent to  self.to(torch.float32) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. float_power ( exponent )   → ¶",See  torch.float_power(),,,,
"
 Tensor. float_power_ ( exponent )   → ¶",In-place version of  float_power(),,,,
"
 Tensor. floor ( )   → ¶",See  torch.floor(),,,,
"
 Tensor. floor_ ( )   → ¶",In-place version of  floor(),,,,
"
 Tensor. floor_divide ( value )   → ¶",See  torch.floor_divide(),,,,
"
 Tensor. floor_divide_ ( value )   → ¶",In-place version of  floor_divide(),,,,
"
 Tensor. fmod ( divisor )   → ¶",See  torch.fmod(),,,,
"
 Tensor. fmod_ ( divisor )   → ¶",In-place version of  fmod(),,,,
"
 Tensor. frac ( )   → ¶",See  torch.frac(),,,,
"
 Tensor. frac_ ( )   → ¶",In-place version of  frac(),,,,
"
 Tensor. frexp ( input) ,  Tensor ) ¶",See  torch.frexp(),,,,
"
 Tensor. gather ( dim ,  index )   → ¶",See  torch.gather(),,,,
"
 Tensor. gcd ( other )   → ¶",See  torch.gcd(),,,,
"
 Tensor. gcd_ ( other )   → ¶",In-place version of  gcd(),,,,
"
 Tensor. ge ( other )   → ¶",See  torch.ge() .,,,,
"
 Tensor. ge_ ( other )   → ¶",In-place version of  ge() .,,,,
"
 Tensor. greater_equal ( other )   → ¶",See  torch.greater_equal() .,,,,
"
 Tensor. greater_equal_ ( other )   → ¶",In-place version of  greater_equal() .,,,,
"
 Tensor. geqrf ( ) ¶",See  torch.geqrf(),,,,
"
 Tensor. ger ( vec2 )   → ¶",See  torch.ger(),,,,
"
 Tensor. get_device ( ) ) ¶","For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.
For CPU tensors, an error is thrown. Example: 
",">>> x=torch.randn(3,4,5,device='cuda:0')
>>> x.get_device()
0
>>> x.cpu().get_device()# RuntimeError: get_device is not implemented for type torch.FloatTensor
",,,
"
 Tensor. gt ( other )   → ¶",See  torch.gt() .,,,,
"
 Tensor. gt_ ( other )   → ¶",In-place version of  gt() .,,,,
"
 Tensor. greater ( other )   → ¶",See  torch.greater() .,,,,
"
 Tensor. greater_ ( other )   → ¶",In-place version of  greater() .,,,,
"
 Tensor. half ( memory_format )   → ¶","self.half()  is equivalent to  self.to(torch.float16) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. hardshrink ( lambd )   → ¶",See  torch.nn.functional.hardshrink(),,,,
"
 Tensor. heaviside ( values )   → ¶",See  torch.heaviside(),,,,
"
 Tensor. histc ( bins ,  min ,  max )   → ¶",See  torch.histc(),,,,
"
 Tensor. histogram ( input ,  bins ,  * ,  range ,  weight ,  density ) ¶",See  torch.histogram(),,,,
"
 Tensor. hsplit ( split_size_or_sections )   → ¶",See  torch.hsplit(),,,,
"
 Tensor. hypot ( other )   → ¶",See  torch.hypot(),,,,
"
 Tensor. hypot_ ( other )   → ¶",In-place version of  hypot(),,,,
"
 Tensor. i0 ( )   → ¶",See  torch.i0(),,,,
"
 Tensor. i0_ ( )   → ¶",In-place version of  i0(),,,,
"
 Tensor. igamma ( other )   → ¶",See  torch.igamma(),,,,
"
 Tensor. igamma_ ( other )   → ¶",In-place version of  igamma(),,,,
"
 Tensor. igammac ( other )   → ¶",See  torch.igammac(),,,,
"
 Tensor. igammac_ ( other )   → ¶",In-place version of  igammac(),,,,
"
 Tensor. index_add ( dim ,  index ,  source ,  * ,  alpha )   → ¶",Out-of-place version of  torch.Tensor.index_add_() .,,,,
"
 Tensor. index_copy_ ( dim ,  index ,  tensor )   → ¶","Copies the elements of  tensor  into the  self  tensor by selecting
the indices in the order given in  index . For example, if  dim 
and  index[i] , then the  i th row of  tensor  is copied to the
 j th row of  self . The  dim th dimension of  tensor  must have the same size as the
length of  index  (which must be a vector), and all other dimensions must
match  self , or an error will be raised. 
 Note 
 If  
 
 Parameters 
 
 
 Example: 
",">>> x=torch.zeros(5,3)
>>> t=torch.tensor([[1,2,3],[4,5,6],[7,8,9]],dtype=torch.float)
>>> index=torch.tensor([0,4,2])
>>> x.index_copy_(0,index,t)
tensor([[ 1.,  2.,  3.],
        [ 0.,  0.,  0.],
        [ 7.,  8.,  9.],
        [ 0.,  0.,  0.],
        [ 4.,  5.,  6.]])
",,,
"
 Tensor. index_copy ( dim ,  index ,  tensor2 )   → ¶",Out-of-place version of  torch.Tensor.index_copy_() .,,,,
"
 Tensor. index_fill_ ( dim ,  index ,  value )   → ¶","Fills the elements of the  self  tensor with value  value  by
selecting the indices in the order given in  index . 
 Parameters 
 
 
 
 Example:: 
",,,,
"
 Tensor. index_fill ( dim ,  index ,  value )   → ¶",Out-of-place version of  torch.Tensor.index_fill_() .,,,,
"
 Tensor. index_put_ ( indices ,  values ,  accumulate )   → ¶","Puts values from the tensor  values  into the tensor  self  using
the indices specified in  indices  (which is a tuple of Tensors). The
expression  tensor.index_put_(indices,  is equivalent to
 tensor[indices] . Returns  self . If  accumulate  is  True , the elements in  values  are added to
 self . If accumulate is  False , the behavior is undefined if indices
contain duplicate elements. 
 Parameters 
 
 
",,,,
"
 Tensor. index_put ( indices ,  values ,  accumulate )   → ¶",Out-place version of  index_put_() .,,,,
"
 Tensor. index_reduce ( ) ¶",,,,,
"
 Tensor. index_select ( dim ,  index )   → ¶",See  torch.index_select(),,,,
"
 Tensor. indices ( )   → ¶","Return the indices tensor of a  sparse COO tensor . 
 Warning 
 Throws an error if  
 See also  Tensor.values() . 
 Note 
 This method can only be called on a coalesced sparse tensor. See
 
",,,,
"
 Tensor. inner ( other )   → ¶",See  torch.inner() .,,,,
"
 Tensor. int ( memory_format )   → ¶","self.int()  is equivalent to  self.to(torch.int32) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. int_repr ( )   → ¶","Given a quantized Tensor,
 self.int_repr()  returns a CPU Tensor with uint8_t as data type that stores the
underlying uint8_t values of the given Tensor.",,,,
"
 Tensor. inverse ( )   → ¶",See  torch.inverse(),,,,
"
 Tensor. isclose ( other ,  rtol ,  atol ,  equal_nan )   → ¶",See  torch.isclose(),,,,
"
 Tensor. isfinite ( )   → ¶",See  torch.isfinite(),,,,
"
 Tensor. isinf ( )   → ¶",See  torch.isinf(),,,,
"
 Tensor. isposinf ( )   → ¶",See  torch.isposinf(),,,,
"
 Tensor. isneginf ( )   → ¶",See  torch.isneginf(),,,,
"
 Tensor. isnan ( )   → ¶",See  torch.isnan(),,,,
"
 Tensor. is_contiguous ( memory_format )   → ¶","Returns True if  self  tensor is contiguous in memory in the order specified
by memory format. 
 Parameters 
 memory_format 
",,,,
"
 Tensor. is_complex ( )   → ¶",Returns True if the data type of  self  is a complex data type.,,,,
"
 Tensor. is_conj ( )   → ¶",Returns True if the conjugate bit of  self  is set to true.,,,,
"
 Tensor. is_floating_point ( )   → ¶",Returns True if the data type of  self  is a floating point data type.,,,,
"
 Tensor. is_inference ( )   → ¶",See  torch.is_inference(),,,,
"
 Tensor. is_leaf ¶","All Tensors that have  requires_grad  which is  False  will be leaf Tensors by convention. For Tensors that have  requires_grad  which is  True , they will be leaf Tensors if they were
created by the user. This means that they are not the result of an operation and so
 grad_fn  is None. Only leaf Tensors will have their  grad  populated during a call to  backward() .
To get  grad  populated for non-leaf Tensors, you can use  retain_grad() . Example: 
",">>> a=torch.rand(10,requires_grad=True)
>>> a.is_leaf
True
>>> b=torch.rand(10,requires_grad=True).cuda()
>>> b.is_leaf
False
# b was created by the operation that cast a cpu Tensor into a cuda Tensor
>>> c=torch.rand(10,requires_grad=True)+2
>>> c.is_leaf
False
# c was created by the addition operation
>>> d=torch.rand(10).cuda()
>>> d.is_leaf
True
# d does not require gradients and so has no operation creating it (that is tracked by the autograd engine)
>>> e=torch.rand(10).cuda().requires_grad_()
>>> e.is_leaf
True
# e requires gradients and has no operations creating it
>>> f=torch.rand(10,requires_grad=True,device=""cuda"")
>>> f.is_leaf
True
# f requires grad, has no operation creating it
",,,
"
 Tensor. is_pinned ( ) ¶",Returns true if this tensor resides in pinned memory.,,,,
"
 Tensor. is_set_to ( tensor )   → ¶","Returns True if both tensors are pointing to the exact same memory (same
storage, offset, size and stride).",,,,
"
 Tensor. is_shared ( ) [source] ¶",Checks if tensor is in shared memory. This is always  True  for CUDA tensors.,,,,
"
 Tensor. is_signed ( )   → ¶",Returns True if the data type of  self  is a signed data type.,,,,
"
 Tensor. is_sparse ¶","Is  True  if the Tensor uses sparse storage layout,  False  otherwise.",,,,
"
 Tensor. istft ( n_fft ,  hop_length ,  win_length ,  window ,  center ,  normalized ,  onesided ,  length ,  return_complex ) [source] ¶","See  torch.istft() 
",,,,
"
 Tensor. isreal ( )   → ¶",See  torch.isreal(),,,,
"
 Tensor. kthvalue ( k ,  dim ,  keepdim ) ¶",See  torch.kthvalue(),,,,
"
 Tensor. lcm ( other )   → ¶",See  torch.lcm(),,,,
"
 Tensor. lcm_ ( other )   → ¶",In-place version of  lcm(),,,,
"
 Tensor. ldexp ( other )   → ¶",See  torch.ldexp(),,,,
"
 Tensor. ldexp_ ( other )   → ¶",In-place version of  ldexp(),,,,
"
 Tensor. le ( other )   → ¶",See  torch.le() .,,,,
"
 Tensor. le_ ( other )   → ¶",In-place version of  le() .,,,,
"
 Tensor. less_equal ( other )   → ¶",See  torch.less_equal() .,,,,
"
 Tensor. less_equal_ ( other )   → ¶",In-place version of  less_equal() .,,,,
"
 Tensor. lerp ( end ,  weight )   → ¶",See  torch.lerp(),,,,
"
 Tensor. lerp_ ( end ,  weight )   → ¶",In-place version of  lerp(),,,,
"
 Tensor. lgamma ( )   → ¶",See  torch.lgamma(),,,,
"
 Tensor. lgamma_ ( )   → ¶",In-place version of  lgamma(),,,,
"
 Tensor. log ( )   → ¶",See  torch.log(),,,,
"
 Tensor. log_ ( )   → ¶",In-place version of  log(),,,,
"
 Tensor. logdet ( )   → ¶",See  torch.logdet(),,,,
"
 Tensor. log10 ( )   → ¶",See  torch.log10(),,,,
"
 Tensor. log10_ ( )   → ¶",In-place version of  log10(),,,,
"
 Tensor. log1p ( )   → ¶",See  torch.log1p(),,,,
"
 Tensor. log1p_ ( )   → ¶",In-place version of  log1p(),,,,
"
 Tensor. log2 ( )   → ¶",See  torch.log2(),,,,
"
 Tensor. log2_ ( )   → ¶",In-place version of  log2(),,,,
"
 Tensor. logaddexp ( other )   → ¶",See  torch.logaddexp(),,,,
"
 Tensor. logaddexp2 ( other )   → ¶",See  torch.logaddexp2(),,,,
"
 Tensor. logsumexp ( dim ,  keepdim )   → ¶",See  torch.logsumexp(),,,,
"
 Tensor. logical_and ( )   → ¶",See  torch.logical_and(),,,,
"
 Tensor. logical_and_ ( )   → ¶",In-place version of  logical_and(),,,,
"
 Tensor. logical_not ( )   → ¶",See  torch.logical_not(),,,,
"
 Tensor. logical_not_ ( )   → ¶",In-place version of  logical_not(),,,,
"
 Tensor. logical_or ( )   → ¶",See  torch.logical_or(),,,,
"
 Tensor. logical_or_ ( )   → ¶",In-place version of  logical_or(),,,,
"
 Tensor. logical_xor ( )   → ¶",See  torch.logical_xor(),,,,
"
 Tensor. logical_xor_ ( )   → ¶",In-place version of  logical_xor(),,,,
"
 Tensor. logit ( )   → ¶",See  torch.logit(),,,,
"
 Tensor. logit_ ( )   → ¶",In-place version of  logit(),,,,
"
 Tensor. long ( memory_format )   → ¶","self.long()  is equivalent to  self.to(torch.int64) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. lt ( other )   → ¶",See  torch.lt() .,,,,
"
 Tensor. lt_ ( other )   → ¶",In-place version of  lt() .,,,,
"
 Tensor. less ( ) ¶",lt(other) -> Tensor See  torch.less() .,,,,
"
 Tensor. less_ ( other )   → ¶",In-place version of  less() .,,,,
"
 Tensor. lu ( pivot ,  get_infos ) [source] ¶",See  torch.lu(),,,,
"
 Tensor. lu_solve ( LU_data ,  LU_pivots )   → ¶",See  torch.lu_solve(),,,,
"
 Tensor. as_subclass ( cls )   → ¶","Makes a  cls  instance with the same data pointer as  self . Changes
in the output mirror changes in  self , and the output stays attached
to the autograd graph.  cls  must be a subclass of  Tensor .",,,,
"
 Tensor. map_ ( tensor ,  callable ) ¶","Applies  callable  for each element in  self  tensor and the given
 tensor  and stores the results in  self  tensor.  self  tensor and
the given  tensor  must be  broadcastable . The  callable  should have the signature: 
",,,,
"
 Tensor. masked_scatter_ ( mask ,  source ) ¶","Copies elements from  source  into  self  tensor at positions where
the  mask  is True.
The shape of  mask  must be  broadcastable 
with the shape of the underlying tensor. The  source  should have at least
as many elements as the number of ones in  mask 
 Parameters 
 
 
 
 Note 
 The  
",,,,
"
 Tensor. masked_scatter ( mask ,  tensor )   → ¶",Out-of-place version of  torch.Tensor.masked_scatter_(),,,,
"
 Tensor. masked_fill_ ( mask ,  value ) ¶","Fills elements of  self  tensor with  value  where  mask  is
True. The shape of  mask  must be
 broadcastable  with the shape of the underlying
tensor. 
 Parameters 
 
 
",,,,
"
 Tensor. masked_fill ( mask ,  value )   → ¶",Out-of-place version of  torch.Tensor.masked_fill_(),,,,
"
 Tensor. masked_select ( mask )   → ¶",See  torch.masked_select(),,,,
"
 Tensor. matmul ( tensor2 )   → ¶",See  torch.matmul(),,,,
"
 Tensor. matrix_power ( n )   → ¶","
 Note 
 matrix_power() 
 Alias for  torch.linalg.matrix_power()",,,,
"
 Tensor. matrix_exp ( )   → ¶",See  torch.matrix_exp(),,,,
"
 Tensor. max ( dim ,  keepdim ) ¶",See  torch.max(),,,,
"
 Tensor. maximum ( other )   → ¶",See  torch.maximum(),,,,
"
 Tensor. mean ( dim ,  keepdim ,  * ,  dtype )   → ¶",See  torch.mean(),,,,
"
 Tensor. nanmean ( dim ,  keepdim ,  * ,  dtype )   → ¶",See  torch.nanmean(),,,,
"
 Tensor. median ( dim ,  keepdim ) ¶",See  torch.median(),,,,
"
 Tensor. nanmedian ( dim ,  keepdim ) ¶",See  torch.nanmedian(),,,,
"
 Tensor. min ( dim ,  keepdim ) ¶",See  torch.min(),,,,
"
 Tensor. minimum ( other )   → ¶",See  torch.minimum(),,,,
"
 Tensor. mm ( mat2 )   → ¶",See  torch.mm(),,,,
"
 Tensor. smm ( mat )   → ¶",See  torch.smm(),,,,
"
 torch. smm ( input ,  mat )   → ¶","Performs a matrix multiplication of the sparse matrix  input 
with the dense matrix  mat . 
 Parameters 
 
 
",,,,
"
 Tensor. mode ( dim ,  keepdim ) ¶",See  torch.mode(),,,,
"
 Tensor. movedim ( source ,  destination )   → ¶",See  torch.movedim(),,,,
"
 Tensor. moveaxis ( source ,  destination )   → ¶",See  torch.moveaxis(),,,,
"
 Tensor. msort ( )   → ¶",See  torch.msort(),,,,
"
 Tensor. mul ( value )   → ¶",See  torch.mul() .,,,,
"
 Tensor. mul_ ( value )   → ¶",In-place version of  mul() .,,,,
"
 Tensor. multiply ( value )   → ¶",See  torch.multiply() .,,,,
"
 Tensor. multiply_ ( value )   → ¶",In-place version of  multiply() .,,,,
"
 Tensor. multinomial ( num_samples ,  replacement ,  * ,  generator )   → ¶",See  torch.multinomial(),,,,
"
 Tensor. mv ( vec )   → ¶",See  torch.mv(),,,,
"
 Tensor. mvlgamma ( p )   → ¶",See  torch.mvlgamma(),,,,
"
 Tensor. mvlgamma_ ( p )   → ¶",In-place version of  mvlgamma(),,,,
"
 Tensor. nansum ( dim ,  keepdim ,  dtype )   → ¶",See  torch.nansum(),,,,
"
 Tensor. narrow ( dimension ,  start ,  length )   → ¶","See  torch.narrow() Example: 
",">>> x=torch.tensor([[1,2,3],[4,5,6],[7,8,9]])
>>> x.narrow(0,0,2)
tensor([[ 1,  2,  3],
        [ 4,  5,  6]])
>>> x.narrow(1,1,2)
tensor([[ 2,  3],
        [ 5,  6],
        [ 8,  9]])
",,,
"
 Tensor. narrow_copy ( dimension ,  start ,  length )   → ¶",See  torch.narrow_copy() .,,,,
"
 Tensor. ndimension ( )   → ¶",Alias for  dim(),,,,
"
 Tensor. nan_to_num ( nan ,  posinf ,  neginf )   → ¶",See  torch.nan_to_num() .,,,,
"
 Tensor. nan_to_num_ ( nan ,  posinf ,  neginf )   → ¶",In-place version of  nan_to_num() .,,,,
"
 Tensor. ne ( other )   → ¶",See  torch.ne() .,,,,
"
 Tensor. ne_ ( other )   → ¶",In-place version of  ne() .,,,,
"
 Tensor. not_equal ( other )   → ¶",See  torch.not_equal() .,,,,
"
 Tensor. not_equal_ ( other )   → ¶",In-place version of  not_equal() .,,,,
"
 Tensor. neg ( )   → ¶",See  torch.neg(),,,,
"
 Tensor. neg_ ( )   → ¶",In-place version of  neg(),,,,
"
 Tensor. negative ( )   → ¶",See  torch.negative(),,,,
"
 Tensor. negative_ ( )   → ¶",In-place version of  negative(),,,,
"
 Tensor. nelement ( )   → ¶",Alias for  numel(),,,,
"
 Tensor. numel ( )   → ¶",See  torch.numel(),,,,
"
 Tensor. nextafter ( other )   → ¶",See  torch.nextafter(),,,,
"
 Tensor. nextafter_ ( other )   → ¶",In-place version of  nextafter(),,,,
"
 Tensor. nonzero ( )   → ¶",See  torch.nonzero(),,,,
"
 Tensor. norm ( p ,  dim ,  keepdim ,  dtype ) [source] ¶",See  torch.norm(),,,,
"
 Tensor. numpy ( * ,  force )   → ¶","Returns the tensor as a NumPy  ndarray . If  force  is  False  (the default), the conversion
is performed only if the tensor is on the CPU, does not require grad,
does not have its conjugate bit set, and is a dtype and layout that
NumPy supports. The returned ndarray and the tensor will share their
storage, so changes to the tensor will be reflected in the ndarray
and vice versa. If  force  is  True  this is equivalent to
calling  t.detach().cpu().resolve_conj().resolve_neg().numpy() .
If the tensor isn’t on the CPU or the conjugate or negative bit is set,
the tensor won’t share its storage with the returned ndarray.
Setting  force  to  True  can be a useful shorthand. 
 Parameters 
 force 
",,,,
"
 Tensor. orgqr ( input2 )   → ¶",See  torch.orgqr(),,,,
"
 Tensor. ormqr ( input2 ,  input3 ,  left ,  transpose )   → ¶",See  torch.ormqr(),,,,
"
 Tensor. outer ( vec2 )   → ¶",See  torch.outer() .,,,,
"
 Tensor. permute ( * )   → ¶",See  torch.permute(),,,,
"
 Tensor. pin_memory ( )   → ¶","Copies the tensor to pinned memory, if it’s not already pinned.",,,,
"
 Tensor. pinverse ( )   → ¶",See  torch.pinverse(),,,,
"
 Tensor. polygamma ( n )   → ¶",See  torch.polygamma(),,,,
"
 Tensor. polygamma_ ( n )   → ¶",In-place version of  polygamma(),,,,
"
 Tensor. positive ( )   → ¶",See  torch.positive(),,,,
"
 Tensor. pow ( exponent )   → ¶",See  torch.pow(),,,,
"
 Tensor. pow_ ( exponent )   → ¶",In-place version of  pow(),,,,
"
 Tensor. prod ( dim ,  keepdim ,  dtype )   → ¶",See  torch.prod(),,,,
"
 Tensor. put_ ( index ,  source ,  accumulate )   → ¶","Copies the elements from  source  into the positions specified by
 index . For the purpose of indexing, the  self  tensor is treated as if
it were a 1-D tensor. index  and  source  need to have the same number of elements, but not necessarily
the same shape. If  accumulate  is  True , the elements in  source  are added to
 self . If accumulate is  False , the behavior is undefined if  index 
contain duplicate elements. 
 Parameters 
 
 
 Example: 
",">>> src=torch.tensor([[4,3,5],
... [6,7,8]])
>>> src.put_(torch.tensor([1,3]),torch.tensor([9,10]))
tensor([[  4,   9,   5],
        [ 10,   7,   8]])
",,,
"
 Tensor. qr ( some ) ¶",See  torch.qr(),,,,
"
 Tensor. qscheme ( )   → ¶",Returns the quantization scheme of a given QTensor.,,,,
"
 Tensor. quantile ( q ,  dim ,  keepdim ,  * ,  interpolation )   → ¶",See  torch.quantile(),,,,
"
 Tensor. nanquantile ( q ,  dim ,  keepdim ,  * ,  interpolation )   → ¶",See  torch.nanquantile(),,,,
"
 Tensor. q_scale ( )   → ¶","Given a Tensor quantized by linear(affine) quantization,
returns the scale of the underlying quantizer().",,,,
"
 Tensor. q_zero_point ( )   → ¶","Given a Tensor quantized by linear(affine) quantization,
returns the zero_point of the underlying quantizer().",,,,
"
 Tensor. q_per_channel_scales ( )   → ¶","Given a Tensor quantized by linear (affine) per-channel quantization,
returns a Tensor of scales of the underlying quantizer. It has the number of
elements that matches the corresponding dimensions (from q_per_channel_axis) of
the tensor.",,,,
"
 Tensor. q_per_channel_zero_points ( )   → ¶","Given a Tensor quantized by linear (affine) per-channel quantization,
returns a tensor of zero_points of the underlying quantizer. It has the number of
elements that matches the corresponding dimensions (from q_per_channel_axis) of
the tensor.",,,,
"
 Tensor. q_per_channel_axis ( )   → ¶","Given a Tensor quantized by linear (affine) per-channel quantization,
returns the index of dimension on which per-channel quantization is applied.",,,,
"
 Tensor. rad2deg ( )   → ¶",See  torch.rad2deg(),,,,
"
 Tensor. ravel ( )   → ¶",see  torch.ravel(),,,,
"
 Tensor. reciprocal ( )   → ¶",See  torch.reciprocal(),,,,
"
 Tensor. reciprocal_ ( )   → ¶",In-place version of  reciprocal(),,,,
"
 Tensor. record_stream ( stream ) ¶","Ensures that the tensor memory is not reused for another tensor until all
current work queued on  stream  are complete. 
 Note 
 The caching allocator is aware of only the stream where a tensor was
allocated. Due to the awareness, it already correctly manages the life
cycle of tensors on only one stream. But if a tensor is used on a stream
different from the stream of origin, the allocator might reuse the memory
unexpectedly. Calling this method lets the allocator know which streams
have used the tensor. 
",,,,
"
 Tensor. register_hook ( hook ) [source] ¶","Registers a backward hook. The hook will be called every time a gradient with respect to the
Tensor is computed. The hook should have the following signature: 
 The hook should not modify its argument, but it can optionally return
a new gradient which will be used in place of  grad . This function returns a handle with a method  handle.remove() 
that removes the hook from the module. Example: 
",">>> v=torch.tensor([0.,0.,0.],requires_grad=True)
>>> h=v.register_hook(lambdagrad:grad*2)# double the gradient
>>> v.backward(torch.tensor([1.,2.,3.]))
>>> v.grad 2
 4
 6
[torch.FloatTensor of size (3,)]>>> h.remove()# removes the hook
",,,
"
 Tensor. remainder ( divisor )   → ¶",See  torch.remainder(),,,,
"
 Tensor. remainder_ ( divisor )   → ¶",In-place version of  remainder(),,,,
"
 Tensor. renorm ( p ,  dim ,  maxnorm )   → ¶",See  torch.renorm(),,,,
"
 Tensor. renorm_ ( p ,  dim ,  maxnorm )   → ¶",In-place version of  renorm(),,,,
"
 Tensor. repeat ( * )   → ¶","Repeats this tensor along the specified dimensions. Unlike  expand() , this function copies the tensor’s data. 
 Warning 
 repeat() 
 
 Parameters 
 sizes 
 Example: 
",">>> x=torch.tensor([1,2,3])
>>> x.repeat(4,2)
tensor([[ 1,  2,  3,  1,  2,  3],
        [ 1,  2,  3,  1,  2,  3],
        [ 1,  2,  3,  1,  2,  3],
        [ 1,  2,  3,  1,  2,  3]])
>>> x.repeat(4,2,1).size()
torch.Size([4, 2, 3])
",,,
"
 Tensor. repeat_interleave ( repeats ,  dim ,  * ,  output_size )   → ¶",See  torch.repeat_interleave() .,,,,
"
 Tensor. requires_grad ¶","Is  True  if gradients need to be computed for this Tensor,  False  otherwise. 
 Note 
 The fact that gradients need to be computed for a Tensor do not mean that the  
",,,,
"
 Tensor. reshape ( * )   → ¶","Returns a tensor with the same data and number of elements as  self 
but with the specified shape. This method returns a view if  shape  is
compatible with the current shape. See  torch.Tensor.view()  on when it is
possible to return a view. See  torch.reshape() 
 Parameters 
 shape 
",,,,
"
 Tensor. reshape_as ( other )   → ¶","Returns this tensor as the same shape as  other .
 self.reshape_as(other)  is equivalent to  self.reshape(other.sizes()) .
This method returns a view if  other.sizes()  is compatible with the current
shape. See  torch.Tensor.view()  on when it is possible to return a view. Please see  reshape()  for more information about  reshape . 
 Parameters 
 other 
",,,,
"
 Tensor. resize_ ( * ,  memory_format )   → ¶","Resizes  self  tensor to the specified size. If the number of elements is
larger than the current storage size, then the underlying storage is resized
to fit the new number of elements. If the number of elements is smaller, the
underlying storage is not changed. Existing elements are preserved but any new
memory is uninitialized. 
 Warning 
 This is a low-level method. The storage is reinterpreted as C-contiguous,
ignoring the current strides (unless the target size equals the current
size, in which case the tensor is left unchanged). For most purposes, you
will instead want to use  
 
 Parameters 
 
 
 Example: 
",">>> x=torch.tensor([[1,2],[3,4],[5,6]])
>>> x.resize_(2,2)
tensor([[ 1,  2],
        [ 3,  4]])
",,,
"
 Tensor. resize_as_ ( tensor ,  memory_format )   → ¶","Resizes the  self  tensor to be the same size as the specified
 tensor . This is equivalent to  self.resize_(tensor.size()) . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. retain_grad ( )   → ¶","Enables this Tensor to have their  grad  populated during
 backward() . This is a no-op for leaf tensors.",,,,
"
 Tensor. retains_grad ¶","Is  True  if this Tensor is non-leaf and its  grad  is enabled to be
populated during  backward() ,  False  otherwise.",,,,
"
 Tensor. roll ( shifts ,  dims )   → ¶",See  torch.roll(),,,,
"
 Tensor. rot90 ( k ,  dims )   → ¶",See  torch.rot90(),,,,
"
 Tensor. round ( decimals )   → ¶",See  torch.round(),,,,
"
 Tensor. round_ ( decimals )   → ¶",In-place version of  round(),,,,
"
 Tensor. rsqrt ( )   → ¶",See  torch.rsqrt(),,,,
"
 Tensor. rsqrt_ ( )   → ¶",In-place version of  rsqrt(),,,,
"
 Tensor. scatter ( dim ,  index ,  src )   → ¶",Out-of-place version of  torch.Tensor.scatter_(),,,,
"
 Tensor. scatter_add ( dim ,  index ,  src )   → ¶",Out-of-place version of  torch.Tensor.scatter_add_(),,,,
"
 Tensor. scatter_reduce ( dim ,  index ,  src ,  reduce ,  * ,  include_self )   → ¶",Out-of-place version of  torch.Tensor.scatter_reduce_(),,,,
"
 Tensor. select ( dim ,  index )   → ¶",See  torch.select(),,,,
"
 Tensor. select_scatter ( src ,  dim ,  index )   → ¶",See  torch.select_scatter(),,,,
"
 Tensor. set_ ( source ,  storage_offset ,  size ,  stride )   → ¶","Sets the underlying storage, size, and strides. If  source  is a tensor,
 self  tensor will share the same storage and have the same size and
strides as  source . Changes to elements in one tensor will be reflected
in the other. If  source  is a  Storage , the method sets the underlying
storage, offset, size, and stride. 
 Parameters 
 
 
",,,,
"
 Tensor. share_memory_ ( ) [source] ¶","Moves the underlying storage to shared memory. This is a no-op if the underlying storage is already in shared memory
and for CUDA tensors. Tensors in shared memory cannot be resized.",,,,
"
 Tensor. short ( memory_format )   → ¶","self.short()  is equivalent to  self.to(torch.int16) . See  to() . 
 Parameters 
 memory_format 
",,,,
"
 Tensor. sigmoid ( )   → ¶",See  torch.sigmoid(),,,,
"
 Tensor. sigmoid_ ( )   → ¶",In-place version of  sigmoid(),,,,
"
 Tensor. sign ( )   → ¶",See  torch.sign(),,,,
"
 Tensor. sign_ ( )   → ¶",In-place version of  sign(),,,,
"
 Tensor. signbit ( )   → ¶",See  torch.signbit(),,,,
"
 Tensor. sgn ( )   → ¶",See  torch.sgn(),,,,
"
 Tensor. sgn_ ( )   → ¶",In-place version of  sgn(),,,,
"
 Tensor. sin ( )   → ¶",See  torch.sin(),,,,
"
 Tensor. sin_ ( )   → ¶",In-place version of  sin(),,,,
"
 Tensor. sinc ( )   → ¶",See  torch.sinc(),,,,
"
 Tensor. sinc_ ( )   → ¶",In-place version of  sinc(),,,,
"
 Tensor. sinh ( )   → ¶",See  torch.sinh(),,,,
"
 Tensor. sinh_ ( )   → ¶",In-place version of  sinh(),,,,
"
 Tensor. asinh ( )   → ¶",See  torch.asinh(),,,,
"
 Tensor. asinh_ ( )   → ¶",In-place version of  asinh(),,,,
"
 Tensor. arcsinh ( )   → ¶",See  torch.arcsinh(),,,,
"
 Tensor. arcsinh_ ( )   → ¶",In-place version of  arcsinh(),,,,
"
 Tensor. size ( dim )   → ¶","Returns the size of the  self  tensor. If  dim  is not specified,
the returned value is a  torch.Size , a subclass of  tuple .
If  dim  is specified, returns an int holding the size of that dimension. 
 Parameters 
 dim 
 Example: 
",">>> t=torch.empty(3,4,5)
>>> t.size()
torch.Size([3, 4, 5])
>>> t.size(dim=1)
4
",,,
"
 Tensor. slogdet ( ) ¶",See  torch.slogdet(),,,,
"
 Tensor. slice_scatter ( src ,  dim ,  start ,  end ,  step )   → ¶",See  torch.slice_scatter(),,,,
"
 Tensor. sort ( dim ,  descending ) ¶",See  torch.sort(),,,,
"
 Tensor. split ( split_size ,  dim ) [source] ¶",See  torch.split(),,,,
"
 Tensor. sparse_mask ( mask )   → ¶","Returns a new  sparse tensor  with values from a
strided tensor  self  filtered by the indices of the sparse
tensor  mask . The values of  mask  sparse tensor are
ignored.  self  and  mask  tensors must have the same
shape. 
 Note 
 The returned sparse tensor has the same indices as the sparse tensor
 
 
 Parameters 
 mask 
 Example: 
",">>> nse=5
>>> dims=(5,5,2,2)
>>> I=torch.cat([torch.randint(0,dims[0],size=(nse,)),
... torch.randint(0,dims[1],size=(nse,))],0).reshape(2,nse)
>>> V=torch.randn(nse,dims[2],dims[3])
>>> S=torch.sparse_coo_tensor(I,V,dims).coalesce()
>>> D=torch.randn(dims)
>>> D.sparse_mask(S)
tensor(indices=tensor([[0, 0, 0, 2],
                       [0, 1, 4, 3]]),
       values=tensor([[[ 1.6550,  0.2397],
                       [-0.1611, -0.0779]],                      [[ 0.2326, -1.0558],
                       [ 1.4711,  1.9678]],                      [[-0.5138, -0.0411],
                       [ 1.9417,  0.5158]],                      [[ 0.0793,  0.0036],
                       [-0.2569, -0.1055]]]),
       size=(5, 5, 2, 2), nnz=4, layout=torch.sparse_coo)
",,,
"
 Tensor. sparse_dim ( )   → ¶","Return the number of sparse dimensions in a  sparse tensor   self . 
 Warning 
 Throws an error if  
 See also  Tensor.dense_dim()  and  hybrid tensors .",,,,
"
 Tensor. sqrt ( )   → ¶",See  torch.sqrt(),,,,
"
 Tensor. sqrt_ ( )   → ¶",In-place version of  sqrt(),,,,
"
 Tensor. square ( )   → ¶",See  torch.square(),,,,
"
 Tensor. square_ ( )   → ¶",In-place version of  square(),,,,
"
 Tensor. squeeze ( dim )   → ¶",See  torch.squeeze(),,,,
"
 Tensor. squeeze_ ( dim )   → ¶",In-place version of  squeeze(),,,,
"
 Tensor. std ( dim ,  unbiased ,  keepdim )   → ¶","See  torch.std() 
 
 
 See  torch.std()",,,,
"
 Tensor. stft ( n_fft ,  hop_length ,  win_length ,  window ,  center ,  pad_mode ,  normalized ,  onesided ,  return_complex ) [source] ¶","See  torch.stft() 
 Warning 
 This function changed signature at version 0.4.1. Calling with
the previous signature may cause error or return incorrect result. 
 
",,,,
"
 Tensor. storage ( )   → [source] ¶",Returns the underlying storage.,,,,
"
 Tensor. storage_offset ( )   → ¶","Returns  self  tensor’s offset in the underlying storage in terms of
number of storage elements (not bytes). Example: 
",">>> x=torch.tensor([1,2,3,4,5])
>>> x.storage_offset()
0
>>> x[3:].storage_offset()
3
",,,
"
 Tensor. storage_type ( )   → [source] ¶",Returns the type of the underlying storage.,,,,
"
 Tensor. stride ( dim )   → ¶","Returns the stride of  self  tensor. Stride is the jump necessary to go from one element to the next one in the
specified dimension  dim . A tuple of all strides is returned when no
argument is passed in. Otherwise, an integer value is returned as the stride in
the particular dimension  dim . 
 Parameters 
 dim 
 Example: 
",">>> x=torch.tensor([[1,2,3,4,5],[6,7,8,9,10]])
>>> x.stride()
(5, 1)
>>> x.stride(0)
5
>>> x.stride(-1)
1
",,,
"
 Tensor. sub ( other ,  * ,  alpha )   → ¶",See  torch.sub() .,,,,
"
 Tensor. sub_ ( other ,  * ,  alpha )   → ¶",In-place version of  sub(),,,,
"
 Tensor. subtract ( other ,  * ,  alpha )   → ¶",See  torch.subtract() .,,,,
"
 Tensor. subtract_ ( other ,  * ,  alpha )   → ¶",In-place version of  subtract() .,,,,
"
 Tensor. sum ( dim ,  keepdim ,  dtype )   → ¶",See  torch.sum(),,,,
"
 Tensor. sum_to_size ( * )   → ¶","Sum  this  tensor to  size .
 size  must be broadcastable to  this  tensor size. 
 Parameters 
 size 
",,,,
"
 Tensor. svd ( some ,  compute_uv ) ¶",See  torch.svd(),,,,
"
 Tensor. swapaxes ( axis0 ,  axis1 )   → ¶",See  torch.swapaxes(),,,,
"
 Tensor. swapdims ( dim0 ,  dim1 )   → ¶",See  torch.swapdims(),,,,
"
 Tensor. symeig ( eigenvectors ,  upper ) ¶",See  torch.symeig(),,,,
"
 Tensor. t ( )   → ¶",See  torch.t(),,,,
"
 Tensor. t_ ( )   → ¶",In-place version of  t(),,,,
"
 Tensor. tensor_split ( indices_or_sections ,  dim )   → ¶",See  torch.tensor_split(),,,,
"
 Tensor. tile ( * )   → ¶",See  torch.tile(),,,,
"
 Tensor. to_mkldnn ( )   → ¶",Returns a copy of the tensor in  torch.mkldnn  layout.,,,,
"
 Tensor. take ( indices )   → ¶",See  torch.take(),,,,
"
 Tensor. take_along_dim ( indices ,  dim )   → ¶",See  torch.take_along_dim(),,,,
"
 Tensor. tan ( )   → ¶",See  torch.tan(),,,,
"
 Tensor. tan_ ( )   → ¶",In-place version of  tan(),,,,
"
 Tensor. tanh ( )   → ¶",See  torch.tanh(),,,,
"
 Tensor. tanh_ ( )   → ¶",In-place version of  tanh(),,,,
"
 Tensor. atanh ( )   → ¶",See  torch.atanh(),,,,
"
 Tensor. atanh_ ( other )   → ¶",In-place version of  atanh(),,,,
"
 Tensor. arctanh ( )   → ¶",See  torch.arctanh(),,,,
"
 Tensor. arctanh_ ( other )   → ¶",In-place version of  arctanh(),,,,
"
 Tensor. tolist ( )   → ¶","Returns the tensor as a (nested) list. For scalars, a standard
Python number is returned, just like with  item() .
Tensors are automatically moved to the CPU first if necessary. This operation is not differentiable. Examples: 
",">>> a=torch.randn(2,2)
>>> a.tolist()
[[0.012766935862600803, 0.5415473580360413],
 [-0.08909505605697632, 0.7729271650314331]]
>>> a[0,0].tolist()
0.012766935862600803
",,,
"
 Tensor. topk ( k ,  dim ,  largest ,  sorted ) ¶",See  torch.topk(),,,,
"
 Tensor. to_dense ( )   → ¶","Creates a strided copy of  self  if  self  is not a strided tensor, otherwise returns  self . Example: 
",">>> s=torch.sparse_coo_tensor(
... torch.tensor([[1,1],
... [0,2]]),
... torch.tensor([9,10]),
... size=(3,3))
>>> s.to_dense()
tensor([[ 0,  0,  0],
        [ 9,  0, 10],
        [ 0,  0,  0]])
",,,
"
 Tensor. to_sparse ( sparseDims )   → ¶","Returns a sparse copy of the tensor.  PyTorch supports sparse tensors in
 coordinate format . 
 Parameters 
 sparseDims 
 Example: 
",">>> d=torch.tensor([[0,0,0],[9,0,10],[0,0,0]])
>>> d
tensor([[ 0,  0,  0],
        [ 9,  0, 10],
        [ 0,  0,  0]])
>>> d.to_sparse()
tensor(indices=tensor([[1, 1],
                       [0, 2]]),
       values=tensor([ 9, 10]),
       size=(3, 3), nnz=2, layout=torch.sparse_coo)
>>> d.to_sparse(1)
tensor(indices=tensor([[1]]),
       values=tensor([[ 9,  0, 10]]),
       size=(3, 3), nnz=1, layout=torch.sparse_coo)
",,,
"
 Tensor. to_sparse_csr ( )   → ¶","Convert a tensor to compressed row storage format (CSR). Only works with 2D tensors. Example: 
",">>> dense=torch.randn(5,5)
>>> sparse=dense.to_sparse_csr()
>>> sparse._nnz()
25
",,,
"
 Tensor. to_sparse_csc ( )   → ¶","Convert a tensor to compressed column storage (CSC) format. Only works with 2D tensors. Example: 
",">>> dense=torch.randn(5,5)
>>> sparse=dense.to_sparse_csc()
>>> sparse._nnz()
25
",,,
"
 Tensor. to_sparse_bsr ( blocksize )   → ¶","Convert a CSR tensor to a block sparse row (BSR) storage format of given blocksize. Example: 
",">>> dense=torch.randn(10,10)
>>> sparse=dense.to_sparse_csr()
>>> sparse_bsr=sparse.to_sparse_bsr((5,5))
>>> sparse_bsr.col_indices()
tensor([0, 1, 0, 1])
",,,
"
 Tensor. to_sparse_bsc ( blocksize )   → ¶","Convert a CSR tensor to a block sparse column (BSC) storage format of given blocksize. Example: 
",">>> dense=torch.randn(10,10)
>>> sparse=dense.to_sparse_csr()
>>> sparse_bsc=sparse.to_sparse_bsc((5,5))
>>> sparse_bsc.row_indices()
tensor([0, 1, 0, 1])
",,,
"
 Tensor. trace ( )   → ¶",See  torch.trace(),,,,
"
 Tensor. transpose ( dim0 ,  dim1 )   → ¶",See  torch.transpose(),,,,
"
 Tensor. transpose_ ( dim0 ,  dim1 )   → ¶",In-place version of  transpose(),,,,
"
 Tensor. triangular_solve ( A ,  upper ,  transpose ,  unitriangular ) ¶",See  torch.triangular_solve(),,,,
"
 Tensor. tril ( diagonal )   → ¶",See  torch.tril(),,,,
"
 Tensor. tril_ ( diagonal )   → ¶",In-place version of  tril(),,,,
"
 Tensor. triu ( diagonal )   → ¶",See  torch.triu(),,,,
"
 Tensor. triu_ ( diagonal )   → ¶",In-place version of  triu(),,,,
"
 Tensor. true_divide ( value )   → ¶",See  torch.true_divide(),,,,
"
 Tensor. true_divide_ ( value )   → ¶",In-place version of  true_divide_(),,,,
"
 Tensor. trunc ( )   → ¶",See  torch.trunc(),,,,
"
 Tensor. trunc_ ( )   → ¶",In-place version of  trunc(),,,,
"
 Tensor. type ( dtype ,  non_blocking ,  ** )   → ¶","Returns the type if  dtype  is not provided, else casts this object to
the specified type. If this is already of the correct type, no copy is performed and the
original object is returned. 
 Parameters 
 
 
",,,,
"
 Tensor. type_as ( tensor )   → ¶","Returns this tensor cast to the type of the given tensor. This is a no-op if the tensor is already of the correct type. This is
equivalent to  self.type(tensor.type()) 
 Parameters 
 tensor 
",,,,
"
 Tensor. unbind ( dim )   → ¶",See  torch.unbind(),,,,
"
 Tensor. unflatten ( dim ,  sizes )   → [source] ¶",See  torch.unflatten() .,,,,
"
 Tensor. unfold ( dimension ,  size ,  step )   → ¶","Returns a view of the original tensor which contains all slices of size  size  from
 self  tensor in the dimension  dimension . Step between two slices is given by  step . If  sizedim  is the size of dimension  dimension  for  self , the size of
dimension  dimension  in the returned tensor will be
 (sizedim - size) / step + 1 . An additional dimension of size  size  is appended in the returned tensor. 
 Parameters 
 
 
 Example: 
",">>> x=torch.arange(1.,8)
>>> x
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.])
>>> x.unfold(0,2,1)
tensor([[ 1.,  2.],
        [ 2.,  3.],
        [ 3.,  4.],
        [ 4.,  5.],
        [ 5.,  6.],
        [ 6.,  7.]])
>>> x.unfold(0,2,2)
tensor([[ 1.,  2.],
        [ 3.,  4.],
        [ 5.,  6.]])
",,,
"
 Tensor. unique ( sorted ,  return_inverse ,  return_counts ,  dim ) [source] ¶",Returns the unique elements of the input tensor. See  torch.unique(),,,,
"
 Tensor. unique_consecutive ( return_inverse ,  return_counts ,  dim ) [source] ¶",Eliminates all but the first element from every consecutive group of equivalent elements. See  torch.unique_consecutive(),,,,
"
 Tensor. unsqueeze ( dim )   → ¶",See  torch.unsqueeze(),,,,
"
 Tensor. unsqueeze_ ( dim )   → ¶",In-place version of  unsqueeze(),,,,
"
 Tensor. values ( )   → ¶","Return the values tensor of a  sparse COO tensor . 
 Warning 
 Throws an error if  
 See also  Tensor.indices() . 
 Note 
 This method can only be called on a coalesced sparse tensor. See
 
",,,,
"
 Tensor. var ( dim ,  unbiased ,  keepdim )   → ¶","See  torch.var() 
 
 
 See  torch.var()",,,,
"
 Tensor. vdot ( other )   → ¶",See  torch.vdot(),,,,
"
 Tensor. view ( * )   → ¶","Returns a new tensor with the same data as the  self  tensor but of a
different  shape . The returned tensor shares the same data and must have the same number
of elements, but may have a different size. For a tensor to be viewed, the new
view size must be compatible with its original size and stride, i.e., each new
view dimension must either be a subspace of an original dimension, or only span
across original dimensions  d  that satisfy the following
contiguity-like condition that  ∀ , 
 stride Otherwise, it will not be possible to view  self  tensor as  shape 
without copying it (e.g., via  contiguous() ). When it is unclear whether a
 view()  can be performed, it is advisable to use  reshape() , which
returns a view if the shapes are compatible, and copies (equivalent to calling
 contiguous() ) otherwise. 
 Parameters 
 shape 
 Example: 
 
 
 
 Returns a new tensor with the same data as the  self  tensor but of a
different  dtype . If the element size of  dtype  is different than that of  self.dtype ,
then the size of the last dimension of the output will be scaled
proportionally.  For instance, if  dtype  element size is twice that of
 self.dtype , then each pair of elements in the last dimension of
 self  will be combined, and the size of the last dimension of the output
will be half that of  self . If  dtype  element size is half that
of  self.dtype , then each element in the last dimension of  self  will
be split in two, and the size of the last dimension of the output will be
double that of  self . For this to be possible, the following conditions
must be true: 
 
 Additionally, if the element size of  dtype  is greater than that of
 self.dtype , the following conditions must be true as well: 
 
 If any of the above conditions are not met, an error is thrown. 
 Warning 
 This overload is not supported by TorchScript, and using it in a Torchscript
program will cause undefined behavior. 
 
 Parameters 
 dtype 
 Example: 
",">>> x=torch.randn(4,4)
>>> x.size()
torch.Size([4, 4])
>>> y=x.view(16)
>>> y.size()
torch.Size([16])
>>> z=x.view(-1,8)# the size -1 is inferred from other dimensions
>>> z.size()
torch.Size([2, 8])>>> a=torch.randn(1,2,3,4)
>>> a.size()
torch.Size([1, 2, 3, 4])
>>> b=a.transpose(1,2)# Swaps 2nd and 3rd dimension
>>> b.size()
torch.Size([1, 3, 2, 4])
>>> c=a.view(1,3,2,4)# Does not change tensor layout in memory
>>> c.size()
torch.Size([1, 3, 2, 4])
>>> torch.equal(b,c)
False
",">>> x=torch.randn(4,4)
>>> x
tensor([[ 0.9482, -0.0310,  1.4999, -0.5316],
        [-0.1520,  0.7472,  0.5617, -0.8649],
        [-2.4724, -0.0334, -0.2976, -0.8499],
        [-0.2109,  1.9913, -0.9607, -0.6123]])
>>> x.dtype
torch.float32>>> y=x.view(torch.int32)
>>> y
tensor([[ 1064483442, -1124191867,  1069546515, -1089989247],
        [-1105482831,  1061112040,  1057999968, -1084397505],
        [-1071760287, -1123489973, -1097310419, -1084649136],
        [-1101533110,  1073668768, -1082790149, -1088634448]],
    dtype=torch.int32)
>>> y[0,0]=1000000000
>>> x
tensor([[ 0.0047, -0.0310,  1.4999, -0.5316],
        [-0.1520,  0.7472,  0.5617, -0.8649],
        [-2.4724, -0.0334, -0.2976, -0.8499],
        [-0.2109,  1.9913, -0.9607, -0.6123]])>>> x.view(torch.cfloat)
tensor([[ 0.0047-0.0310j,  1.4999-0.5316j],
        [-0.1520+0.7472j,  0.5617-0.8649j],
        [-2.4724-0.0334j, -0.2976-0.8499j],
        [-0.2109+1.9913j, -0.9607-0.6123j]])
>>> x.view(torch.cfloat).size()
torch.Size([4, 2])>>> x.view(torch.uint8)
tensor([[  0, 202, 154,  59, 182, 243, 253, 188, 185, 252, 191,  63, 240,  22,
           8, 191],
        [227, 165,  27, 190, 128,  72,  63,  63, 146, 203,  15,  63,  22, 106,
          93, 191],
        [205,  59,  30, 192, 112, 206,   8, 189,   7,  95, 152, 190,  12, 147,
          89, 191],
        [ 43, 246,  87, 190, 235, 226, 254,  63, 111, 240, 117, 191, 177, 191,
          28, 191]], dtype=torch.uint8)
>>> x.view(torch.uint8).size()
torch.Size([4, 16])
",,
"
 Tensor. view_as ( other )   → ¶","View this tensor as the same size as  other .
 self.view_as(other)  is equivalent to  self.view(other.size()) . Please see  view()  for more information about  view . 
 Parameters 
 other 
",,,,
"
 Tensor. vsplit ( split_size_or_sections )   → ¶",See  torch.vsplit(),,,,
"
 Tensor. where ( condition ,  y )   → ¶","self.where(condition,  is equivalent to  torch.where(condition, .
See  torch.where()",,,,
"
 Tensor. xlogy ( other )   → ¶",See  torch.xlogy(),,,,
"
 Tensor. xlogy_ ( other )   → ¶",In-place version of  xlogy(),,,,
"
 Tensor. zero_ ( )   → ¶",Fills  self  tensor with zeros.,,,,
"
 torch.cuda. set_device ( device ) [source] ¶","Sets the current device. Usage of this function is discouraged in favor of  device . In most
cases it’s better to use  CUDA_VISIBLE_DEVICES  environmental variable. 
 Parameters 
 device 
",,,,
"
 torch.cuda. current_device ( ) [source] ¶","Returns the index of a currently selected device. 
 Return type 
 int 
",,,,
"
 torch.autograd. backward ( tensors ,  grad_tensors ,  retain_graph ,  create_graph ,  grad_variables ,  inputs ) [source] ¶","Computes the sum of gradients of given tensors with respect to graph
leaves. The graph is differentiated using the chain rule. If any of  tensors 
are non-scalar (i.e. their data has more than one element) and require
gradient, then the Jacobian-vector product would be computed, in this
case the function additionally requires specifying  grad_tensors .
It should be a sequence of matching length, that contains the “vector”
in the Jacobian-vector product, usually the gradient of the differentiated
function w.r.t. corresponding tensors ( None  is an acceptable value for
all tensors that don’t need gradient tensors). This function accumulates gradients in the leaves - you might need to zero
 .grad  attributes or set them to  None  before calling it.
See  Default gradient layouts 
for details on the memory layout of accumulated gradients. 
 Note 
 Using this method with  
 
 Note 
 If you run any forward ops, create  
 
 Note 
 When  
 
 Parameters 
 
 
",,,,
"
 torch.autograd. grad ( outputs ,  inputs ,  grad_outputs ,  retain_graph ,  create_graph ,  only_inputs ,  allow_unused ,  is_grads_batched ) [source] ¶","Computes and returns the sum of gradients of outputs with respect to
the inputs. grad_outputs  should be a sequence of length matching  output 
containing the “vector” in vector-Jacobian product, usually the pre-computed
gradients w.r.t. each of the outputs. If an output doesn’t require_grad,
then the gradient can be  None ). 
 Note 
 If you run any forward ops, create  
 
 Note 
 only_inputs 
 
 Parameters 
 
 
 Return type 
 Tuple 
",,,,
"
 class torch.autograd.forward_ad. dual_level [source] ¶","Context-manager that enables forward AD. All forward AD computation must
be performed in a  dual_level  context. 
 Note 
 The  
 We currently don’t plan to support nested  
 Example: 
 Please see the  forward-mode AD tutorial 
for detailed steps on how to use this API.",">>> x=torch.tensor([1])
>>> x_t=torch.tensor([1])
>>> withdual_level():
... inp=make_dual(x,x_t)
... # Do computations with inp
... out=your_fn(inp)
... _,grad=unpack_dual(out)
>>> gradisNone
False
>>> # After exiting the level, the grad is deleted
>>> _,grad_after=unpack_dual(out)
>>> gradisNone
True
",,,
"
 torch.autograd.forward_ad. make_dual ( tensor ,  tangent ,  * ,  level ) [source] ¶","Associates a tensor value with a forward gradient, the tangent, to create a
“dual tensor”, which is used to compute forward AD gradients.
The result is a new tensor aliased to  tensor  with  tangent  embedded
as an attribute as-is if it has the same storage layout or copied otherwise.
The tangent attribute can be recovered with  unpack_dual() . This function is backward differentiable. Given a function  f  whose jacobian is  J , it allows one to compute the Jacobian-vector product ( jvp )
between  J  and a given vector  v  as follows. Example: 
 Please see the  forward-mode AD tutorial 
for detailed steps on how to use this API.",">>> withdual_level():
... inp=make_dual(x,v)
... out=f(inp)
... y,jvp=unpack_dual(out)
",,,
"
 torch.autograd.forward_ad. unpack_dual ( tensor ,  * ,  level ) [source] ¶","Unpacks a “dual tensor” to get both its Tensor value and its forward AD gradient.
The result is a namedtuple  (primal,  where  primal  is a view of
 tensor ’s primal and  tangent  is  tensor ’s tangent as-is.
Neither of these tensors can be dual tensor of level  level . This function is backward differentiable. Example: 
 Please see the  forward-mode AD tutorial 
for detailed steps on how to use this API.",">>> withdual_level():
... inp=make_dual(x,x_t)
... out=f(inp)
... y,jvp=unpack_dual(out)
... jvp=unpack_dual(out).tangent
",,,
"
 torch.autograd.functional. jacobian ( func ,  inputs ,  create_graph ,  strict ,  vectorize ,  strategy ) [source] ¶","Function that computes the Jacobian of a given function. 
 Parameters 
 
 
 Returns 
 if there is a single
input and output, this will be a single Tensor containing the
Jacobian for the linearized inputs and output. If one of the two is
a tuple, then the Jacobian will be a tuple of Tensors. If both of
them are tuples, then the Jacobian will be a tuple of tuple of
Tensors where  
 Return type 
 Jacobian ( 
 Example 
 
 
",,,,
"
 torch.autograd.functional. hessian ( func ,  inputs ,  create_graph ,  strict ,  vectorize ,  outer_jacobian_strategy ) [source] ¶","Function that computes the Hessian of a given scalar function. 
 Parameters 
 
 
 Returns 
 if there is a single input,
this will be a single Tensor containing the Hessian for the input.
If it is a tuple, then the Hessian will be a tuple of tuples where
 
 Return type 
 Hessian ( 
 Example 
 
 
",,,,
"
 torch.autograd.functional. vjp ( func ,  inputs ,  v ,  create_graph ,  strict ) [source] ¶","Function that computes the dot product between a vector  v  and the
Jacobian of the given function at the point given by the inputs. 
 Parameters 
 
 
 Returns 
 
 
 Return type 
 output ( 
 Example 
 
 
",,,,
"
 torch.autograd.functional. jvp ( func ,  inputs ,  v ,  create_graph ,  strict ) [source] ¶","Function that computes the dot product between  the Jacobian of
the given function at the point given by the inputs and a vector  v . 
 Parameters 
 
 
 Returns 
 
 
 Return type 
 output ( 
 
 Note 
 autograd.functional.jvp 
 Example 
 
 
",,,,
"
 torch.autograd.functional. vhp ( func ,  inputs ,  v ,  create_graph ,  strict ) [source] ¶","Function that computes the dot product between a vector  v  and the
Hessian of a given scalar function at the point given by the inputs. 
 Parameters 
 
 
 Returns 
 
 
 Return type 
 output ( 
 Example 
",,,,
"
 torch.autograd.functional. hvp ( func ,  inputs ,  v ,  create_graph ,  strict ) [source] ¶","Function that computes the dot product between the Hessian of a given scalar
function and a vector  v  at the point given by the inputs. 
 Parameters 
 
 
 Returns 
 
 
 Return type 
 output ( 
 Example 
 
 
 
 Note 
 This function is significantly slower than  
",,,,
"
 static Function. forward ( ctx ,  * ,  ** ) [source] ¶","Performs the operation. This function is to be overridden by all subclasses. It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types). The context can be used to store arbitrary data that can be then
retrieved during the backward pass. Tensors should not be stored
directly on  ctx  (though this is not currently enforced for
backward compatibility). Instead, tensors should be saved either with
 ctx.save_for_backward()  if they are intended to be used in
 backward  (equivalently,  vjp ) or  ctx.save_for_forward() 
if they are intended to be used for in  jvp . 
 Return type 
 Any 
",,,,
"
 torch.autograd. gradcheck ( func ,  inputs ,  * ,  eps ,  atol ,  rtol ,  raise_exception ,  check_sparse_nnz ,  nondet_tol ,  check_undefined_grad ,  check_grad_dtypes ,  check_batched_grad ,  check_batched_forward_grad ,  check_forward_ad ,  check_backward_ad ,  fast_mode ) [source] ¶","Check gradients computed via small finite differences against analytical
gradients w.r.t. tensors in  inputs  that are of floating point or complex type
and with  requires_grad=True . The check between numerical and analytical gradients uses  allclose() . For most of the complex functions we consider for optimization purposes, no notion of
Jacobian exists. Instead, gradcheck verifies if the numerical and analytical values of
the Wirtinger and Conjugate Wirtinger derivatives are consistent. Because the gradient
computation is done under the assumption that the overall function has a real-valued
output, we treat functions with complex output in a special way. For these functions,
gradcheck is applied to two real-valued functions corresponding to taking the real
components of the complex outputs for the first, and taking the imaginary components
of the complex outputs for the second. For more details, check out
 Autograd for Complex Numbers . 
 Note 
 The default values are designed for  
 
 Warning 
 If any checked tensor in  
 
 Parameters 
 
 
 Returns 
 True if all differences satisfy allclose condition 
 Return type 
 bool 
",,,,
"
 static Function. backward ( ctx ,  * ) [source] ¶","Defines a formula for differentiating the operation with backward mode
automatic differentiation (alias to the vjp function). This function is to be overridden by all subclasses. It must accept a context  ctx  as the first argument, followed by
as many outputs as the  forward()  returned (None will be passed in
for non tensor outputs of the forward function),
and it should return as many tensors, as there were inputs to
 forward() . Each argument is the gradient w.r.t the given output,
and each returned value should be the gradient w.r.t. the
corresponding input. If an input is not a Tensor or is a Tensor not
requiring grads, you can just pass None as a gradient for that input. The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute  ctx.needs_input_grad  as a tuple
of booleans representing whether each input needs gradient. E.g.,
 backward()  will have  ctx.needs_input_grad[0]  if the
first input to  forward()  needs gradient computated w.r.t. the
output. 
 Return type 
 Any 
",,,,
"
 static Function. jvp ( ctx ,  * ) [source] ¶","Defines a formula for differentiating the operation with forward mode
automatic differentiation.
This function is to be overridden by all subclasses.
It must accept a context  ctx  as the first argument, followed by
as many inputs as the  forward()  got (None will be passed in
for non tensor inputs of the forward function),
and it should return as many tensors as there were outputs to
 forward() . Each argument is the gradient w.r.t the given input,
and each returned value should be the gradient w.r.t. the
corresponding output. If an output is not a Tensor or the function is not
differentiable with respect to that output, you can just pass None as a
gradient for that input. You can use the  ctx  object to pass any value from the forward to this
functions. 
 Return type 
 Any 
",,,,
"
 FunctionCtx. mark_dirty ( * ) [source] ¶","Marks given tensors as modified in an in-place operation. This should be called at most once, only from inside the 
 forward()   method, and all arguments should be inputs. Every tensor that’s been modified in-place in a call to  forward() 
should be given to this function, to ensure correctness of our checks.
It doesn’t matter whether the function is called before or after
modification. 
 Examples:: 
 
",,,,
"
 FunctionCtx. mark_non_differentiable ( * ) [source] ¶","Marks outputs as non-differentiable. This should be called at most once, only from inside the 
 forward()   method, and all arguments should be tensor outputs. This will mark outputs as not requiring gradients, increasing the
efficiency of backward computation. You still need to accept a gradient
for each output in  backward() , but it’s always going to
be a zero tensor with the same shape as the shape of a corresponding
output. 
 This is used e.g. for indices returned from a sort. See example:: 
 
",,,,
"
 FunctionCtx. save_for_backward ( * ) [source] ¶","Saves given tensors for a future call to  backward() . save_for_backward  should be called at most once, only from inside the
 forward()  method, and only with tensors. All tensors intended to be used in the backward pass should be saved
with  save_for_backward  (as opposed to directly on  ctx ) to prevent
incorrect gradients and memory leaks, and enable the application of saved
tensor hooks. See  torch.autograd.graph.saved_tensors_hooks . Note that if intermediary tensors, tensors that are neither inputs
nor outputs of  forward() , are saved for backward, your custom Function
may not support double backward.
Custom Functions that do not support double backward should decorate their
 backward()  method with  @once_differentiable  so that performing
double backward raises an error. If you’d like to support double backward,
you can either recompute intermediaries based on the inputs during backward
or return the intermediaries as the outputs of the custom Function. See the
 double backward tutorial 
for more details. In  backward() , saved tensors can be accessed through the  saved_tensors 
attribute. Before returning them to the user, a check is made to ensure
they weren’t used in any in-place operation that modified their content. Arguments can also be  None . This is a no-op. See  Extending torch.autograd  for more details on how to use this method. 
 Example:: 
 
",,,,
"
 FunctionCtx. set_materialize_grads ( value ) [source] ¶","Sets whether to materialize output grad tensors. Default is  True . This should be called only from inside the   forward()   method If  True , undefined output grad tensors will be expanded to tensors full
of zeros prior to calling the  backward()  method. 
 Example:: 
 
",,,,
"
 torch.autograd. gradgradcheck ( func ,  inputs ,  grad_outputs ,  * ,  eps ,  atol ,  rtol ,  gen_non_contig_grad_outputs ,  raise_exception ,  nondet_tol ,  check_undefined_grad ,  check_grad_dtypes ,  check_batched_grad ,  check_fwd_over_rev ,  check_rev_over_rev ,  fast_mode ) [source] ¶","Check gradients of gradients computed via small finite differences
against analytical gradients w.r.t. tensors in  inputs  and
 grad_outputs  that are of floating point or complex type and with
 requires_grad=True . This function checks that backpropagating through the gradients computed
to the given  grad_outputs  are correct. The check between numerical and analytical gradients uses  allclose() . 
 Note 
 The default values are designed for  
 
 Warning 
 If any checked tensor in  
 
 Parameters 
 
 
 Returns 
 True if all differences satisfy allclose condition 
 Return type 
 bool 
",,,,
"
 profile. export_chrome_trace ( path ) [source] ¶","Exports an EventList as a Chrome tracing tools file. The checkpoint can be later loaded and inspected under  chrome://tracing  URL. 
 Parameters 
 path 
",,,,
"
 profile. key_averages ( group_by_input_shape ,  group_by_stack_n ) [source] ¶","Averages all function events over their keys. 
 Parameters 
 
 
 Returns 
 An EventList containing FunctionEventAvg objects. 
",,,,
"
 property profile. self_cpu_time_total ¶","Returns total time spent on CPU obtained as a sum of
all self times across all the events.",,,,
"
 profile. total_average ( ) [source] ¶","Averages all events. 
 Returns 
 A FunctionEventAvg object. 
",,,,
"
 torch.autograd.profiler. load_nvprof ( path ) [source] ¶","Opens an nvprof trace file and parses autograd annotations. 
 Parameters 
 path 
",,,,
"
 class torch.cuda. StreamContext ( stream ) [source] ¶","Context-manager that selects a given stream. All CUDA kernels queued within its context will be enqueued on a selected
stream. 
 Parameters 
 Stream 
 
 Note 
 Streams are per-device. 
",,,,
"
 torch.cuda. is_available ( ) [source] ¶","Returns a bool indicating if CUDA is currently available. 
 Return type 
 bool 
",,,,
"
 torch.cuda. can_device_access_peer ( device ,  peer_device ) [source] ¶","Checks if peer access between two devices is possible. 
 Return type 
 bool 
",,,,
"
 torch.cuda. current_blas_handle ( ) [source] ¶",Returns cublasHandle_t pointer to current cuBLAS handle,,,,
"
 torch.cuda. current_stream ( device ) [source] ¶","Returns the currently selected  Stream  for a given device. 
 Parameters 
 device 
 Return type 
 Stream 
",,,,
"
 class torch.cuda. Stream ( device ,  priority ,  ** ) [source] ¶","Wrapper around a CUDA stream. A CUDA stream is a linear sequence of execution that belongs to a specific
device, independent from other streams.  See  CUDA semantics  for
details. 
 Parameters 
 
 
 
 Note 
 Although CUDA versions >= 11 support more than two levels of
priorities, in PyTorch, we only support two levels of priorities. 
 
 
 
 Checks if all the work submitted has been completed. 
 
 
 Records an event. 
 
 
 Wait for all the kernels in this stream to complete. 
 
 
 Makes all future work submitted to the stream wait for an event. 
 
 
 Synchronizes with another stream.",,,,
"
 torch.cuda. default_stream ( device ) [source] ¶","Returns the default  Stream  for a given device. 
 Parameters 
 device 
 Return type 
 Stream 
",,,,
"
 class torch.cuda. device ( device ) [source] ¶","Context-manager that changes the selected device. 
 Parameters 
 device 
",,,,
"
 torch.cuda. device_count ( ) [source] ¶","Returns the number of GPUs available. 
 Return type 
 int 
",,,,
"
 class torch.cuda. device_of ( obj ) [source] ¶","Context-manager that changes the current device to that of given object. You can use both tensors and storages as arguments. If a given object is
not allocated on a GPU, this is a no-op. 
 Parameters 
 obj 
",,,,
"
 torch.cuda. get_arch_list ( ) [source] ¶","Returns list CUDA architectures this library was compiled for. 
 Return type 
 List 
",,,,
"
 torch.cuda. get_device_capability ( device ) [source] ¶","Gets the cuda capability of a device. 
 Parameters 
 device 
 Returns 
 the major and minor cuda capability of the device 
 Return type 
 tuple 
",,,,
"
 torch.cuda. get_device_name ( device ) [source] ¶","Gets the name of a device. 
 Parameters 
 device 
 Returns 
 the name of the device 
 Return type 
 str 
",,,,
"
 torch.cuda. get_device_properties ( device ) [source] ¶","Gets the properties of a device. 
 Parameters 
 device 
 Returns 
 the properties of the device 
 Return type 
 _CudaDeviceProperties 
",,,,
"
 torch.cuda. get_gencode_flags ( ) [source] ¶","Returns NVCC gencode flags this library was compiled with. 
 Return type 
 str 
",,,,
"
 torch.cuda. get_sync_debug_mode ( ) [source] ¶","Returns current value of debug mode for cuda synchronizing operations. 
 Return type 
 int 
",,,,
"
 torch.cuda. init ( ) [source] ¶","Initialize PyTorch’s CUDA state.  You may need to call
this explicitly if you are interacting with PyTorch via
its C API, as Python bindings for CUDA functionality will not
be available until this initialization takes place.  Ordinary users
should not need this, as all of PyTorch’s CUDA methods
automatically initialize CUDA state on-demand. Does nothing if the CUDA state is already initialized.",,,,
"
 torch.cuda. ipc_collect ( ) [source] ¶","Force collects GPU memory after it has been released by CUDA IPC. 
 Note 
 Checks if any sent CUDA tensors could be cleaned from the memory. Force
closes shared memory file used for reference counting if there is no
active counters. Useful when the producer process stopped actively sending
tensors and want to release unused memory. 
",,,,
"
 torch.cuda. is_initialized ( ) [source] ¶",Returns whether PyTorch’s CUDA state has been initialized.,,,,
"
 torch.cuda. memory_usage ( device ) [source] ¶","Returns the percent of time over the past sample period during which global (device)
memory was being read or written. as given by  nvidia-smi . 
 Parameters 
 device 
 Return type 
 int 
 Warning: Each sample period may be between 1 second and 1/6 second,
depending on the product being queried.",,,,
"
 torch.cuda. set_stream ( stream ) [source] ¶","
 Sets the current stream.This is a wrapper API to set the stream. Usage of this function is discouraged in favor of the  
 
 Parameters 
 stream 
",,,,
"
 torch.cuda. set_sync_debug_mode ( debug_mode ) [source] ¶","Sets the debug mode for cuda synchronizing operations. 
 Parameters 
 debug_mode 
 
 Warning 
 This is an experimental feature, and not all synchronizing operations will trigger warning or error. In
particular, operations in torch.distributed and torch.sparse namespaces are not covered yet. 
",,,,
"
 torch.cuda. stream ( stream ) [source] ¶","Wrapper around the Context-manager StreamContext that
selects a given stream. 
 Parameters 
 stream 
 Return type 
 StreamContext 
 ..Note:: In eager mode stream is of type Stream class while in JIT it is
an object of the custom class  torch.classes.cuda.Stream .",,,,
"
 torch.cuda. synchronize ( device ) [source] ¶","Waits for all kernels in all streams on a CUDA device to complete. 
 Parameters 
 device 
",,,,
"
 torch.cuda. utilization ( device ) [source] ¶","Returns the percent of time over the past sample period during which one or
more kernels was executing on the GPU as given by  nvidia-smi . 
 Parameters 
 device 
 Return type 
 int 
 Warning: Each sample period may be between 1 second and 1/6 second,
depending on the product being queried.",,,,
"
 exception torch.cuda. OutOfMemoryError ¶",Exception raised when CUDA is out of memory,,,,
"
 torch.cuda. get_rng_state ( device ) [source] ¶","Returns the random number generator state of the specified GPU as a ByteTensor. 
 Parameters 
 device 
 Return type 
 Tensor 
 
 Warning 
 This function eagerly initializes CUDA. 
",,,,
"
 torch.cuda. get_rng_state_all ( ) [source] ¶","Returns a list of ByteTensor representing the random number states of all devices. 
 Return type 
 List 
",,,,
"
 torch.cuda. set_rng_state ( new_state ,  device ) [source] ¶","Sets the random number generator state of the specified GPU. 
 Parameters 
 
 
",,,,
"
 torch.cuda. set_rng_state_all ( new_states ) [source] ¶","Sets the random number generator state of all devices. 
 Parameters 
 new_states 
",,,,
"
 torch.cuda. manual_seed ( seed ) [source] ¶","Sets the seed for generating random numbers for the current GPU.
It’s safe to call this function if CUDA is not available; in that
case, it is silently ignored. 
 Parameters 
 seed 
 
 Warning 
 If you are working with a multi-GPU model, this function is insufficient
to get determinism.  To seed all GPUs, use  
",,,,
"
 torch.cuda. manual_seed_all ( seed ) [source] ¶","Sets the seed for generating random numbers on all GPUs.
It’s safe to call this function if CUDA is not available; in that
case, it is silently ignored. 
 Parameters 
 seed 
",,,,
"
 torch.cuda. seed ( ) [source] ¶","Sets the seed for generating random numbers to a random number for the current GPU.
It’s safe to call this function if CUDA is not available; in that
case, it is silently ignored. 
 Warning 
 If you are working with a multi-GPU model, this function will only initialize
the seed on one GPU.  To initialize all GPUs, use  
 
",,,,
"
 torch.cuda. seed_all ( ) [source] ¶","Sets the seed for generating random numbers to a random number on all GPUs.
It’s safe to call this function if CUDA is not available; in that
case, it is silently ignored. 
",,,,
"
 torch.cuda. initial_seed ( ) [source] ¶","Returns the current random seed of the current GPU. 
 Warning 
 This function eagerly initializes CUDA. 
 
 Return type 
 int 
",,,,
"
 torch.cuda.comm. broadcast ( tensor ,  devices ,  * ,  out ) [source] ¶","Broadcasts a tensor to specified GPU devices. 
 Parameters 
 
 
 
 Note 
 Exactly one of  
 
 Returns 
 
 
",,,,
"
 torch.cuda.comm. broadcast_coalesced ( tensors ,  devices ,  buffer_size ) [source] ¶","Broadcasts a sequence tensors to the specified GPUs.
Small tensors are first coalesced into a buffer to reduce the number
of synchronizations. 
 Parameters 
 
 
 Returns 
 A tuple containing copies of  
",,,,
"
 torch.cuda.comm. reduce_add ( inputs ,  destination ) [source] ¶","Sums tensors from multiple GPUs. All inputs should have matching shapes, dtype, and layout. The output tensor
will be of the same shape, dtype, and layout. 
 Parameters 
 
 
 Returns 
 A tensor containing an elementwise sum of all inputs, placed on the
 
",,,,
"
 torch.cuda.comm. scatter ( tensor ,  devices ,  chunk_sizes ,  dim ,  streams ,  * ,  out ) [source] ¶","Scatters tensor across multiple GPUs. 
 Parameters 
 
 
 
 Note 
 Exactly one of  
 
 Returns 
 
 
",,,,
"
 torch.cuda.comm. gather ( tensors ,  dim ,  destination ,  * ,  out ) [source] ¶","Gathers tensors from multiple GPU devices. 
 Parameters 
 
 
 
 Note 
 destination 
 
 Returns 
 
 
",,,,
"
 class torch.cuda. ExternalStream ( stream_ptr ,  device ,  ** ) [source] ¶","Wrapper around an externally allocated CUDA stream. This class is used to wrap streams allocated in other libraries in order
to facilitate data exchange and multi-library interactions. 
 Note 
 This class doesn’t manage the stream life-cycle, it is the user
responsibility to keep the referenced stream alive while this class is
being used. 
 
 Parameters 
 
 
 
 
 
 Checks if all the work submitted has been completed. 
 
 
 Records an event. 
 
 
 Wait for all the kernels in this stream to complete. 
 
 
 Makes all future work submitted to the stream wait for an event. 
 
 
 Synchronizes with another stream.",,,,
"
 class torch.cuda. Event ( enable_timing ,  blocking ,  interprocess ) [source] ¶","Wrapper around a CUDA event. CUDA events are synchronization markers that can be used to monitor the
device’s progress, to accurately measure timing, and to synchronize CUDA
streams. The underlying CUDA events are lazily initialized when the event is first
recorded or exported to another process. After creation, only streams on the
same device may record the event. However, streams on any device can wait on
the event. 
 Parameters 
 
 
 
 
 
 Returns the time elapsed in milliseconds after the event was
recorded and before the end_event was recorded. 
 
 
 Reconstruct an event from an IPC handle on the given device. 
 
 
 Returns an IPC handle of this event. If not recorded yet, the event
will use the current device. 
 
 
 Checks if all work currently captured by event has completed. 
 
 
 Records the event in a given stream. 
 
 
 Waits for the event to complete. 
 
 
 Makes all future work submitted to the given stream wait for this
event.",,,,
"
 torch.cuda. is_current_stream_capturing ( ) [source] ¶","Returns True if CUDA graph capture is underway on the current CUDA stream, False otherwise. If a CUDA context does not exist on the current device, returns False without initializing the context.",,,,
"
 torch.cuda. graph_pool_handle ( ) [source] ¶","Returns an opaque token representing the id of a graph memory pool.
See  Graph memory management . 
 Warning 
 This API is in beta and may change in future releases. 
",,,,
"
 class torch.cuda. CUDAGraph [source] ¶","Wrapper around a CUDA graph. 
 Warning 
 This API is in beta and may change in future releases. 
 
 
 
 Begins capturing CUDA work on the current stream. 
 
 
 Ends CUDA graph capture on the current stream.
After  
 
 
 Returns an opaque token representing the id of this graph’s memory pool.
This id can optionally be passed to another graph’s  
 
 
 Replays the CUDA work captured by this graph. 
 
 
 Deletes the graph currently held by this instance.",,,,
"
 class torch.cuda. graph ( cuda_graph ,  pool ,  stream ) [source] ¶","Context-manager that captures CUDA work into a  torch.cuda.CUDAGraph 
object for later replay. See  CUDA Graphs  for a general introduction,
detailed use, and constraints. 
 Parameters 
 
 
 
 Note 
 For effective memory sharing, if you pass a  
 
 Warning 
 This API is in beta and may change in future releases. 
",,,,
"
 torch.cuda. make_graphed_callables ( callables ,  sample_args ,  num_warmup_iters ) [source] ¶","Accepts callables (functions or  nn.Module s)
and returns graphed versions. Each graphed callable’s forward pass runs its source callable’s
forward CUDA work as a CUDA graph inside a single autograd node. The graphed callable’s forward pass also appends
a backward node to the autograd graph. During backward, this node runs the
callable’s backward work as a CUDA graph. Therefore, each graphed callable should be a drop-in replacement for its source callable
in an autograd-enabled training loop. See  Partial-network capture  for detailed use and constraints. If you pass a tuple of several callables, their captures will use the same memory pool.
See  Graph memory management  for when this is appropriate. 
 Parameters 
 
 
 
 Note 
 The  
 
 Warning 
 This API is in beta and may change in future releases. 
 
 Warning 
 sample_args 
 
 Warning 
 Returned callables do not support higher order differentiation (e.g., double backward). 
 
 Warning 
 In any  
 
 Warning 
 After you pass a  
 
 Warning 
 torch.nn.Module 
 
 Warning 
 When running a graphed callable, you must pass its arguments in the same order and format
they appeared in that callable’s  
 
 Warning 
 The automatic mixed precision is supported in  
 
 Warning 
 All Tensor outputs of graphed callables must require grad. 
",,,,
"
 torch.cuda. empty_cache ( ) [source] ¶","Releases all unoccupied cached memory currently held by the caching
allocator so that those can be used in other GPU application and visible in
 nvidia-smi . 
 Note 
 empty_cache() 
 
",,,,
"
 torch.cuda. list_gpu_processes ( device ) [source] ¶","Returns a human-readable printout of the running processes
and their GPU memory use for a given device. This can be useful to display periodically during training, or when
handling out-of-memory exceptions. 
 Parameters 
 device 
 Return type 
 str 
",,,,
"
 torch.cuda. mem_get_info ( device ) [source] ¶","Returns the global free and total GPU memory occupied for a given
device using cudaMemGetInfo. 
 Parameters 
 device 
 Return type 
 Tuple 
 
 Note 
 See  
",,,,
"
 torch.cuda. memory_stats ( device ) [source] ¶","Returns a dictionary of CUDA memory allocator statistics for a
given device. The return value of this function is a dictionary of statistics, each of
which is a non-negative integer. Core statistics: 
 ""allocated.{all,large_pool,small_pool}.{current,peak,allocated,freed}"" 
 ""allocated_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}"" 
 ""segment.{all,large_pool,small_pool}.{current,peak,allocated,freed}"" 
 ""reserved_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}"" 
 ""active.{all,large_pool,small_pool}.{current,peak,allocated,freed}"" 
 ""active_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}"" 
 ""inactive_split.{all,large_pool,small_pool}.{current,peak,allocated,freed}"" 
 ""inactive_split_bytes.{all,large_pool,small_pool}.{current,peak,allocated,freed}"" 
 For these core statistics, values are broken down as follows. Pool type: 
 all 
 large_pool 
 small_pool 
 Metric type: 
 current 
 peak 
 allocated 
 freed 
 In addition to the core statistics, we also provide some simple event
counters: 
 ""num_alloc_retries"" 
 ""num_ooms"" 
 The caching allocator can be configured via ENV to not split blocks larger than a
defined size (see Memory Management section of the Cuda Semantics documentation).
This helps avoid memory framentation but may have a performance
penalty. Additional outputs to assist with tuning and evaluating impact: 
 ""max_split_size"" 
 ""oversize_allocations.{current,peak,allocated,freed}"" 
 ""oversize_segments.{current,peak,allocated,freed}"" 
 
 Parameters 
 device 
 Return type 
 Dict 
 
 Note 
 See  
",,,,
"
 torch.cuda. memory_summary ( device ,  abbreviated ) [source] ¶","Returns a human-readable printout of the current memory allocator
statistics for a given device. This can be useful to display periodically during training, or when
handling out-of-memory exceptions. 
 Parameters 
 
 
 Return type 
 str 
 
 Note 
 See  
",,,,
"
 torch.cuda. memory_snapshot ( ) [source] ¶","Returns a snapshot of the CUDA memory allocator state across all devices. Interpreting the output of this function requires familiarity with the
memory allocator internals. 
 Note 
 See  
",,,,
"
 torch.cuda. memory_allocated ( device ) [source] ¶","Returns the current GPU memory occupied by tensors in bytes for a given
device. 
 Parameters 
 device 
 Return type 
 int 
 
 Note 
 This is likely less than the amount shown in  
",,,,
"
 torch.cuda. max_memory_allocated ( device ) [source] ¶","Returns the maximum GPU memory occupied by tensors in bytes for a given
device. By default, this returns the peak allocated memory since the beginning of
this program.  reset_peak_memory_stats()  can be used to
reset the starting point in tracking this metric. For example, these two
functions can measure the peak allocated memory usage of each iteration in a
training loop. 
 Parameters 
 device 
 Return type 
 int 
 
 Note 
 See  
",,,,
"
 torch.cuda. reset_max_memory_allocated ( device ) [source] ¶","Resets the starting point in tracking maximum GPU memory occupied by
tensors for a given device. See  max_memory_allocated()  for details. 
 Parameters 
 device 
 
 Warning 
 This function now calls  
 
 Note 
 See  
",,,,
"
 torch.cuda. memory_reserved ( device ) [source] ¶","Returns the current GPU memory managed by the caching allocator in bytes
for a given device. 
 Parameters 
 device 
 Return type 
 int 
 
 Note 
 See  
",,,,
"
 torch.cuda. max_memory_reserved ( device ) [source] ¶","Returns the maximum GPU memory managed by the caching allocator in bytes
for a given device. By default, this returns the peak cached memory since the beginning of this
program.  reset_peak_memory_stats()  can be used to reset
the starting point in tracking this metric. For example, these two functions
can measure the peak cached memory amount of each iteration in a training
loop. 
 Parameters 
 device 
 Return type 
 int 
 
 Note 
 See  
",,,,
"
 torch.cuda. set_per_process_memory_fraction ( fraction ,  device ) [source] ¶","Set memory fraction for a process.
The fraction is used to limit an caching allocator to allocated memory on a CUDA device.
The allowed value equals the total visible memory multiplied fraction.
If trying to allocate more than the allowed value in a process, will raise an out of
memory error in allocator. 
 Parameters 
 
 
 
 Note 
 In general, the total available free memory is less than the total capacity. 
",,,,
"
 torch.cuda. memory_cached ( device ) [source] ¶","Deprecated; see  memory_reserved() . 
 Return type 
 int 
",,,,
"
 torch.cuda. max_memory_cached ( device ) [source] ¶","Deprecated; see  max_memory_reserved() . 
 Return type 
 int 
",,,,
"
 torch.cuda. reset_max_memory_cached ( device ) [source] ¶","Resets the starting point in tracking maximum GPU memory managed by the
caching allocator for a given device. See  max_memory_cached()  for details. 
 Parameters 
 device 
 
 Warning 
 This function now calls  
 
 Note 
 See  
",,,,
"
 torch.cuda. reset_peak_memory_stats ( device ) [source] ¶","Resets the “peak” stats tracked by the CUDA memory allocator. See  memory_stats()  for details. Peak stats correspond to the
 “peak”  key in each individual stat dict. 
 Parameters 
 device 
 
 Note 
 See  
",,,,
"
 torch.cuda. caching_allocator_alloc ( size ,  device ,  stream ) [source] ¶","Performs a memory allocation using the CUDA memory allocator. Memory is allocated for a given device and a stream, this
function is intended to be used for interoperability with other
frameworks. Allocated memory is released through
 caching_allocator_delete() . 
 Parameters 
 
 
 
 Note 
 See  
",,,,
"
 torch.cuda. caching_allocator_delete ( mem_ptr ) [source] ¶","Deletes memory allocated using the CUDA memory allocator. Memory allocated with  caching_allocator_alloc() .
is freed here. The associated device and stream are tracked inside
the allocator. 
 Parameters 
 mem_ptr 
 
 Note 
 See  
",,,,
"
 torch.cuda.nvtx. mark ( msg ) [source] ¶","Describe an instantaneous event that occurred at some point. 
 Parameters 
 msg 
",,,,
"
 torch.cuda.nvtx. range_push ( msg ) [source] ¶","Pushes a range onto a stack of nested range span.  Returns zero-based
depth of the range that is started. 
 Parameters 
 msg 
",,,,
"
 torch.cuda.nvtx. range_pop ( ) [source] ¶","Pops a range off of a stack of nested range spans.  Returns the
zero-based depth of the range that is ended.",,,,
"
 torch.cuda.jiterator. _create_jit_fn ( code_string ,  ** ) [source] ¶","Create a jiterator-generated cuda kernel for an elementwise op. The code string has to be a valid CUDA function that describes the computation for a single element. The code
string has to follow the c++ template pattern, as shown in the example below. This function will be inlined
into elementwise kernel template, and compiled on the fly. Compiled kernel will be cached in memory, as well as
local temp dir. Jiterator-generated kernels accepts noncontiguous tensors, and supports boardcasting and type promotion. 
 Parameters 
 
 
 Return type 
 Callable 
 Example: 
 code_string also allows mulitple function definitions, and the last function will be treated as the entry function. Example: 
 Jiterator can be used together with python registration to override an operator’s cuda kernel.
Following example is overriding gelu’s cuda kernel with relu. Example: 
 
 Warning 
 This API is in beta and may change in future releases. 
 
 Warning 
 This API only supports up to 8 inputs and 1 output 
 
 Warning 
 All input tensors must live in CUDA device 
","code_string=""template <typename T> T my_kernel(T x, T y, T alpha) { return -x + alpha * y; }""
jitted_fn=create_jit_fn(code_string,alpha=1.0)
a=torch.rand(3,device='cuda')
b=torch.rand(3,device='cuda')
# invoke jitted function like a regular python function
result=jitted_fn(a,b,alpha=3.14)
","code_string=""template <typename T> T util_fn(T x, T y) { return ::sin(x) + ::cos(y); }""
code_string+=""template <typename T> T my_kernel(T x, T y, T val) { return ::min(val, util_fn(x, y)); }""
jitted_fn=create_jit_fn(code_string,val=0.0)
a=torch.rand(3,device='cuda')
b=torch.rand(3,device='cuda')
# invoke jitted function like a regular python function
result=jitted_fn(a,b)# using default val=0.0
","code_string=""template <typename T> T my_gelu(T a) { return a > 0 ? a : 0; }""
my_gelu=create_jit_fn(code_string)
my_lib=torch.library.Library(""aten"",""IMPL"")
my_lib.impl('aten::gelu',my_gelu,""CUDA"")
# torch.nn.GELU and torch.nn.function.gelu are now overridden
a=torch.rand(3,device='cuda')
torch.allclose(torch.nn.functional.gelu(a),torch.nn.functional.relu(a))
",
"
 torch.cuda.jiterator. _create_multi_output_jit_fn ( code_string ,  num_outputs ,  ** ) [source] ¶","Create a jiterator-generated cuda kernel for an elementwise op that supports returning one or more outputs. 
 Parameters 
 
 
 Return type 
 Callable 
 Example: 
 
 Warning 
 This API is in beta and may change in future releases. 
 
 Warning 
 This API only supports up to 8 inputs and 8 outputs 
","code_string=""template <typename T> void my_kernel(T x, T y, T alpha, T& out) { out = -x + alpha * y; }""
jitted_fn=create_jit_fn(code_string,alpha=1.0)
a=torch.rand(3,device='cuda')
b=torch.rand(3,device='cuda')
# invoke jitted function like a regular python function
result=jitted_fn(a,b,alpha=3.14)
",,,
"
 torch.linalg. inv_ex ( A ,  * ,  check_errors ,  out ) ¶","Computes the inverse of a square matrix if it is invertible. Returns a namedtuple  (inverse, .  inverse  contains the result of
inverting  A  and  info  stores the LAPACK error codes. If  A  is not an invertible matrix, or if it’s a batch of matrices
and one or more of them is not an invertible matrix,
then  info  stores a positive integer for the corresponding matrix.
The positive integer indicates the diagonal element of the LU decomposition of
the input matrix that is exactly zero.
 info  filled with zeros indicates that the inversion was successful.
If  check_errors=True  and  info  contains positive integers, then a RuntimeError is thrown. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. 
 Note 
 When the inputs are on a CUDA device, this function synchronizes only when  
 
 Warning 
 This function is “experimental” and it may change in a future PyTorch release. 
 
 See also 
 torch.linalg.inv() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Examples: 
",">>> A=torch.randn(3,3)
>>> Ainv,info=torch.linalg.inv_ex(A)
>>> torch.dist(torch.linalg.inv(A),Ainv)
tensor(0.)
>>> info
tensor(0, dtype=torch.int32)
",,,
"
 torch.linalg. cholesky ( A ,  * ,  upper ,  out )   → ¶","Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix. Letting  K  be  R  or  C ,
the  Cholesky decomposition  of a complex Hermitian or real symmetric positive-definite matrix
 A  is defined as 
 A where  L  is a lower triangular matrix with real positive diagonal (even in the complex case) and
 L  is the conjugate transpose when  L  is complex, and the transpose when  L  is real-valued. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU. 
 
 See also 
 torch.linalg.cholesky_ex() 
 torch.linalg.eigh() 
 
 Parameters 
 A 
 Keyword Arguments 
 
 
 Raises 
 RuntimeError 
 Examples: 
",">>> A=torch.randn(2,2,dtype=torch.complex128)
>>> A=A@A.T.conj()+torch.eye(2)# creates a Hermitian positive-definite matrix
>>> A
tensor([[2.5266+0.0000j, 1.9586-2.0626j],
        [1.9586+2.0626j, 9.4160+0.0000j]], dtype=torch.complex128)
>>> L=torch.linalg.cholesky(A)
>>> L
tensor([[1.5895+0.0000j, 0.0000+0.0000j],
        [1.2322+1.2976j, 2.4928+0.0000j]], dtype=torch.complex128)
>>> torch.dist(L@L.T.conj(),A)
tensor(4.4692e-16, dtype=torch.float64)>>> A=torch.randn(3,2,2,dtype=torch.float64)
>>> A=A@A.mT+torch.eye(2)# batch of symmetric positive-definite matrices
>>> L=torch.linalg.cholesky(A)
>>> torch.dist(L@L.mT,A)
tensor(5.8747e-16, dtype=torch.float64)
",,,
"
 torch.linalg. cholesky_ex ( A ,  * ,  upper ,  check_errors ,  out ) ¶","Computes the Cholesky decomposition of a complex Hermitian or real
symmetric positive-definite matrix. This function skips the (slow) error checking and error message construction
of  torch.linalg.cholesky() , instead directly returning the LAPACK
error codes as part of a named tuple  (L, . This makes this function
a faster way to check if a matrix is positive-definite, and it provides an
opportunity to handle decomposition errors more gracefully or performantly
than  torch.linalg.cholesky()  does. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. If  A  is not a Hermitian positive-definite matrix, or if it’s a batch of matrices
and one or more of them is not a Hermitian positive-definite matrix,
then  info  stores a positive integer for the corresponding matrix.
The positive integer indicates the order of the leading minor that is not positive-definite,
and the decomposition could not be completed.
 info  filled with zeros indicates that the decomposition was successful.
If  check_errors=True  and  info  contains positive integers, then a RuntimeError is thrown. 
 Note 
 When the inputs are on a CUDA device, this function synchronizes only when  
 
 Warning 
 This function is “experimental” and it may change in a future PyTorch release. 
 
 See also 
 torch.linalg.cholesky() 
 
 Parameters 
 A 
 Keyword Arguments 
 
 
 Examples: 
",">>> A=torch.randn(2,2,dtype=torch.complex128)
>>> A=A@A.t().conj()# creates a Hermitian positive-definite matrix
>>> L,info=torch.linalg.cholesky_ex(A)
>>> A
tensor([[ 2.3792+0.0000j, -0.9023+0.9831j],
        [-0.9023-0.9831j,  0.8757+0.0000j]], dtype=torch.complex128)
>>> L
tensor([[ 1.5425+0.0000j,  0.0000+0.0000j],
        [-0.5850-0.6374j,  0.3567+0.0000j]], dtype=torch.complex128)
>>> info
tensor(0, dtype=torch.int32)
",,,
"
 torch.linalg. lu ( A ,  * ,  pivot ,  out ) ¶","Computes the LU decomposition with partial pivoting of a matrix. Letting  K  be  R  or  C ,
the  LU decomposition with partial pivoting  of a matrix
 A  is defined as 
 A where  k = min(m,n) ,  P  is a  permutation matrix ,  L  is lower triangular with ones on the diagonal
and  U  is upper triangular. If  pivot = False  and  A  is on GPU, then the  LU decomposition without pivoting  is computed 
 A When  pivot = False , the returned matrix  P  will be empty.
The LU decomposition without pivoting  may not exist  if any of the principal minors of  A  is singular.
In this case, the output matrix may contain  inf  or  NaN . Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. 
 See also 
 torch.linalg.solve() 
 
 Warning 
 The LU decomposition is almost never unique, as often there are different permutation
matrices that can yield different LU decompositions.
As such, different platforms, like SciPy, or inputs on different devices,
may produce different valid decompositions. 
 
 Warning 
 Gradient computations are only supported if the input matrix is full-rank.
If this condition is not met, no error will be thrown, but the gradient
may not be finite.
This is because the LU decomposition with pivoting is not differentiable at these points. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A named tuple  
 Examples: 
",">>> A=torch.randn(3,2)
>>> P,L,U=torch.linalg.lu(A)
>>> P
tensor([[0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.]])
>>> L
tensor([[1.0000, 0.0000],
        [0.5007, 1.0000],
        [0.0633, 0.9755]])
>>> U
tensor([[0.3771, 0.0489],
        [0.0000, 0.9644]])
>>> torch.dist(A,P@L@U)
tensor(5.9605e-08)>>> A=torch.randn(2,5,7,device=""cuda"")
>>> P,L,U=torch.linalg.lu(A,pivot=False)
>>> P
tensor([], device='cuda:0')
>>> torch.dist(A,L@U)
tensor(1.0376e-06, device='cuda:0')
",,,
"
 torch.linalg. lu_solve ( LU ,  pivots ,  B ,  * ,  left ,  adjoint ,  out )   → ¶","Computes the solution of a square system of linear equations with a unique solution given an LU decomposition. Letting  K  be  R  or  C ,
this function computes the solution  X  of the  linear system  associated to
 A , which is defined as 
 A where  A  is given factorized as returned by  lu_factor() . If  left = False , this function returns the matrix  X  that solves the system 
 X If   adjoint = True  (and  left = True), given an LU factorization of :math:`A 
this function function returns the  X  that solves the system 
 A where  A  is the conjugate transpose when  A  is complex, and the
transpose when  A  is real-valued. The  left = False  case is analogous. Supports inputs of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if the inputs are batches of matrices then
the output has the same batch dimensions. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> A=torch.randn(3,3)
>>> LU,pivots=torch.linalg.lu_factor(A)
>>> B=torch.randn(3,2)
>>> X=torch.linalg.lu_solve(LU,pivots,B)
>>> torch.allclose(A@X,B)
True>>> B=torch.randn(3,3,2)# Broadcasting rules apply: A is broadcasted
>>> X=torch.linalg.lu_solve(LU,pivots,B)
>>> torch.allclose(A@X,B)
True>>> B=torch.randn(3,5,3)
>>> X=torch.linalg.lu_solve(LU,pivots,B,left=False)
>>> torch.allclose(X@A,B)
True>>> B=torch.randn(3,3,4)# Now solve for A^T
>>> X=torch.linalg.lu_solve(LU,pivots,B,adjoint=True)
>>> torch.allclose(A.mT@X,B)
True
",,,
"
 torch.linalg. qr ( A ,  mode ,  * ,  out ) ¶","Computes the QR decomposition of a matrix. Letting  K  be  R  or  C ,
the  full QR decomposition  of a matrix
 A  is defined as 
 A where  Q  is orthogonal in the real case and unitary in the complex case,
and  R  is upper triangular with real diagonal (even in the complex case). When  m > n  (tall matrix), as  R  is upper triangular, its last  m - n  rows are zero.
In this case, we can drop the last  m - n  columns of  Q  to form the
 reduced QR decomposition : 
 A The reduced QR decomposition agrees with the full QR decomposition when  n >= m  (wide matrix). Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. The parameter  mode  chooses between the full and reduced QR decomposition.
If  A  has shape  (*, m, n) , denoting  k = min(m, n) 
 mode 
 mode 
 mode 
 Differences with  numpy.linalg.qr : 
 mode 
 Unlike  
 
 Warning 
 The elements in the diagonal of  
 
 Warning 
 The QR decomposition is only well-defined if the first  
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A named tuple  
 Examples: 
",">>> A=torch.tensor([[12.,-51,4],[6,167,-68],[-4,24,-41]])
>>> Q,R=torch.linalg.qr(A)
>>> Q
tensor([[-0.8571,  0.3943,  0.3314],
        [-0.4286, -0.9029, -0.0343],
        [ 0.2857, -0.1714,  0.9429]])
>>> R
tensor([[ -14.0000,  -21.0000,   14.0000],
        [   0.0000, -175.0000,   70.0000],
        [   0.0000,    0.0000,  -35.0000]])
>>> (Q@R).round()
tensor([[  12.,  -51.,    4.],
        [   6.,  167.,  -68.],
        [  -4.,   24.,  -41.]])
>>> (Q.T@Q).round()
tensor([[ 1.,  0.,  0.],
        [ 0.,  1., -0.],
        [ 0., -0.,  1.]])
>>> Q2,R2=torch.linalg.qr(A,mode='r')
>>> Q2
tensor([])
>>> torch.equal(R,R2)
True
>>> A=torch.randn(3,4,5)
>>> Q,R=torch.linalg.qr(A,mode='complete')
>>> torch.dist(Q@R,A)
tensor(1.6099e-06)
>>> torch.dist(Q.mT@Q,torch.eye(4))
tensor(6.2158e-07)
",,,
"
 torch.linalg. eigh ( A ,  UPLO ,  * ,  out ) ¶","Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix. Letting  K  be  R  or  C ,
the  eigenvalue decomposition  of a complex Hermitian or real symmetric matrix
 A  is defined as 
 A where  Q  is the conjugate transpose when  Q  is complex, and the transpose when  Q  is real-valued.
 Q  is orthogonal in the real case and unitary in the complex case. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. A  is assumed to be Hermitian (resp. symmetric), but this is not checked internally, instead: 
 If  
 If  
 The eigenvalues are returned in ascending order. 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU. 
 
 Note 
 The eigenvalues of real symmetric or complex Hermitian matrices are always real. 
 
 Warning 
 The eigenvectors of a symmetric matrix are not unique, nor are they continuous with
respect to  
 This non-uniqueness is caused by the fact that multiplying an eigenvector by
 
 
 Warning 
 Gradients computed using the  
 
 See also 
 torch.linalg.eigvalsh() 
 torch.linalg.cholesky() 
 torch.linalg.eig() 
 torch.linalg.svd() 
 torch.linalg.qr() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A named tuple  
 
 Examples:: 
",,,,
"
 torch.linalg. svd ( A ,  full_matrices ,  * ,  driver ,  out ) ¶","Computes the singular value decomposition (SVD) of a matrix. Letting  K  be  R  or  C ,
the  full SVD  of a matrix
 A , if  k = min(m,n) , is defined as 
 A where  diag ,
 V  is the conjugate transpose when  V  is complex, and the transpose when  V  is real-valued.
The matrices   U ,  V  (and thus  V ) are orthogonal in the real case, and unitary in the complex case. When  m > n  (resp.  m < n ) we can drop the last  m - n  (resp.  n - m ) columns of  U  (resp.  V ) to form the  reduced SVD : 
 A where  diag .
In this case,  U  and  V  also have orthonormal columns. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. The returned decomposition is a named tuple  (U, S, Vh) 
which corresponds to  U ,  S ,  V  above. The singular values are returned in descending order. The parameter  full_matrices  chooses between the full (default) and reduced SVD. The  driver  kwarg may be used in CUDA with a cuSOLVER backend to choose the algorithm used to compute the SVD.
The choice of a driver is a trade-off between accuracy and speed. 
 If  
 If  
 By default ( driver = None ), we call  ‘gesvdj’  and, if it fails, we fallback to  ‘gesvd’ . Differences with  numpy.linalg.svd : 
 Unlike  
 
 Note 
 When  
 
 Warning 
 The returned tensors  
 This non-uniqueness is caused by the fact that multiplying any pair of singular
vectors  
 
 Warning 
 Gradients computed using  
 
 See also 
 torch.linalg.svdvals() 
 torch.linalg.eig() 
 torch.linalg.eigh() 
 torch.linalg.qr() 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A named tuple  
 Examples: 
",">>> A=torch.randn(5,3)
>>> U,S,Vh=torch.linalg.svd(A,full_matrices=False)
>>> U.shape,S.shape,Vh.shape
(torch.Size([5, 3]), torch.Size([3]), torch.Size([3, 3]))
>>> torch.dist(A,U@torch.diag(S)@Vh)
tensor(1.0486e-06)>>> U,S,Vh=torch.linalg.svd(A)
>>> U.shape,S.shape,Vh.shape
(torch.Size([5, 5]), torch.Size([3]), torch.Size([3, 3]))
>>> torch.dist(A,U[:,:3]@torch.diag(S)@Vh)
tensor(1.0486e-06)>>> A=torch.randn(7,5,3)
>>> U,S,Vh=torch.linalg.svd(A,full_matrices=False)
>>> torch.dist(A,U@torch.diag_embed(S)@Vh)
tensor(3.0957e-06)
",,,
"
 torch.linalg. svdvals ( A ,  * ,  driver ,  out )   → ¶","Computes the singular values of a matrix. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. The singular values are returned in descending order. 
 Note 
 This function is equivalent to NumPy’s  
 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU. 
 
 See also 
 torch.linalg.svd() 
 
 Parameters 
 A 
 Keyword Arguments 
 
 
 Returns 
 A real-valued tensor, even when  
 Examples: 
",">>> A=torch.randn(5,3)
>>> S=torch.linalg.svdvals(A)
>>> S
tensor([2.5139, 2.1087, 1.1066])>>> torch.dist(S,torch.linalg.svd(A,full_matrices=False).S)
tensor(2.4576e-07)
",,,
"
 Optimizer. state_dict ( ) [source] ¶","Returns the state of the optimizer as a  dict . It contains two entries: 
 
 
 
 
",,,,
"
 Optimizer. step ( closure ) [source] ¶","Performs a single optimization step (parameter update). 
 Parameters 
 closure 
 
 Note 
 Unless otherwise specified, this function should not modify the
 
",,,,
"
 torch.fft. fft ( input ,  n ,  dim ,  norm ,  * ,  out )   → ¶","Computes the one dimensional discrete Fourier transform of  input . 
 Note 
 The Fourier domain representation of any real signal satisfies the
Hermitian property:  
 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimension. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 
",,,,
"
 torch.fft. ifft ( input ,  n ,  dim ,  norm ,  * ,  out )   → ¶","Computes the one dimensional inverse discrete Fourier transform of  input . 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimension. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
",,,,
"
 torch.fft. fft2 ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the 2 dimensional discrete Fourier transform of  input .
Equivalent to  fftn()  but FFTs only the last two dimensions by default. 
 Note 
 The Fourier domain representation of any real signal satisfies the
Hermitian property:  
 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 The discrete Fourier transform is separable, so  fft2() 
here is equivalent to two one-dimensional  fft()  calls: 
",,,,
"
 torch.fft. ifft2 ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the 2 dimensional inverse discrete Fourier transform of  input .
Equivalent to  ifftn()  but IFFTs only the last two dimensions by default. 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 The discrete Fourier transform is separable, so  ifft2() 
here is equivalent to two one-dimensional  ifft()  calls: 
",,,,
"
 torch.fft. fftn ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the N dimensional discrete Fourier transform of  input . 
 Note 
 The Fourier domain representation of any real signal satisfies the
Hermitian property:  
 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 The discrete Fourier transform is separable, so  fftn() 
here is equivalent to two one-dimensional  fft()  calls: 
",,,,
"
 torch.fft. ifftn ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the N dimensional inverse discrete Fourier transform of  input . 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 The discrete Fourier transform is separable, so  ifftn() 
here is equivalent to two one-dimensional  ifft()  calls: 
",,,,
"
 torch.fft. rfft ( input ,  n ,  dim ,  norm ,  * ,  out )   → ¶","Computes the one dimensional Fourier transform of real-valued  input . The FFT of a real signal is Hermitian-symmetric,  X[i]  so
the output contains only the positive frequencies below the Nyquist frequency.
To compute the full output, use  fft() 
 Note 
 Supports torch.half on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimension. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 Compare against the full output from  fft() : 
 Notice that the symmetric element  T[-1]  is omitted.
At the Nyquist frequency  T[-2]  is it’s own symmetric pair,
and therefore must always be real-valued.",,,,
"
 torch.fft. irfft ( input ,  n ,  dim ,  norm ,  * ,  out )   → ¶","Computes the inverse of  rfft() . input  is interpreted as a one-sided Hermitian signal in the Fourier
domain, as produced by  rfft() . By the Hermitian property, the
output will be real-valued. 
 Note 
 Some input frequencies must be real-valued to satisfy the Hermitian
property. In these cases the imaginary component will be ignored.
For example, any imaginary component in the zero-frequency term cannot
be represented in a real output and so will always be ignored. 
 
 Note 
 The correct interpretation of the Hermitian input depends on the length of
the original data, as given by  
 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimension.
With default arguments, size of the transformed dimension should be (2^n + 1) as argument
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 Without specifying the output length to  irfft() , the output
will not round-trip properly because the input is odd-length: 
 So, it is recommended to always pass the signal length  n : 
",,,,
"
 torch.fft. rfft2 ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the 2-dimensional discrete Fourier transform of real  input .
Equivalent to  rfftn()  but FFTs only the last two dimensions by default. The FFT of a real signal is Hermitian-symmetric,  X[i, ,
so the full  fft2()  output contains redundant information.
 rfft2()  instead omits the negative frequencies in the last
dimension. 
 Note 
 Supports torch.half on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 Compared against the full output from  fft2() , we have all
elements up to the Nyquist frequency. 
 The discrete Fourier transform is separable, so  rfft2() 
here is equivalent to a combination of  fft()  and
 rfft() : 
",,,,
"
 torch.fft. irfft2 ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the inverse of  rfft2() .
Equivalent to  irfftn()  but IFFTs only the last two dimensions by default. input  is interpreted as a one-sided Hermitian signal in the Fourier
domain, as produced by  rfft2() . By the Hermitian property, the
output will be real-valued. 
 Note 
 Some input frequencies must be real-valued to satisfy the Hermitian
property. In these cases the imaginary component will be ignored.
For example, any imaginary component in the zero-frequency term cannot
be represented in a real output and so will always be ignored. 
 
 Note 
 The correct interpretation of the Hermitian input depends on the length of
the original data, as given by  
 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions.
With default arguments, the size of last dimension should be (2^n + 1) as argument
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 Without specifying the output length to  irfft2() , the output
will not round-trip properly because the input is odd-length in the last
dimension: 
 So, it is recommended to always pass the signal shape  s . 
",,,,
"
 torch.fft. rfftn ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the N-dimensional discrete Fourier transform of real  input . The FFT of a real signal is Hermitian-symmetric,
 X[i_1,  so the full
 fftn()  output contains redundant information.
 rfftn()  instead omits the negative frequencies in the
last dimension. 
 Note 
 Supports torch.half on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 Compared against the full output from  fftn() , we have all
elements up to the Nyquist frequency. 
 The discrete Fourier transform is separable, so  rfftn() 
here is equivalent to a combination of  fft()  and
 rfft() : 
",,,,
"
 torch.fft. irfftn ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the inverse of  rfftn() . input  is interpreted as a one-sided Hermitian signal in the Fourier
domain, as produced by  rfftn() . By the Hermitian property, the
output will be real-valued. 
 Note 
 Some input frequencies must be real-valued to satisfy the Hermitian
property. In these cases the imaginary component will be ignored.
For example, any imaginary component in the zero-frequency term cannot
be represented in a real output and so will always be ignored. 
 
 Note 
 The correct interpretation of the Hermitian input depends on the length of
the original data, as given by  
 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions.
With default arguments, the size of last dimension should be (2^n + 1) as argument
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 Without specifying the output length to  irfft() , the output
will not round-trip properly because the input is odd-length in the last
dimension: 
 So, it is recommended to always pass the signal shape  s . 
",,,,
"
 torch.fft. hfft ( input ,  n ,  dim ,  norm ,  * ,  out )   → ¶","Computes the one dimensional discrete Fourier transform of a Hermitian
symmetric  input  signal. 
 Note 
 hfft() 
 
 Note 
 Because the signal is Hermitian in the time-domain, the result will be
real in the frequency domain. Note that some input frequencies must be
real-valued to satisfy the Hermitian property. In these cases the imaginary
component will be ignored. For example, any imaginary component in
 
 
 Note 
 The correct interpretation of the Hermitian input depends on the length of
the original data, as given by  
 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimension.
With default arguments, size of the transformed dimension should be (2^n + 1) as argument
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example Taking a real-valued frequency signal and bringing it into the time domain
gives Hermitian symmetric output: 
 Note that  T[1]  and  T[2]  is
redundant. We can thus compute the forward transform without considering
negative frequencies: 
 Like with  irfft() , the output length must be given in order
to recover an even length output: 
",,,,
"
 torch.fft. ihfft ( input ,  n ,  dim ,  norm ,  * ,  out )   → ¶","Computes the inverse of  hfft() . input  must be a real-valued signal, interpreted in the Fourier domain.
The IFFT of a real signal is Hermitian-symmetric,  X[i] .
 ihfft()  represents this in the one-sided form where only the
positive frequencies below the Nyquist frequency are included. To compute the
full output, use  ifft() . 
 Note 
 Supports torch.half on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimension. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 Compare against the full output from  ifft() : 
",,,,
"
 torch.fft. hfft2 ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the 2-dimensional discrete Fourier transform of a Hermitian symmetric
 input  signal. Equivalent to  hfftn()  but only
transforms the last two dimensions by default. input  is interpreted as a one-sided Hermitian signal in the time
domain. By the Hermitian property, the Fourier transform will be real-valued. 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions.
With default arguments, the size of last dimension should be (2^n + 1) as argument
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example Starting from a real frequency-space signal, we can generate a
Hermitian-symmetric time-domain signal:
>>> T = torch.rand(10, 9)
>>> t = torch.fft.ihfft2(T) Without specifying the output length to  hfftn() , the
output will not round-trip properly because the input is odd-length in the
last dimension: 
 So, it is recommended to always pass the signal shape  s . 
",,,,
"
 torch.fft. ihfft2 ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the 2-dimensional inverse discrete Fourier transform of real
 input . Equivalent to  ihfftn()  but transforms only the
two last dimensions by default. 
 Note 
 Supports torch.half on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 Compared against the full output from  ifft2() , the
Hermitian time-space signal takes up only half the space. 
 The discrete Fourier transform is separable, so  ihfft2() 
here is equivalent to a combination of  ifft()  and
 ihfft() : 
",,,,
"
 torch.fft. hfftn ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the n-dimensional discrete Fourier transform of a Herimitian symmetric
 input  signal. input  is interpreted as a one-sided Hermitian signal in the time
domain. By the Hermitian property, the Fourier transform will be real-valued. 
 Note 
 hfftn() 
 
 Note 
 Some input frequencies must be real-valued to satisfy the Hermitian
property. In these cases the imaginary component will be ignored.
For example, any imaginary component in the zero-frequency term cannot
be represented in a real output and so will always be ignored. 
 
 Note 
 The correct interpretation of the Hermitian input depends on the length of
the original data, as given by  
 
 Note 
 Supports torch.half and torch.chalf on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions.
With default arguments, the size of last dimension should be (2^n + 1) as argument
 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example Starting from a real frequency-space signal, we can generate a
Hermitian-symmetric time-domain signal:
>>> T = torch.rand(10, 9)
>>> t = torch.fft.ihfftn(T) Without specifying the output length to  hfftn() , the
output will not round-trip properly because the input is odd-length in the
last dimension: 
 So, it is recommended to always pass the signal shape  s . 
",,,,
"
 torch.fft. ihfftn ( input ,  s ,  dim ,  norm ,  * ,  out )   → ¶","Computes the N-dimensional inverse discrete Fourier transform of real  input . input  must be a real-valued signal, interpreted in the Fourier domain.
The n-dimensional IFFT of a real signal is Hermitian-symmetric,
 X[i, .  ihfftn()  represents
this in the one-sided form where only the positive frequencies below the
Nyquist frequency are included in the last signal dimension. To compute the
full output, use  ifftn() . 
 Note 
 Supports torch.half on CUDA with GPU Architecture SM53 or greater.
However it only supports powers of 2 signal length in every transformed dimensions. 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
 Compared against the full output from  ifftn() , we have all
elements up to the Nyquist frequency. 
 The discrete Fourier transform is separable, so  ihfftn() 
here is equivalent to a combination of  ihfft()  and
 ifft() : 
",,,,
"
 torch.fft. fftfreq ( n ,  d ,  * ,  out ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Computes the discrete Fourier Transform sample frequencies for a signal of size  n . 
 Note 
 By convention,  
 
 
 Note 
 For even lengths, the Nyquist frequency at  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example 
 For even input, we can see the Nyquist frequency at  f[2]  is given as
negative: 
",,,,
"
 torch.fft. rfftfreq ( n ,  d ,  * ,  out ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Computes the sample frequencies for  rfft()  with a signal of size  n . 
 Note 
 rfft() 
 
 
 Note 
 For even lengths, the Nyquist frequency at  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Example 
 
 Compared to the output from  fftfreq() , we see that the
Nyquist frequency at  f[2]  has changed sign:
>>> torch.fft.fftfreq(4)
tensor([ 0.0000,  0.2500, -0.5000, -0.2500])",,,,
"
 torch.fft. fftshift ( input ,  dim )   → ¶","Reorders n-dimensional FFT data, as provided by  fftn() , to have
negative frequency terms first. This performs a periodic shift of n-dimensional data such that the origin
 (0,  is moved to the center of the tensor. Specifically, to
 input.shape[dim]  in each selected dimension. 
 Note 
 By convention, the FFT returns positive frequency terms first, followed by
the negative frequencies in reverse order, so that  
 
 Note 
 For even lengths, the Nyquist frequency at  
 
 Parameters 
 
 
 Example 
 
 Also notice that the Nyquist frequency term at  f[2]  was moved to the
beginning of the tensor. This also works for multi-dimensional transforms: 
 
 fftshift()  can also be useful for spatial data. If our
data is defined on a centered grid ( [-(N//2), ) then we can
use the standard FFT defined on an uncentered grid ( [0, ) by first
applying an  ifftshift() . 
 Similarly, we can convert the frequency domain components to centered
convention by applying  fftshift() . 
 The inverse transform, from centered Fourier space back to centered spatial
data, can be performed by applying the inverse shifts in reverse order: 
",,,,
"
 torch.fft. ifftshift ( input ,  dim )   → ¶","Inverse of  fftshift() . 
 Parameters 
 
 
 Example 
 A round-trip through  fftshift()  and
 ifftshift()  gives the same result: 
",,,,
"
 torch.jit. script ( obj ,  optimize ,  _frames_up ,  _rcb ,  example_inputs ) [source] ¶","Scripting a function or  nn.Module  will inspect the source code, compile
it as TorchScript code using the TorchScript compiler, and return a  ScriptModule  or
 ScriptFunction . TorchScript itself is a subset of the Python language, so not all
features in Python work, but we provide enough functionality to compute on
tensors and do control-dependent operations. For a complete guide, see the
 TorchScript Language Reference . Scripting a dictionary or list copies the data inside it into a TorchScript instance than can be
subsequently passed by reference between Python and TorchScript with zero copy overhead. 
 torch.jit.script and as a decorator  
 
 Parameters 
 
 
 Returns 
 If  
 
 Scripting a function The  
 **Scripting a function using example_inputs Example inputs can be used to annotate a function arguments. 
 Scripting an nn.Module Scripting an  
",,,,
"
 class torch.jit. ScriptModule [source] ¶","A wrapper around C++  torch::jit::Module .  ScriptModule s
contain methods, attributes, parameters, and
constants. These can be accessed the same way as on a normal  nn.Module . 
 
 
 Adds a child module to the current module. 
 
 
 Applies  
 
 
 Casts all floating point parameters and buffers to  
 
 
 Returns an iterator over module buffers. 
 
 
 Returns an iterator over immediate children modules. 
 
 
 Returns a pretty-printed representation (as valid Python syntax) of
the internal graph for the  
 
 
 Returns a tuple of: 
 
 
 Moves all model parameters and buffers to the CPU. 
 
 
 Moves all model parameters and buffers to the GPU. 
 
 
 Casts all floating point parameters and buffers to  
 
 
 Sets the module in evaluation mode. 
 
 
 Set the extra representation of the module 
 
 
 Casts all floating point parameters and buffers to  
 
 
 Returns the buffer given by  
 
 
 Returns any extra state to include in the module’s state_dict.
Implement this and a corresponding  
 
 
 Returns the parameter given by  
 
 
 Returns the submodule given by  
 
 
 Returns a string representation of the internal graph for the
 
 
 
 Casts all floating point parameters and buffers to  
 
 
 Returns a string representation of the internal graph for the
 
 
 
 Moves all model parameters and buffers to the IPU. 
 
 
 Copies parameters and buffers from  
 
 
 Returns an iterator over all modules in the network. 
 
 
 Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself. 
 
 
 Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself. 
 
 
 Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself. 
 
 
 Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself. 
 
 
 Returns an iterator over module parameters. 
 
 
 Registers a backward hook on the module. 
 
 
 Adds a buffer to the module. 
 
 
 Registers a forward hook on the module. 
 
 
 Registers a forward pre-hook on the module. 
 
 
 Registers a backward hook on the module. 
 
 
 Registers a post hook to be run after module’s  
 
 
 Alias for  
 
 
 Adds a parameter to the module. 
 
 
 Change if autograd should record operations on parameters in this
module. 
 
 
 See  
 
 
 This function is called from  
 
 
 See  
 
 
 Returns a dictionary containing references to the whole state of the module. 
 
 
 Moves and/or casts the parameters and buffers. 
 
 
 Moves the parameters and buffers to the specified device without copying storage. 
 
 
 Sets the module in training mode. 
 
 
 Casts all parameters and buffers to  
 
 
 Moves all model parameters and buffers to the XPU. 
 
 
 Sets gradients of all model parameters to zero. See similar function
under ",,,,
"
 class torch.jit. ScriptFunction ¶","Functionally equivalent to a  ScriptModule , but represents a single
function and does not have any attributes or Parameters. 
 
 
 
 
 
 
 
 
",,,,
"
 torch.jit. trace ( func ,  example_inputs ,  optimize=None ,  check_trace=True ,  check_inputs=None ,  check_tolerance=1e-05 ,  strict=True ,  _force_outplace=False ,  _module_class=None ,  _compilation_unit=<torch.jit.CompilationUnit ) [source] ¶","Trace a function and return an executable  or  ScriptFunction 
that will be optimized using just-in-time compilation. Tracing is ideal for
code that operates only on  Tensor s and lists, dictionaries, and
tuples of  Tensor s. Using  torch.jit.trace  and  torch.jit.trace_module , you can turn an
existing module or Python function into a TorchScript
 ScriptFunction  or  ScriptModule . You must provide example
inputs, and we run the function, recording the operations performed on all
the tensors. 
 The resulting recording of a standalone function produces  
 The resulting recording of  
 This module also contains any parameters that the original
module had as well. 
 Warning 
 Tracing only correctly records functions and modules which are not data
dependent (e.g., do not have conditionals on data in tensors) and do not have
any untracked external dependencies (e.g., perform input/output or
access global variables). Tracing only records operations done when the given
function is run on the given tensors. Therefore, the returned
 
 
 
 In cases like these, tracing would not be appropriate and
 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 If  
 Example (tracing a function): 
 Example (tracing an existing module): 
",,,,
"
 torch.jit. script_if_tracing ( fn ) [source] ¶","Compiles  fn  when it is first called during tracing.  torch.jit.script 
has a non-negligible start up time when it is first called due to
lazy-initializations of many compiler builtins. Therefore you should not use
it in library code. However, you may want to have parts of your library work
in tracing even if they use control flow. In these cases, you should use
 @torch.jit.script_if_tracing  to substitute for
 torch.jit.script . 
 Parameters 
 fn 
 Returns 
 If called during tracing, a  
",,,,
"
 torch.jit. trace_module ( mod ,  inputs ,  optimize=None ,  check_trace=True ,  check_inputs=None ,  check_tolerance=1e-05 ,  strict=True ,  _force_outplace=False ,  _module_class=None ,  _compilation_unit=<torch.jit.CompilationUnit ) [source] ¶","Trace a module and return an executable  ScriptModule  that will be optimized
using just-in-time compilation. When a module is passed to  torch.jit.trace , only
the  forward  method is run and traced. With  trace_module , you can specify a dictionary of
method names to example inputs to trace (see the  inputs ) argument below. See  torch.jit.trace  for more information on tracing. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A  
 Example (tracing a module with multiple methods): 
",,,,
"
 torch.jit. fork ( func ,  * ,  ** ) [source] ¶","Creates an asynchronous task executing  func  and a reference to the value
of the result of this execution.  fork  will return immediately,
so the return value of  func  may not have been computed yet. To force completion
of the task and access the return value invoke  torch.jit.wait  on the Future.  fork  invoked
with a  func  which returns  T  is typed as  torch.jit.Future[T] .  fork  calls can be arbitrarily
nested, and may be invoked with positional and keyword arguments.
Asynchronous execution will only occur when run in TorchScript. If run in pure python,
 fork  will not execute in parallel.  fork  will also not execute in parallel when invoked
while tracing, however the  fork  and  wait  calls will be captured in the exported IR Graph. 
 Warning 
 fork 
 
 Parameters 
 
 
 Returns 
 a reference to the execution of  
 Return type 
 torch.jit.Future[T] 
 Example (fork a free function): 
 Example (fork a module method): 
",,,,
"
 torch.jit. wait ( future ) [source] ¶","Forces completion of a  torch.jit.Future[T]  asynchronous task, returning the
result of the task. See  fork()  for docs and examples.
:param func: an asynchronous task reference, created through  torch.jit.fork 
:type func: torch.jit.Future[T] 
 Returns 
 the return value of the the completed task 
 Return type 
 T 
",,,,
"
 torch.jit. freeze ( mod ,  preserved_attrs ,  optimize_numerics ) [source] ¶","Freezing a  ScriptModule  will clone it and attempt to inline the cloned
module’s submodules, parameters, and attributes as constants in the TorchScript IR Graph.
By default,  forward  will be preserved, as well as attributes & methods specified in
 preserved_attrs . Additionally, any attribute that is modified within a preserved
method will be preserved. Freezing currently only accepts ScriptModules that are in eval mode. Freezing applies generic optimization that will speed up your model regardless of machine.
To further optimize using server-specific settings, run  optimize_for_inference  after
freezing. 
 Parameters 
 
 
 Returns 
 Frozen  
 Example (Freezing a simple module with a Parameter): 
 Example (Freezing a module with preserved attributes) 
 
 Note 
 Freezing submodule attributes is also supported:
frozen_module = torch.jit.freeze(scripted_module, preserved_attrs=[“submodule.version”]) 
 
 Note 
 If you’re not sure why an attribute is not being inlined as a constant, you can run
 
 
 Note 
 Because freezing makes weights constants and removes module hierarchy,  
",,,,
"
 torch.jit. optimize_for_inference ( mod ,  other_methods ) [source] ¶","Performs a set of optimization passes to optimize a model for the
purposes of inference. If the model is not already frozen, optimize_for_inference
will invoke  torch.jit.freeze  automatically. In addition to generic optimizations that should speed up your model regardless
of environment, prepare for inference will also bake in build specific settings
such as the presence of CUDNN or MKLDNN, and may in the future make transformations
which speed things up on one machine but slow things down on another. Accordingly,
serialization is not implemented following invoking  optimize_for_inference  and
is not guaranteed. This is still in prototype, and may have the potential to slow down your model.
Primary use cases that have been targeted so far have been vision models on cpu
and gpu to a lesser extent. Example (optimizing a module with Conv->Batchnorm): 
 
 Return type 
 ScriptModule 
",,,,
"
 torch.jit. enable_onednn_fusion ( enabled ) [source] ¶","Enables or disables onednn JIT fusion based on the parameter  enabled . 
",,,,
"
 torch.jit. onednn_fusion_enabled ( ) [source] ¶",Returns whether onednn JIT fusion is enabled,,,,
"
 torch.jit. set_fusion_strategy ( strategy ) [source] ¶","Sets the type and number of specializations that can occur during fusion. Usage: provide a list of pairs (type, depth) where type is one of “STATIC” or “DYNAMIC”
and depth is an integer. 
 Behavior - static vs dynamic: In STATIC fusion, fused ops are compiled to have fixed input shapes. The shape is determined
based on some initial profiling runs.
In DYNAMIC fusion, fused ops are compiled to have variable input shapes, so that multiple
shapes are possible. 
 In both cases, we also recompile on new striding behavior, device, or dtype. 
 Behavior - fallback functions & depth: When an input doesn’t match the format required by the specialized compiled op, it will run
a fallback function. Fallback functions are recursively be compiled and specialized based
on the observed tensor shapes. Since compilation can be slow, the “depth” parameter is provided to
limit the number of specializations that can be compiled, before giving up on recompiling and
falling back to a completely un-fused, un-specialized implementation. 
 The list of (type, depth) pairs controls the type of specializations and the number of
specializations. For example: [(“STATIC”, 2), (“DYNAMIC”, 2)] indicates that the first
two specializations will use static fusions, the following two specializations will use
dynamic fusion, and any inputs that satisfy none of the 4 options will run an
unfused implementation. NB: in the future, if more as more fusion backends are added there may be more granular
apis for specific fusers. 
",,,,
"
 class torch.jit. strict_fusion [source] ¶","This class errors if not all nodes have been fused in
inference, or symbolically differentiated in training. Example: Forcing fusion of additions. 
",,,,
"
 torch.jit. save ( m ,  f ,  _extra_files ) [source] ¶","Save an offline version of this module for use in a separate process. The
saved module serializes all of the methods, submodules, parameters, and
attributes of this module. It can be loaded into the C++ API using
 torch::jit::load(filename)  or into the Python API with
 torch.jit.load . To be able to save a module, it must not make any calls to native Python
functions.  This means that all submodules must be subclasses of
 ScriptModule  as well. 
 Danger 
 All modules, no matter their device, are always loaded onto the CPU
during loading.  This is different from  
 
 Parameters 
 
 
 
 Note 
 torch.jit.save attempts to preserve the behavior of some operators
across versions. For example, dividing two integer tensors in
PyTorch 1.5 performed floor division, and if the module
containing that code is saved in PyTorch 1.5 and loaded in PyTorch 1.6
its division behavior will be preserved. The same module saved in
PyTorch 1.6 will fail to load in PyTorch 1.5, however, since the
behavior of division changed in 1.6, and 1.5 does not know how to
replicate the 1.6 behavior. 
 Example: 
",,,,
"
 torch.jit. load ( f ,  map_location ,  _extra_files ) [source] ¶","Load a  ScriptModule  or  ScriptFunction  previously
saved with  torch.jit.save All previously saved modules, no matter their device, are first loaded onto CPU,
and then are moved to the devices they were saved from. If this fails (e.g.
because the run time system doesn’t have certain devices), an exception is
raised. 
 Parameters 
 
 
 Returns 
 A  
 Example: 
",,,,
"
 torch.jit. ignore ( drop ,  ** ) [source] ¶","This decorator indicates to the compiler that a function or method should
be ignored and left as a Python function. This allows you to leave code in
your model that is not yet TorchScript compatible. If called from TorchScript,
ignored functions will dispatch the call to the Python interpreter. Models with ignored
functions cannot be exported; use  @torch.jit.unused  instead. Example (using  @torch.jit.ignore  on a method): 
 Example (using  @torch.jit.ignore(drop=True)  on a method): 
",,,,
"
 torch.jit. unused ( fn ) [source] ¶","This decorator indicates to the compiler that a function or method should
be ignored and replaced with the raising of an exception. This allows you
to leave code in your model that is not yet TorchScript compatible and still
export your model. 
 Example (using ",,,,
"
 torch.jit. isinstance ( obj ,  target_type ) [source] ¶","This function provides for container type refinement in TorchScript. It can refine
parameterized containers of the List, Dict, Tuple, and Optional types. E.g.  List[str] ,
 Dict[str, ,  Optional[Tuple[int,str,int]] . It can also
refine basic types such as bools and ints that are available in TorchScript. 
 Parameters 
 
 
 Returns 
 
 
 Return type 
 bool 
 Example (using  torch.jit.isinstance  for type refinement):
.. testcode: 
",,,,
"
 class torch.jit. Attribute ( value ,  type ) [source] ¶","This method is a pass-through function that returns  value , mostly
used to indicate to the TorchScript compiler that the left-hand side
expression is a class instance attribute with type of  type . Note that
 torch.jit.Attribute  should only be used in  __init__  method of  jit.ScriptModule 
subclasses. Though TorchScript can infer correct type for most Python expressions, there are some cases where
type inference can be wrong, including: 
 Empty containers like  
 Optional types like  
 In eager mode, it is simply a pass-through function that returns  value 
without other implications. Example: 
 Note: it’s now preferred to instead use type annotations instead of  torch.jit.Annotate : 
 
 Parameters 
 
 
 Returns 
 Returns  
 
 
 
 Return number of occurrences of value. 
 
 
 Return first index of value. 
 
 
 Alias for field number 1 
 
 
 Alias for field number 0",,,,
"
 torch.jit. annotate ( the_type ,  the_value ) [source] ¶","This method is a pass-through function that returns  the_value , used to hint TorchScript
compiler the type of  the_value . It is a no-op when running outside of TorchScript. Though TorchScript can infer correct type for most Python expressions, there are some cases where
type inference can be wrong, including: 
 Empty containers like  
 Optional types like  
 Note that  annotate()  does not help in  __init__  method of  torch.nn.Module  subclasses because it
is executed in eager mode. To annotate types of  torch.nn.Module  attributes,
use  Annotate()  instead. Example: 
 
 Parameters 
 
 
 Returns 
 the_value 
",,,,
"
 torch.linalg. norm ( A ,  ord ,  dim ,  keepdim ,  * ,  out ,  dtype )   → ¶","Computes a vector or matrix norm. Supports input of float, double, cfloat and cdouble dtypes. Whether this function computes a vector or matrix norm is determined as follows: 
 If  
 If  
 If  
 If  
 ord  defines the norm that is computed. The following norms are supported: 
 
 
 
 
 where  inf  refers to  float(‘inf’) , NumPy’s  inf  object, or any equivalent object. 
 See also 
 torch.linalg.vector_norm() 
 torch.linalg.matrix_norm() 
 The above functions are often clearer and more flexible than using  
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A real-valued tensor, even when  
 Examples: 
 Using the  dim  argument to compute vector norms: 
 Using the  dim  argument to compute matrix norms: 
",">>> fromtorchimportlinalgasLA
>>> a=torch.arange(9,dtype=torch.float)-4
>>> a
tensor([-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])
>>> B=a.reshape((3,3))
>>> B
tensor([[-4., -3., -2.],
        [-1.,  0.,  1.],
        [ 2.,  3.,  4.]])>>> LA.norm(a)
tensor(7.7460)
>>> LA.norm(B)
tensor(7.7460)
>>> LA.norm(B,'fro')
tensor(7.7460)
>>> LA.norm(a,float('inf'))
tensor(4.)
>>> LA.norm(B,float('inf'))
tensor(9.)
>>> LA.norm(a,-float('inf'))
tensor(0.)
>>> LA.norm(B,-float('inf'))
tensor(2.)>>> LA.norm(a,1)
tensor(20.)
>>> LA.norm(B,1)
tensor(7.)
>>> LA.norm(a,-1)
tensor(0.)
>>> LA.norm(B,-1)
tensor(6.)
>>> LA.norm(a,2)
tensor(7.7460)
>>> LA.norm(B,2)
tensor(7.3485)>>> LA.norm(a,-2)
tensor(0.)
>>> LA.norm(B.double(),-2)
tensor(1.8570e-16, dtype=torch.float64)
>>> LA.norm(a,3)
tensor(5.8480)
>>> LA.norm(a,-3)
tensor(0.)
",">>> c=torch.tensor([[1.,2.,3.],
... [-1,1,4]])
>>> LA.norm(c,dim=0)
tensor([1.4142, 2.2361, 5.0000])
>>> LA.norm(c,dim=1)
tensor([3.7417, 4.2426])
>>> LA.norm(c,ord=1,dim=1)
tensor([6., 6.])
",">>> A=torch.arange(8,dtype=torch.float).reshape(2,2,2)
>>> LA.norm(A,dim=(1,2))
tensor([ 3.7417, 11.2250])
>>> LA.norm(A[0,:,:]),LA.norm(A[1,:,:])
(tensor(3.7417), tensor(11.2250))
",
"
 torch.linalg. vector_norm ( x ,  ord ,  dim ,  keepdim ,  * ,  dtype ,  out )   → ¶","Computes a vector norm. If  x  is complex valued, it computes the norm of  x .abs() Supports input of float, double, cfloat and cdouble dtypes. This function does not necessarily treat multidimensonal  x  as a batch of
vectors, instead: 
 If  
 If  
 This behavior is for consistency with  torch.linalg.norm() . ord  defines the vector norm that is computed. The following norms are supported: 
 
 
 
 
 where  inf  refers to  float(‘inf’) , NumPy’s  inf  object, or any equivalent object. dtype  may be used to perform the computation in a more precise dtype.
It is semantically equivalent to calling  linalg.vector_norm(x.to(dtype)) 
but it is faster in some cases. 
 See also 
 torch.linalg.matrix_norm() 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A real-valued tensor, even when  
 Examples: 
",">>> fromtorchimportlinalgasLA
>>> a=torch.arange(9,dtype=torch.float)-4
>>> a
tensor([-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])
>>> B=a.reshape((3,3))
>>> B
tensor([[-4., -3., -2.],
        [-1.,  0.,  1.],
        [ 2.,  3.,  4.]])
>>> LA.vector_norm(a,ord=3.5)
tensor(5.4345)
>>> LA.vector_norm(B,ord=3.5)
tensor(5.4345)
",,,
"
 torch.linalg. matrix_norm ( A ,  ord ,  dim ,  keepdim ,  * ,  dtype ,  out )   → ¶","Computes a matrix norm. If  A  is complex valued, it computes the norm of  A .abs() Support input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices: the norm will be computed over the
dimensions specified by the 2-tuple  dim  and the other dimensions will
be treated as batch dimensions. The output will have the same batch dimensions. ord  defines the matrix norm that is computed. The following norms are supported: 
 
 
 
 
 where  inf  refers to  float(‘inf’) , NumPy’s  inf  object, or any equivalent object. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Returns 
 A real-valued tensor, even when  
 Examples: 
",">>> fromtorchimportlinalgasLA
>>> A=torch.arange(9,dtype=torch.float).reshape(3,3)
>>> A
tensor([[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]])
>>> LA.matrix_norm(A)
tensor(14.2829)
>>> LA.matrix_norm(A,ord=-1)
tensor(9.)
>>> B=A.expand(2,-1,-1)
>>> B
tensor([[[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]],        [[0., 1., 2.],
        [3., 4., 5.],
        [6., 7., 8.]]])
>>> LA.matrix_norm(B)
tensor([14.2829, 14.2829])
>>> LA.matrix_norm(B,dim=(0,2))
tensor([ 3.1623, 10.0000, 17.2627])
",,,
"
 torch.linalg. diagonal ( A ,  * ,  offset ,  dim1 ,  dim2 )   → ¶","Alias for  torch.diagonal()  with defaults  dim1 = -2 ,  dim2 = -1 .",,,,
"
 torch.linalg. cond ( A ,  p ,  * ,  out )   → ¶","Computes the condition number of a matrix with respect to a matrix norm. Letting  K  be  R  or  C ,
the  condition number   κ  of a matrix
 A  is defined as 
 κ The condition number of  A  measures the numerical stability of the linear system  AX = B 
with respect to a matrix norm. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. p  defines the matrix norm that is computed. The following norms are supported: 
 
 
 
 
 where  inf  refers to  float(‘inf’) , NumPy’s  inf  object, or any equivalent object. For  p  is one of  (‘fro’, ‘nuc’, inf, -inf, 1, -1) , this function uses
 torch.linalg.norm()  and  torch.linalg.inv() .
As such, in this case, the matrix (or every matrix in the batch)  A  has to be square
and invertible. For  p  in  (2, -2) , this function can be computed in terms of the singular values
 σ 
 κ In these cases, it is computed using  torch.linalg.svdvals() . For these norms, the matrix
(or every matrix in the batch)  A  may have any shape. 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU
if  
 
 See also 
 torch.linalg.solve() 
 torch.linalg.lstsq() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A real-valued tensor, even when  
 Raises 
 RuntimeError 
 Examples: 
",">>> A=torch.randn(3,4,4,dtype=torch.complex64)
>>> torch.linalg.cond(A)
>>> A=torch.tensor([[1.,0,-1],[0,1,0],[1,0,1]])
>>> torch.linalg.cond(A)
tensor([1.4142])
>>> torch.linalg.cond(A,'fro')
tensor(3.1623)
>>> torch.linalg.cond(A,'nuc')
tensor(9.2426)
>>> torch.linalg.cond(A,float('inf'))
tensor(2.)
>>> torch.linalg.cond(A,float('-inf'))
tensor(1.)
>>> torch.linalg.cond(A,1)
tensor(2.)
>>> torch.linalg.cond(A,-1)
tensor(1.)
>>> torch.linalg.cond(A,2)
tensor([1.4142])
>>> torch.linalg.cond(A,-2)
tensor([0.7071])>>> A=torch.randn(2,3,3)
>>> torch.linalg.cond(A)
tensor([[9.5917],
        [3.2538]])
>>> A=torch.randn(2,3,3,dtype=torch.complex64)
>>> torch.linalg.cond(A)
tensor([[4.6245],
        [4.5671]])
",,,
"
 torch.linalg. matrix_rank ( A ,  * ,  atol ,  rtol ,  hermitian ,  out )   → ¶","Computes the numerical rank of a matrix. The matrix rank is computed as the number of singular values
(or eigenvalues in absolute value when  hermitian = True )
that are greater than  max  threshold,
where  σ  is the largest singular value (or eigenvalue). Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. If  hermitian = True ,  A  is assumed to be Hermitian if complex or
symmetric if real, but this is not checked internally. Instead, just the lower
triangular part of the matrix is used in the computations. If  rtol  is not specified and  A  is a matrix of dimensions  (m, n) ,
the relative tolerance is set to be  rtol 
and  ε  is the epsilon value for the dtype of  A  (see  finfo ).
If  rtol  is not specified and  atol  is specified to be larger than zero then
 rtol  is set to zero. If  atol  or  rtol  is a  torch.Tensor , its shape must be broadcastable to that
of the singular values of  A  as returned by  torch.linalg.svdvals() . 
 Note 
 This function has NumPy compatible variant  
 
 Note 
 The matrix rank is computed using a singular value decomposition
 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> A=torch.eye(10)
>>> torch.linalg.matrix_rank(A)
tensor(10)
>>> B=torch.eye(10)
>>> B[0,0]=0
>>> torch.linalg.matrix_rank(B)
tensor(9)>>> A=torch.randn(4,3,2)
>>> torch.linalg.matrix_rank(A)
tensor([2, 2, 2, 2])>>> A=torch.randn(2,4,2,3)
>>> torch.linalg.matrix_rank(A)
tensor([[2, 2, 2, 2],
        [2, 2, 2, 2]])>>> A=torch.randn(2,4,3,3,dtype=torch.complex64)
>>> torch.linalg.matrix_rank(A)
tensor([[3, 3, 3, 3],
        [3, 3, 3, 3]])
>>> torch.linalg.matrix_rank(A,hermitian=True)
tensor([[3, 3, 3, 3],
        [3, 3, 3, 3]])
>>> torch.linalg.matrix_rank(A,atol=1.0,rtol=0.0)
tensor([[3, 2, 2, 2],
        [1, 2, 1, 2]])
>>> torch.linalg.matrix_rank(A,atol=1.0,rtol=0.0,hermitian=True)
tensor([[2, 2, 2, 1],
        [1, 2, 2, 2]])
",,,
"
 torch.linalg. eig ( A ,  * ,  out ) ¶","Computes the eigenvalue decomposition of a square matrix if it exists. Letting  K  be  R  or  C ,
the  eigenvalue decomposition  of a square matrix
 A  (if it exists) is defined as 
 A This decomposition exists if and only if  A  is  diagonalizable .
This is the case when all its eigenvalues are different. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. 
 Note 
 The eigenvalues and eigenvectors of a real matrix may be complex. 
 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU. 
 
 Warning 
 This function assumes that  
 
 Warning 
 The returned eigenvectors are normalized to have norm  
 This non-uniqueness is caused by the fact that multiplying an eigenvector by
by  
 
 Warning 
 Gradients computed using the  
 
 See also 
 torch.linalg.eigvals() 
 torch.linalg.eigh() 
 torch.linalg.svd() 
 torch.linalg.qr() 
 
 Parameters 
 A 
 Keyword Arguments 
 out 
 Returns 
 A named tuple  
 Examples: 
",">>> A=torch.randn(2,2,dtype=torch.complex128)
>>> A
tensor([[ 0.9828+0.3889j, -0.4617+0.3010j],
        [ 0.1662-0.7435j, -0.6139+0.0562j]], dtype=torch.complex128)
>>> L,V=torch.linalg.eig(A)
>>> L
tensor([ 1.1226+0.5738j, -0.7537-0.1286j], dtype=torch.complex128)
>>> V
tensor([[ 0.9218+0.0000j,  0.1882-0.2220j],
        [-0.0270-0.3867j,  0.9567+0.0000j]], dtype=torch.complex128)
>>> torch.dist(V@torch.diag(L)@torch.linalg.inv(V),A)
tensor(7.7119e-16, dtype=torch.float64)>>> A=torch.randn(3,2,2,dtype=torch.float64)
>>> L,V=torch.linalg.eig(A)
>>> torch.dist(V@torch.diag_embed(L)@torch.linalg.inv(V),A)
tensor(3.2841e-16, dtype=torch.float64)
",,,
"
 torch.linalg. eigvals ( A ,  * ,  out )   → ¶","Computes the eigenvalues of a square matrix. Letting  K  be  R  or  C ,
the  eigenvalues  of a square matrix  A  are defined
as the roots (counted with multiplicity) of the polynomial  p  of degree  n  given by 
 p where  I  is the  n -dimensional identity matrix. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. 
 Note 
 The eigenvalues of a real matrix may be complex, as the roots of a real polynomial may be complex. 
 The eigenvalues of a matrix are always well-defined, even when the matrix is not diagonalizable. 
 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU. 
 
 See also 
 torch.linalg.eig() 
 
 Parameters 
 A 
 Keyword Arguments 
 out 
 Returns 
 A complex-valued tensor cointaining the eigenvalues even when  
 Examples: 
",">>> A=torch.randn(2,2,dtype=torch.complex128)
>>> L=torch.linalg.eigvals(A)
>>> L
tensor([ 1.1226+0.5738j, -0.7537-0.1286j], dtype=torch.complex128)>>> torch.dist(L,torch.linalg.eig(A).eigenvalues)
tensor(2.4576e-07)
",,,
"
 torch.linalg. eigvalsh ( A ,  UPLO ,  * ,  out )   → ¶","Computes the eigenvalues of a complex Hermitian or real symmetric matrix. Letting  K  be  R  or  C ,
the  eigenvalues  of a complex Hermitian or real symmetric  matrix  A 
are defined as the roots (counted with multiplicity) of the polynomial  p  of degree  n  given by 
 p where  I  is the  n -dimensional identity matrix.
The eigenvalues of a real symmetric or complex Hermitian matrix are always real. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. The eigenvalues are returned in ascending order. A  is assumed to be Hermitian (resp. symmetric), but this is not checked internally, instead: 
 If  
 If  
 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU. 
 
 See also 
 torch.linalg.eigh() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Returns 
 A real-valued tensor cointaining the eigenvalues even when  
 Examples: 
",">>> A=torch.randn(2,2,dtype=torch.complex128)
>>> A=A+A.T.conj()# creates a Hermitian matrix
>>> A
tensor([[2.9228+0.0000j, 0.2029-0.0862j],
        [0.2029+0.0862j, 0.3464+0.0000j]], dtype=torch.complex128)
>>> torch.linalg.eigvalsh(A)
tensor([0.3277, 2.9415], dtype=torch.float64)>>> A=torch.randn(3,2,2,dtype=torch.float64)
>>> A=A+A.mT# creates a batch of symmetric matrices
>>> torch.linalg.eigvalsh(A)
tensor([[ 2.5797,  3.4629],
        [-4.1605,  1.3780],
        [-3.1113,  2.7381]], dtype=torch.float64)
",,,
"
 torch.linalg. solve ( A ,  B ,  * ,  left ,  out )   → ¶","Computes the solution of a square system of linear equations with a unique solution. Letting  K  be  R  or  C ,
this function computes the solution  X  of the  linear system  associated to
 A , which is defined as 
 A If  left = False , this function returns the matrix  X  that solves the system 
 X This system of linear equations has one solution if and only if  A  is  invertible .
This function assumes that  A  is invertible. Supports inputs of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if the inputs are batches of matrices then
the output has the same batch dimensions. Letting  *  be zero or more batch dimensions, 
 If  
 Otherwise, if  
 
 Note 
 This function computes  
 
 Note 
 It is possible to compute the solution of the system  
 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU. 
 
 See also 
 torch.linalg.solve_triangular() 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Raises 
 RuntimeError 
 Examples: 
",">>> A=torch.randn(3,3)
>>> b=torch.randn(3)
>>> x=torch.linalg.solve(A,b)
>>> torch.allclose(A@x,b)
True
>>> A=torch.randn(2,3,3)
>>> B=torch.randn(2,3,4)
>>> X=torch.linalg.solve(A,B)
>>> X.shape
torch.Size([2, 3, 4])
>>> torch.allclose(A@X,B)
True>>> A=torch.randn(2,3,3)
>>> b=torch.randn(3,1)
>>> x=torch.linalg.solve(A,b)# b is broadcasted to size (2, 3, 1)
>>> x.shape
torch.Size([2, 3, 1])
>>> torch.allclose(A@x,b)
True
>>> b=torch.randn(3)
>>> x=torch.linalg.solve(A,b)# b is broadcasted to size (2, 3)
>>> x.shape
torch.Size([2, 3])
>>> Ax=A@x.unsqueeze(-1)
>>> torch.allclose(Ax,b.unsqueeze(-1).expand_as(Ax))
True
",,,
"
 torch.linalg. solve_triangular ( A ,  B ,  * ,  upper ,  left ,  unitriangular ,  out )   → ¶","Computes the solution of a triangular system of linear equations with a unique solution. Letting  K  be  R  or  C ,
this function computes the solution  X  of the  linear system 
associated to the triangular matrix  A  without zeros on the diagonal
(that is, it is  invertible ) and the rectangular matrix ,  B ,
which is defined as 
 A The argument  upper  signals whether  A  is upper or lower triangular. If  left = False , this function returns the matrix  X  that
solves the system 
 X If  upper = True  (resp.  False ) just the upper (resp. lower) triangular half of  A 
will be accessed. The elements below the main diagonal will be considered to be zero and will not be accessed. If  unitriangular = True , the diagonal of  A  is assumed to be ones and will not be accessed. The result may contain  NaN  s if the diagonal of  A  contains zeros or elements that
are very close to zero and  unitriangular = False  (default) or if the input matrix
has very small eigenvalues. Supports inputs of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if the inputs are batches of matrices then
the output has the same batch dimensions. 
 See also 
 torch.linalg.solve() 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> A=torch.randn(3,3).triu_()
>>> b=torch.randn(3,4)
>>> X=torch.linalg.solve_triangular(A,B,upper=True)
>>> torch.allclose(A@X,B)
True>>> A=torch.randn(2,3,3).tril_()
>>> B=torch.randn(2,3,4)
>>> X=torch.linalg.solve_triangular(A,B,upper=False)
>>> torch.allclose(A@X,B)
True>>> A=torch.randn(2,4,4).tril_()
>>> B=torch.randn(2,3,4)
>>> X=torch.linalg.solve_triangular(A,B,upper=False,left=False)
>>> torch.allclose(X@A,B)
True
",,,
"
 torch.linalg. lstsq ( A ,  B ,  rcond ,  * ,  driver ) ¶","Computes a solution to the least squares problem of a system of linear equations. Letting  K  be  R  or  C ,
the  least squares problem  for a linear system  A  with
 A  is defined as 
 min where  ∥  denotes the Frobenius norm. Supports inputs of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if the inputs are batches of matrices then
the output has the same batch dimensions. driver  chooses the LAPACK/MAGMA function that will be used.
For CPU inputs the valid values are  ‘gels’ ,  ‘gelsy’ ,  ‘gelsd ,  ‘gelss’ .
For CUDA input, the only valid driver is  ‘gels’ , which assumes that  A  is full-rank.
To choose the best driver on CPU consider: 
 If  
 If  
 See also the  full description of these drivers rcond  is used to determine the effective rank of the matrices in  A 
when  driver  is one of ( ‘gelsy’ ,  ‘gelsd’ ,  ‘gelss’ ).
In this case, if  σ  are the singular values of  A  in decreasing order,
 σ  will be rounded down to zero if  σ .
If  rcond = None  (default),  rcond  is set to the machine precision of the dtype of  A  times  max(m, n) . This function returns the solution to the problem and some extra information in a named tuple of
four tensors  (solution, residuals, rank, singular_values) . For inputs  A ,  B 
of shape  (*, m, n) ,  (*, m, k)  respectively, it cointains 
 solution 
 residuals 
 rank 
 singular_values 
 
 Note 
 This function computes  
 
 Warning 
 The default value of  
 
 Parameters 
 
 
 Keyword Arguments 
 driver 
 Returns 
 A named tuple  
 Examples: 
",">>> A=torch.tensor([[[10,2,3],[3,10,5],[5,6,12]]],dtype=torch.float)# shape (1, 3, 3)
>>> B=torch.tensor([[[2,5,1],[3,2,1],[5,1,9]],
                      [[4, 2, 9], [2, 0, 3], [2, 5, 3]]], dtype=torch.float) # shape (2, 3, 3)
>>> X=torch.linalg.lstsq(A,B).solution# A is broadcasted to shape (2, 3, 3)
>>> torch.dist(X,torch.linalg.pinv(A)@B)
tensor(2.0862e-07)>>> S=torch.linalg.lstsq(A,B,driver='gelsd').singular_values
>>> torch.dist(S,torch.linalg.svdvals(A))
tensor(5.7220e-06)>>> A[:,0].zero_()# Decrease the rank of A
>>> rank=torch.linalg.lstsq(A,B).rank
>>> rank
tensor([2])
",,,
"
 torch.linalg. cross ( input ,  other ,  * ,  dim ,  out )   → ¶","Computes the cross product of two 3-dimensional vectors. Supports input of float, double, cfloat and cdouble dtypes. Also supports batches
of vectors, for which it computes the product along the dimension  dim .
It broadcasts over the batch dimensions. 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Example 
",,,,
"
 torch.linalg. matmul ( input ,  other ,  * ,  out )   → ¶",Alias for  torch.matmul(),,,,
"
 torch.linalg. vecdot ( x ,  y ,  * ,  dim ,  out )   → ¶","Computes the dot product of two batches of vectors along a dimension. In symbols, this function computes 
 ∑ over the dimension  dim  where  x  denotes the conjugate for complex
vectors, and it is the identity for real vectors. Supports input of half, bfloat16, float, double, cfloat, cdouble and integral dtypes.
It also supports broadcasting. 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> v1=torch.randn(3,2)
>>> v2=torch.randn(3,2)
>>> linalg.vecdot(v1,v2)
tensor([ 0.3223,  0.2815, -0.1944])
>>> torch.vdot(v1[0],v2[0])
tensor(0.3223)
",,,
"
 torch.linalg. multi_dot ( tensors ,  * ,  out ) ¶","Efficiently multiplies two or more matrices by reordering the multiplications so that
the fewest arithmetic operations are performed. Supports inputs of float, double, cfloat and cdouble dtypes.
This function does not support batched inputs. Every tensor in  tensors  must be 2D, except for the first and last which
may be 1D. If the first tensor is a 1D vector of shape  (n,)  it is treated as a row vector
of shape  (1, n) , similarly if the last tensor is a 1D vector of shape  (n,)  it is treated
as a column vector of shape  (n, 1) . If the first and last tensors are matrices, the output will be a matrix.
However, if either is a 1D vector, then the output will be a 1D vector. Differences with  numpy.linalg.multi_dot : 
 Unlike  
 
 Warning 
 This function does not broadcast. 
 
 Note 
 This function is implemented by chaining  
 
 Note 
 The cost of multiplying two matrices with shapes  
 
 In this case, multiplying  
 
 Parameters 
 tensors 
 Keyword Arguments 
 out 
 Examples: 
",">>> fromtorch.linalgimportmulti_dot>>> multi_dot([torch.tensor([1,2]),torch.tensor([2,3])])
tensor(8)
>>> multi_dot([torch.tensor([[1,2]]),torch.tensor([2,3])])
tensor([8])
>>> multi_dot([torch.tensor([[1,2]]),torch.tensor([[2],[3]])])
tensor([[8]])>>> A=torch.arange(2*3).view(2,3)
>>> B=torch.arange(3*2).view(3,2)
>>> C=torch.arange(2*2).view(2,2)
>>> multi_dot((A,B,C))
tensor([[ 26,  49],
        [ 80, 148]])
",,,
"
 torch.linalg. tensorinv ( A ,  ind ,  * ,  out )   → ¶","Computes the multiplicative inverse of  torch.tensordot() . If  m  is the product of the first  ind  dimensions of  A  and  n  is the product of
the rest of the dimensions, this function expects  m  and  n  to be equal.
If this is the case, it computes a tensor  X  such that
 tensordot( A , X,  ind )  is the identity matrix in dimension  m .
 X  will have the shape of  A  but with the first  ind  dimensions pushed back to the end 
 Supports input of float, double, cfloat and cdouble dtypes. 
 Note 
 When  
 
 Note 
 Consider using  
 
 It is always prefered to use  
 
 See also 
 torch.linalg.tensorsolve() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Raises 
 RuntimeError 
 Examples: 
",">>> A=torch.eye(4*6).reshape((4,6,8,3))
>>> Ainv=torch.linalg.tensorinv(A,ind=2)
>>> Ainv.shape
torch.Size([8, 3, 4, 6])
>>> B=torch.randn(4,6)
>>> torch.allclose(torch.tensordot(Ainv,B),torch.linalg.tensorsolve(A,B))
True>>> A=torch.randn(4,4)
>>> Atensorinv=torch.linalg.tensorinv(A,ind=1)
>>> Ainv=torch.linalg.inverse(A)
>>> torch.allclose(Atensorinv,Ainv)
True
",,,
"
 torch.linalg. tensorsolve ( A ,  B ,  dims ,  * ,  out )   → ¶","Computes the solution  X  to the system  torch.tensordot(A, X) = B . If  m  is the product of the first  B .ndim   dimensions of  A  and
 n  is the product of the rest of the dimensions, this function expects  m  and  n  to be equal. The returned tensor  x  satisfies
 tensordot( A , x, dims=x.ndim) ==  B .
 x  has shape  A [B.ndim:] . If  dims  is specified,  A  will be reshaped as 
 Supports inputs of float, double, cfloat and cdouble dtypes. 
 See also 
 torch.linalg.tensorinv() 
 
 Parameters 
 
 
 Keyword Arguments 
 out 
 Raises 
 RuntimeError 
 Examples: 
",">>> A=torch.eye(2*3*4).reshape((2*3,4,2,3,4))
>>> B=torch.randn(2*3,4)
>>> X=torch.linalg.tensorsolve(A,B)
>>> X.shape
torch.Size([2, 3, 4])
>>> torch.allclose(torch.tensordot(A,X,dims=X.ndim),B)
True>>> A=torch.randn(6,4,4,3,2)
>>> B=torch.randn(4,3,2)
>>> X=torch.linalg.tensorsolve(A,B,dims=(0,2))
>>> X.shape
torch.Size([6, 4])
>>> A=A.permute(1,3,4,0,2)
>>> A.shape[B.ndim:]
torch.Size([6, 4])
>>> torch.allclose(torch.tensordot(A,X,dims=X.ndim),B,atol=1e-6)
True
",,,
"
 torch.linalg. vander ( x ,  N )   → ¶","Generates a Vandermonde matrix. Returns the Vandermonde matrix  V 
 V for  N > 1 .
If  N = None , then  N = x.size(-1)  so that the output is a square matrix. Supports inputs of float, double, cfloat, cdouble, and integral dtypes.
Also supports batches of vectors, and if  x  is a batch of vectors then
the output has the same batch dimensions. Differences with  numpy.vander : 
 Unlike  
 
 Parameters 
 x 
 Keyword Arguments 
 N 
 Example: 
",">>> x=torch.tensor([1,2,3,5])
>>> linalg.vander(x)
tensor([[  1,   1,   1,   1],
        [  1,   2,   4,   8],
        [  1,   3,   9,  27],
        [  1,   5,  25, 125]])
>>> linalg.vander(x,N=3)
tensor([[ 1,  1,  1],
        [ 1,  2,  4],
        [ 1,  3,  9],
        [ 1,  5, 25]])
",,,
"
 torch.linalg. solve_ex ( A ,  B ,  * ,  left ,  check_errors ,  out ) ¶","A version of  solve()  that does not perform error checks unless  check_errors = True .
It also returns the  info  tensor returned by  LAPACK’s getrf . 
 Note 
 When the inputs are on a CUDA device, this function synchronizes only when  
 
 Warning 
 This function is “experimental” and it may change in a future PyTorch release. 
 
 Parameters 
 A 
 Keyword Arguments 
 
 
 Returns 
 A named tuple  
 Examples: 
",">>> A=torch.randn(3,3)
>>> Ainv,info=torch.linalg.solve_ex(A)
>>> torch.dist(torch.linalg.inv(A),Ainv)
tensor(0.)
>>> info
tensor(0, dtype=torch.int32)
",,,
"
 torch.linalg. lu_factor_ex ( A ,  * ,  pivot ,  check_errors ,  out ) ¶","This is a version of  lu_factor()  that does not perform error checks unless  check_errors = True .
It also returns the  info  tensor returned by  LAPACK’s getrf . 
 Note 
 When the inputs are on a CUDA device, this function synchronizes only when  
 
 Warning 
 This function is “experimental” and it may change in a future PyTorch release. 
 
 Parameters 
 A 
 Keyword Arguments 
 
 
 Returns 
 A named tuple  
",,,,
"
 torch.linalg. ldl_factor ( A ,  * ,  hermitian ,  out ) ¶","Computes a compact representation of the LDL factorization of a Hermitian or symmetric (possibly indefinite) matrix. When  A  is complex valued it can be Hermitian ( hermitian = True )
or symmetric ( hermitian = False ). The factorization is of the form the form  A .
If  hermitian  is  True  then transpose operation is the conjugate transpose. L  (or  U ) and  D  are stored in compact form in  LD .
They follow the format specified by  LAPACK’s sytrf  function.
These tensors may be used in  torch.linalg.ldl_solve()  to solve linear systems. Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. 
 Note 
 When inputs are on a CUDA device, this function synchronizes that device with the CPU. For a version of this function that does not synchronize, see  
 
 Parameters 
 A 
 Keyword Arguments 
 
 
 Returns 
 A named tuple  
 Examples: 
",">>> A=torch.randn(3,3)
>>> A=A@A.mT# make symmetric
>>> A
tensor([[7.2079, 4.2414, 1.9428],
        [4.2414, 3.4554, 0.3264],
        [1.9428, 0.3264, 1.3823]])
>>> LD,pivots=torch.linalg.ldl_factor(A)
>>> LD
tensor([[ 7.2079,  0.0000,  0.0000],
        [ 0.5884,  0.9595,  0.0000],
        [ 0.2695, -0.8513,  0.1633]])
>>> pivots
tensor([1, 2, 3], dtype=torch.int32)
",,,
"
 torch.linalg. ldl_factor_ex ( A ,  * ,  hermitian ,  check_errors ,  out ) ¶","This is a version of  ldl_factor()  that does not perform error checks unless  check_errors = True .
It also returns the  info  tensor returned by  LAPACK’s sytrf .
 info  stores integer error codes from the backend library.
A positive integer indicates the diagonal element of  D  that is zero.
Division by 0 will occur if the result is used for solving a system of linear equations.
 info  filled with zeros indicates that the factorization was successful.
If  check_errors=True  and  info  contains positive integers, then a  RuntimeError  is thrown. 
 Note 
 When the inputs are on a CUDA device, this function synchronizes only when  
 
 Warning 
 This function is “experimental” and it may change in a future PyTorch release. 
 
 Parameters 
 A 
 Keyword Arguments 
 
 
 Returns 
 A named tuple  
 Examples: 
",">>> A=torch.randn(3,3)
>>> A=A@A.mT# make symmetric
>>> A
tensor([[7.2079, 4.2414, 1.9428],
        [4.2414, 3.4554, 0.3264],
        [1.9428, 0.3264, 1.3823]])
>>> LD,pivots,info=torch.linalg.ldl_factor_ex(A)
>>> LD
tensor([[ 7.2079,  0.0000,  0.0000],
        [ 0.5884,  0.9595,  0.0000],
        [ 0.2695, -0.8513,  0.1633]])
>>> pivots
tensor([1, 2, 3], dtype=torch.int32)
>>> info
tensor(0, dtype=torch.int32)
",,,
"
 torch.linalg. ldl_solve ( LD ,  pivots ,  B ,  * ,  hermitian ,  out )   → ¶","Computes the solution of a system of linear equations using the LDL factorization. LD  and  pivots  are the compact representation of the LDL factorization and
are expected to be computed by  torch.linalg.ldl_factor_ex() .
 hermitian  argument to this function should be the same
as the corresponding argumens in  torch.linalg.ldl_factor_ex() . Supports input of float, double, cfloat and cdouble dtypes.
Also supports batches of matrices, and if  A  is a batch of matrices then
the output has the same batch dimensions. 
 Warning 
 This function is “experimental” and it may change in a future PyTorch release. 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> A=torch.randn(2,3,3)
>>> A=A@A.mT# make symmetric
>>> LD,pivots,info=torch.linalg.ldl_factor_ex(A)
>>> B=torch.randn(2,3,4)
>>> X=torch.linalg.ldl_solve(LD,pivots,B)
>>> torch.linalg.norm(A@X-B)
>>> tensor(0.0001)
",,,
"
 class torch.onnx. JitScalarType ( value ) ¶","Scalar types defined in torch. Use  JitScalarType  to convert from torch and JIT scalar types to ONNX scalar types. 
 Examples:: 
 
 
 
 Convert a ScalarType to a torch dtype. 
 
 
 Convert a torch dtype to ScalarType. 
 
 
 Convert a JIT scalar type or torch type name to ScalarType. 
 
 
 Return whether this ScalarType is compatible with ONNX. 
 
 
 Convert a ScalarType to an ONNX data type. 
 
 
 Convert a ScalarType to a JIT scalar type name. 
 
 
 Convert a ScalarType to a torch type name.",,,,
"
 Optimizer. add_param_group ( param_group ) [source] ¶","Add a param group to the  Optimizer  s  param_groups . This can be useful when fine tuning a pre-trained network as frozen layers can be made
trainable and added to the  Optimizer  as training progresses. 
 Parameters 
 param_group 
",,,,
"
 Optimizer. load_state_dict ( state_dict ) [source] ¶","Loads the optimizer state. 
 Parameters 
 state_dict 
",,,,
"
 Optimizer. zero_grad ( set_to_none ) [source] ¶","Sets the gradients of all optimized  torch.Tensor  s to zero. 
 Parameters 
 set_to_none 
",,,,
"
 class torch.optim. Adadelta ( params ,  lr ,  rho ,  eps ,  weight_decay ,  foreach ,  * ,  maximize ) [source] ¶","Implements Adadelta algorithm. 
 For further details regarding the algorithm we refer to  ADADELTA: An Adaptive Learning Rate Method . 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Performs a single optimization step. 
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. Adagrad ( params ,  lr ,  lr_decay ,  weight_decay ,  initial_accumulator_value ,  eps ,  foreach ,  * ,  maximize ) [source] ¶","Implements Adagrad algorithm. 
 For further details regarding the algorithm we refer to  Adaptive Subgradient Methods for Online Learning
and Stochastic Optimization . 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Performs a single optimization step. 
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. Adam ( params ,  lr ,  betas ,  eps ,  weight_decay ,  amsgrad ,  * ,  foreach ,  maximize ,  capturable ,  differentiable ,  fused ) [source] ¶","Implements Adam algorithm. 
 For further details regarding the algorithm we refer to  Adam: A Method for Stochastic Optimization . 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. AdamW ( params ,  lr ,  betas ,  eps ,  weight_decay ,  amsgrad ,  * ,  maximize ,  foreach ,  capturable ) [source] ¶","Implements AdamW algorithm. 
 For further details regarding the algorithm we refer to  Decoupled Weight Decay Regularization . 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Performs a single optimization step. 
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. SparseAdam ( params ,  lr ,  betas ,  eps ,  maximize ) [source] ¶","Implements lazy version of Adam algorithm suitable for sparse tensors. In this variant, only moments that show up in the gradient get updated, and
only those portions of the gradient get applied to the parameters. 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Performs a single optimization step. 
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. Adamax ( params ,  lr ,  betas ,  eps ,  weight_decay ,  foreach ,  * ,  maximize ) [source] ¶","Implements Adamax algorithm (a variant of Adam based on infinity norm). 
 For further details regarding the algorithm we refer to  Adam: A Method for Stochastic Optimization . 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Performs a single optimization step. 
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. ASGD ( params ,  lr ,  lambd ,  alpha ,  t0 ,  weight_decay ,  foreach ,  maximize ) [source] ¶","Implements Averaged Stochastic Gradient Descent. It has been proposed in  Acceleration of stochastic approximation by
averaging . 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Performs a single optimization step. 
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. LBFGS ( params ,  lr ,  max_iter ,  max_eval ,  tolerance_grad ,  tolerance_change ,  history_size ,  line_search_fn ) [source] ¶","Implements L-BFGS algorithm, heavily inspired by  minFunc . 
 Warning 
 This optimizer doesn’t support per-parameter options and parameter
groups (there can be only one). 
 
 Warning 
 Right now all parameters have to be on a single device. This will be
improved in the future. 
 
 Note 
 This is a very memory intensive optimizer (it requires additional
 
 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Performs a single optimization step. 
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. NAdam ( params ,  lr ,  betas ,  eps ,  weight_decay ,  momentum_decay ,  foreach ) [source] ¶","Implements NAdam algorithm. 
 For further details regarding the algorithm we refer to  Incorporating Nesterov Momentum into Adam . 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Performs a single optimization step. 
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. RAdam ( params ,  lr ,  betas ,  eps ,  weight_decay ,  foreach ) [source] ¶","Implements RAdam algorithm. 
 For further details regarding the algorithm we refer to  On the variance of the adaptive learning rate and beyond . 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Performs a single optimization step. 
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. RMSprop ( params ,  lr ,  alpha ,  eps ,  weight_decay ,  momentum ,  centered ,  foreach ,  maximize ,  differentiable ) [source] ¶","Implements RMSprop algorithm. 
 For further details regarding the algorithm we refer to
 lecture notes  by G. Hinton.
and centered version  Generating Sequences
With Recurrent Neural Networks .
The implementation here takes the square root of the gradient average before
adding epsilon (note that TensorFlow interchanges these two operations). The effective
learning rate is thus  γ  where  γ 
is the scheduled learning rate and  v  is the weighted moving average
of the squared gradient. 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. Rprop ( params ,  lr ,  etas ,  step_sizes ,  foreach ,  maximize ) [source] ¶","Implements the resilient backpropagation algorithm. 
 For further details regarding the algorithm we refer to the paper
 A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm . 
 Parameters 
 
 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Performs a single optimization step. 
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim. SGD ( params ,  lr=<required ,  momentum=0 ,  dampening=0 ,  weight_decay=0 ,  nesterov=False ,  * ,  maximize=False ,  foreach=None ,  differentiable=False ) [source] ¶","Implements stochastic gradient descent (optionally with momentum). 
 Nesterov momentum is based on the formula from
 On the importance of initialization and momentum in deep learning . 
 Parameters 
 
 
 Example 
 
 Note 
 The implementation of SGD with Momentum/Nesterov subtly differs from
Sutskever et. al. and implementations in some other frameworks. 
 Considering the specific case of Momentum, the update can be written as 
 
 where  
 This is in contrast to Sutskever et. al. and
other frameworks which employ an update of the form 
 
 The Nesterov version is analogously modified. 
 
 
 
 Add a param group to the  
 
 
 Loads the optimizer state. 
 
 
 Returns the state of the optimizer as a  
 
 
 Sets the gradients of all optimized ",,,,
"
 class torch.optim.lr_scheduler. ReduceLROnPlateau ( optimizer ,  mode ,  factor ,  patience ,  threshold ,  threshold_mode ,  cooldown ,  min_lr ,  eps ,  verbose ) [source] ¶","Reduce learning rate when a metric has stopped improving.
Models often benefit from reducing the learning rate by a factor
of 2-10 once learning stagnates. This scheduler reads a metrics
quantity and if no improvement is seen for a ‘patience’ number
of epochs, the learning rate is reduced. 
 Parameters 
 
 
 Example 
",,,,
"
 class torch.optim.lr_scheduler. LambdaLR ( optimizer ,  lr_lambda ,  last_epoch ,  verbose ) [source] ¶","Sets the learning rate of each parameter group to the initial lr
times a given function. When last_epoch=-1, sets initial lr as lr. 
 Parameters 
 
 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. MultiplicativeLR ( optimizer ,  lr_lambda ,  last_epoch ,  verbose ) [source] ¶","Multiply the learning rate of each parameter group by the factor given
in the specified function. When last_epoch=-1, sets initial lr as lr. 
 Parameters 
 
 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. StepLR ( optimizer ,  step_size ,  gamma ,  last_epoch ,  verbose ) [source] ¶","Decays the learning rate of each parameter group by gamma every
step_size epochs. Notice that such decay can happen simultaneously with
other changes to the learning rate from outside this scheduler. When
last_epoch=-1, sets initial lr as lr. 
 Parameters 
 
 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. MultiStepLR ( optimizer ,  milestones ,  gamma ,  last_epoch ,  verbose ) [source] ¶","Decays the learning rate of each parameter group by gamma once the
number of epoch reaches one of the milestones. Notice that such decay can
happen simultaneously with other changes to the learning rate from outside
this scheduler. When last_epoch=-1, sets initial lr as lr. 
 Parameters 
 
 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. ConstantLR ( optimizer ,  factor ,  total_iters ,  last_epoch ,  verbose ) [source] ¶","Decays the learning rate of each parameter group by a small constant factor until the
number of epoch reaches a pre-defined milestone: total_iters. Notice that such decay can
happen simultaneously with other changes to the learning rate from outside this scheduler.
When last_epoch=-1, sets initial lr as lr. 
 Parameters 
 
 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. LinearLR ( optimizer ,  start_factor ,  end_factor ,  total_iters ,  last_epoch ,  verbose ) [source] ¶","Decays the learning rate of each parameter group by linearly changing small
multiplicative factor until the number of epoch reaches a pre-defined milestone: total_iters.
Notice that such decay can happen simultaneously with other changes to the learning rate
from outside this scheduler. When last_epoch=-1, sets initial lr as lr. 
 Parameters 
 
 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. ExponentialLR ( optimizer ,  gamma ,  last_epoch ,  verbose ) [source] ¶","Decays the learning rate of each parameter group by gamma every epoch.
When last_epoch=-1, sets initial lr as lr. 
 Parameters 
 
 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. PolynomialLR ( optimizer ,  total_iters ,  power ,  last_epoch ,  verbose ) [source] ¶","Decays the learning rate of each parameter group using a polynomial function
in the given total_iters. When last_epoch=-1, sets initial lr as lr. 
 Parameters 
 
 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. CosineAnnealingLR ( optimizer ,  T_max ,  eta_min ,  last_epoch ,  verbose ) [source] ¶","Set the learning rate of each parameter group using a cosine annealing
schedule, where  η  is set to the initial lr and
 T  is the number of epochs since the last restart in SGDR: 
 η When last_epoch=-1, sets initial lr as lr. Notice that because the schedule
is defined recursively, the learning rate can be simultaneously modified
outside this scheduler by other operators. If the learning rate is set
solely by this scheduler, the learning rate at each step becomes: 
 η It has been proposed in
 SGDR: Stochastic Gradient Descent with Warm Restarts . Note that this only
implements the cosine annealing part of SGDR, and not the restarts. 
 Parameters 
 
 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. ChainedScheduler ( schedulers ) [source] ¶","Chains list of learning rate schedulers. It takes a list of chainable learning
rate schedulers and performs consecutive step() functions belonging to them by just
one call. 
 Parameters 
 schedulers 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. SequentialLR ( optimizer ,  schedulers ,  milestones ,  last_epoch ,  verbose ) [source] ¶","Receives the list of schedulers that is expected to be called sequentially during
optimization process and milestone points that provides exact intervals to reflect
which scheduler is supposed to be called at a given epoch. 
 Parameters 
 
 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. CyclicLR ( optimizer ,  base_lr ,  max_lr ,  step_size_up ,  step_size_down ,  mode ,  gamma ,  scale_fn ,  scale_mode ,  cycle_momentum ,  base_momentum ,  max_momentum ,  last_epoch ,  verbose ) [source] ¶","Sets the learning rate of each parameter group according to
cyclical learning rate policy (CLR). The policy cycles the learning
rate between two boundaries with a constant frequency, as detailed in
the paper  Cyclical Learning Rates for Training Neural Networks .
The distance between the two boundaries can be scaled on a per-iteration
or per-cycle basis. Cyclical learning rate policy changes the learning rate after every batch.
 step  should be called after a batch has been used for training. This class has three built-in policies, as put forth in the paper: 
 “triangular”: A basic triangular cycle without amplitude scaling. 
 “triangular2”: A basic triangular cycle that scales initial amplitude by half each cycle. 
 “exp_range”: A cycle that scales initial amplitude by  
 This implementation was adapted from the github repo:  bckenstler/CLR 
 Parameters 
 
 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Calculates the learning rate at batch index. This function treats
 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. OneCycleLR ( optimizer ,  max_lr ,  total_steps ,  epochs ,  steps_per_epoch ,  pct_start ,  anneal_strategy ,  cycle_momentum ,  base_momentum ,  max_momentum ,  div_factor ,  final_div_factor ,  three_phase ,  last_epoch ,  verbose ) [source] ¶","Sets the learning rate of each parameter group according to the
1cycle learning rate policy. The 1cycle policy anneals the learning
rate from an initial learning rate to some maximum learning rate and then
from that maximum learning rate to some minimum learning rate much lower
than the initial learning rate.
This policy was initially described in the paper  Super-Convergence:
Very Fast Training of Neural Networks Using Large Learning Rates . The 1cycle learning rate policy changes the learning rate after every batch.
 step  should be called after a batch has been used for training. This scheduler is not chainable. Note also that the total number of steps in the cycle can be determined in one
of two ways (listed in order of precedence): 
 A value for total_steps is explicitly provided. 
 A number of epochs (epochs) and a number of steps per epoch
(steps_per_epoch) are provided.
In this case, the number of total steps is inferred by
total_steps = epochs * steps_per_epoch 
 You must either provide a value for total_steps or provide a value for both
epochs and steps_per_epoch. The default behaviour of this scheduler follows the fastai implementation of 1cycle, which
claims that “unpublished work has shown even better results by using only two phases”. To
mimic the behaviour of the original paper instead, set  three_phase=True . 
 Parameters 
 
 
 Example 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a ",,,,
"
 class torch.optim.lr_scheduler. CosineAnnealingWarmRestarts ( optimizer ,  T_0 ,  T_mult ,  eta_min ,  last_epoch ,  verbose ) [source] ¶","Set the learning rate of each parameter group using a cosine annealing
schedule, where  η  is set to the initial lr,  T 
is the number of epochs since the last restart and  T  is the number
of epochs between two warm restarts in SGDR: 
 η When  T , set  η .
When  T  after restart, set  η . It has been proposed in
 SGDR: Stochastic Gradient Descent with Warm Restarts . 
 Parameters 
 
 
 
 
 
 Return last computed learning rate by current scheduler. 
 
 
 Loads the schedulers state. 
 
 
 Display the current learning rate. 
 
 
 Returns the state of the scheduler as a  
 
 
 Step could be called after every batch update",,,,
"
 class torch.ao.nn.quantized. FloatFunctional [source] ¶","State collector class for float operations. The instance of this class can be used instead of the  torch.  prefix for
some operations. See example usage below. 
 Note 
 This class does not provide a  
 Examples: 
 
 Valid operation names: 
 
",">>> f_add=FloatFunctional()
>>> a=torch.tensor(3.0)
>>> b=torch.tensor(4.0)
>>> f_add.add(a,b)# Equivalent to ``torch.add(a, b)``
",,,
"
 Tensor. is_sparse_csr ¶","Is  True  if the Tensor uses sparse CSR storage layout,  False  otherwise.",,,,
"
 Tensor. coalesce ( )   → ¶","Returns a coalesced copy of  self  if  self  is an
 uncoalesced tensor . Returns  self  if  self  is a coalesced tensor. 
 Warning 
 Throws an error if  
",,,,
"
 Tensor. is_coalesced ( )   → ¶","Returns  True  if  self  is a  sparse COO tensor  that is coalesced,  False  otherwise. 
 Warning 
 Throws an error if  
 See  coalesce()  and  uncoalesced tensors .",,,,
"
 torch.sparse. softmax ( input ,  dim ,  * ,  dtype )   → ¶","Applies a softmax function. Softmax is defined as: Softmax where  i  run over sparse tensor indices and unspecified
entries are ignores. This is equivalent to defining unspecified
entries as negative infinity so that  e  when the
entry with index  k  has not specified. It is applied to all slices along  dim , and will re-scale them so
that the elements lie in the range  [0, 1]  and sum to 1. 
 Parameters 
 
 
",,,,
"
 torch. sparse_csr_tensor ( crow_indices ,  col_indices ,  values ,  size ,  * ,  dtype ,  device ,  requires_grad )   → ¶","Constructs a  sparse tensor in CSR (Compressed Sparse Row)  with specified
values at the given  crow_indices  and  col_indices . Sparse matrix multiplication operations
in CSR format are typically faster than that for sparse tensors in COO format. Make you have a look
at  the note on the data type of the indices . 
 Parameters 
 
 
 Keyword Arguments 
 
 
 
 Example:: 
",,,,
"
 torch. sparse_csc_tensor ( ccol_indices ,  row_indices ,  values ,  size ,  * ,  dtype ,  device ,  requires_grad )   → ¶","Constructs a  sparse tensor in CSC (Compressed Sparse Column)  with specified values at the given
 ccol_indices  and  row_indices . Sparse matrix
multiplication operations in CSC format are typically faster than that
for sparse tensors in COO format. Make you have a look at  the
note on the data type of the indices . 
 Parameters 
 
 
 Keyword Arguments 
 
 
 
 Example:: 
",,,,
"
 torch. sparse_bsr_tensor ( crow_indices ,  col_indices ,  values ,  size ,  * ,  dtype ,  device ,  requires_grad )   → ¶","Constructs a  sparse tensor in BSR (Block Compressed Sparse Row))  with specified 2-dimensional blocks at the given
 crow_indices  and  col_indices . Sparse matrix
multiplication operations in BSR format are typically faster than that
for sparse tensors in COO format. Make you have a look at  the
note on the data type of the indices . 
 Parameters 
 
 
 Keyword Arguments 
 
 
 
 Example:: 
",,,,
"
 torch. sparse_bsc_tensor ( ccol_indices ,  row_indices ,  values ,  size ,  * ,  dtype ,  device ,  requires_grad )   → ¶","Constructs a  sparse tensor in BSC (Block Compressed Sparse
Column))  with specified 2-dimensional blocks at the
given  ccol_indices  and  row_indices . Sparse matrix
multiplication operations in BSC format are typically faster than that
for sparse tensors in COO format. Make you have a look at  the
note on the data type of the indices . 
 Parameters 
 
 
 Keyword Arguments 
 
 
 
 Example:: 
",,,,
"
 torch. sparse_compressed_tensor ( compressed_indices ,  plain_indices ,  values ,  size ,  * ,  dtype ,  layout ,  device ,  requires_grad )   → ¶","Constructs a  sparse tensor in Compressed Sparse format - CSR,
CSC, BSR, or BSC -  with specified values at
the given  compressed_indices  and  plain_indices . Sparse
matrix multiplication operations in Compressed Sparse format are
typically faster than that for sparse tensors in COO format. Make you
have a look at  the note on the data type of the indices . 
 Parameters 
 
 
 Keyword Arguments 
 
 
 
 Example:: 
",,,,
"
 torch.sparse. mm ( ) ¶","
 Performs a matrix multiplication of the sparse matrix  
 Note 
 This function doesn’t support computing derivaties with respect to CSR matrices. 
 
 
 Example: 
 
",,,,
"
 torch. hspmm ( mat1 ,  mat2 ,  * ,  out )   → ¶","Performs a matrix multiplication of a  sparse COO matrix   mat1  and a strided matrix  mat2 . The
result is a (1 + 1)-dimensional  hybrid COO matrix . 
 Parameters 
 
 
 Keyword Arguments 
 out 
",,,,
"
 torch.sparse. addmm ( mat ,  mat1 ,  mat2 ,  * ,  beta ,  alpha )   → ¶","This function does exact same thing as  torch.addmm()  in the forward,
except that it supports backward for sparse COO matrix  mat1 .
When  mat1  is a COO tensor it must have  sparse_dim = 2 .
When inputs are COO tensors, this function also supports backward for both inputs. Supports both CSR and COO storage formats. 
 Note 
 This function doesn’t support computing derivaties with respect to CSR matrices. 
 
 Parameters 
 
 
",,,,
"
 Tensor. to_sparse_coo ( ) [source] ¶","Convert a tensor to  coordinate format . Examples: 
",">>> dense=torch.randn(5,5)
>>> sparse=dense.to_sparse_coo()
>>> sparse._nnz()
25
",,,
"
 Tensor. sparse_resize_ ( size ,  sparse_dim ,  dense_dim )   → ¶","Resizes  self   sparse tensor  to the desired
size and the number of sparse and dense dimensions. 
 Note 
 If the number of specified elements in  
 If  
 
 Warning 
 Throws an error if  
 
 Parameters 
 
 
",,,,
"
 Tensor. sparse_resize_and_clear_ ( size ,  sparse_dim ,  dense_dim )   → ¶","Removes all specified elements from a  sparse tensor   self  and resizes  self  to the desired
size and the number of sparse and dense dimensions. 
 Parameters 
 
 
",,,,
"
 Tensor. crow_indices ( )   → ¶","Returns the tensor containing the compressed row indices of the  self 
tensor when  self  is a sparse CSR tensor of layout  sparse_csr .
The  crow_indices  tensor is strictly of shape ( self .size(0) + 1)
and of type  int32  or  int64 . When using MKL routines such as sparse
matrix multiplication, it is necessary to use  int32  indexing in order
to avoid downcasting and potentially losing information. 
 Example:: 
",,,,
"
 Tensor. col_indices ( )   → ¶","Returns the tensor containing the column indices of the  self 
tensor when  self  is a sparse CSR tensor of layout  sparse_csr .
The  col_indices  tensor is strictly of shape ( self .nnz())
and of type  int32  or  int64 .  When using MKL routines such as sparse
matrix multiplication, it is necessary to use  int32  indexing in order
to avoid downcasting and potentially losing information. 
 Example:: 
",,,,
"
 Tensor. row_indices ( ) ¶",,,,,
"
 Tensor. ccol_indices ( ) ¶",,,,,
"
 torch.sparse. sum ( input ,  dim ,  dtype ) [source] ¶","Returns the sum of each row of the sparse tensor  input  in the given
dimensions  dim . If  dim  is a list of dimensions,
reduce over all of them. When sum over all  sparse_dim , this method
returns a dense tensor instead of a sparse tensor. All summed  dim  are squeezed (see  torch.squeeze() ), resulting an output
tensor having  dim  fewer dimensions than  input . During backward, only gradients at  nnz  locations of  input 
will propagate back. Note that the gradients of  input  is coalesced. 
 Parameters 
 
 
 Return type 
 Tensor 
 Example: 
",">>> nnz=3
>>> dims=[5,5,2,3]
>>> I=torch.cat([torch.randint(0,dims[0],size=(nnz,)),
                   torch.randint(0, dims[1], size=(nnz,))], 0).reshape(2, nnz)
>>> V=torch.randn(nnz,dims[2],dims[3])
>>> size=torch.Size(dims)
>>> S=torch.sparse_coo_tensor(I,V,size)
>>> S
tensor(indices=tensor([[2, 0, 3],
                       [2, 4, 1]]),
       values=tensor([[[-0.6438, -1.6467,  1.4004],
                       [ 0.3411,  0.0918, -0.2312]],                      [[ 0.5348,  0.0634, -2.0494],
                       [-0.7125, -1.0646,  2.1844]],                      [[ 0.1276,  0.1874, -0.6334],
                       [-1.9682, -0.5340,  0.7483]]]),
       size=(5, 5, 2, 3), nnz=3, layout=torch.sparse_coo)# when sum over only part of sparse_dims, return a sparse tensor
>>> torch.sparse.sum(S,[1,3])
tensor(indices=tensor([[0, 2, 3]]),
       values=tensor([[-1.4512,  0.4073],
                      [-0.8901,  0.2017],
                      [-0.3183, -1.7539]]),
       size=(5, 2), nnz=3, layout=torch.sparse_coo)# when sum over all sparse dim, return a dense tensor
# with summed dims squeezed
>>> torch.sparse.sum(S,[0,1,3])
tensor([-2.6596, -1.1450])
",,,
"
 torch.sparse. sampled_addmm ( input ,  mat1 ,  mat2 ,  * ,  beta ,  alpha ,  out )   → ¶","Performs a matrix multiplication of the dense matrices  mat1  and  mat2  at the locations
specified by the sparsity pattern of  input . The matrix  input  is added to the final result. Mathematically this performs the following operation: 
 out where  spy  is the sparsity pattern matrix of  input ,  alpha 
and  beta  are the scaling factors.
 spy  has value 1 at the positions where  input  has non-zero values, and 0 elsewhere. 
 Note 
 input 
 
 Parameters 
 
 
 Keyword Arguments 
 
 
 Examples: 
",">>> input=torch.eye(3,device='cuda').to_sparse_csr()
>>> mat1=torch.randn(3,5,device='cuda')
>>> mat2=torch.randn(5,3,device='cuda')
>>> torch.sparse.sampled_addmm(input,mat1,mat2)
tensor(crow_indices=tensor([0, 1, 2, 3]),
    col_indices=tensor([0, 1, 2]),
    values=tensor([ 0.2847, -0.7805, -0.1900]), device='cuda:0',
    size=(3, 3), nnz=3, layout=torch.sparse_csr)
>>> torch.sparse.sampled_addmm(input,mat1,mat2).to_dense()
tensor([[ 0.2847,  0.0000,  0.0000],
    [ 0.0000, -0.7805,  0.0000],
    [ 0.0000,  0.0000, -0.1900]], device='cuda:0')
>>> torch.sparse.sampled_addmm(input,mat1,mat2,beta=0.5,alpha=0.5)
tensor(crow_indices=tensor([0, 1, 2, 3]),
    col_indices=tensor([0, 1, 2]),
    values=tensor([ 0.1423, -0.3903, -0.0950]), device='cuda:0',
    size=(3, 3), nnz=3, layout=torch.sparse_csr)
",,,
"
 torch.sparse. log_softmax ( input ,  dim ,  * ,  dtype )   → ¶","Applies a softmax function followed by logarithm. See  softmax  for more details. 
 Parameters 
 
 
",,,,
"
 torch.sparse. spdiags ( diagonals ,  offsets ,  shape ,  layout )   → ¶","Creates a sparse 2D tensor by placing the values from rows of
 diagonals  along specified diagonals of the output The  offsets  tensor controls which diagonals are set. 
 If  
 If  
 If  
 The number of rows in  diagonals  must match the length of  offsets ,
and an offset may not be repeated. 
 Parameters 
 
 
 Keyword Arguments 
 layout 
 Examples: Set the main and first two lower diagonals of a matrix: 
 Change the output layout: 
 Set partial diagonals of a large output: 
 
 Note 
 When setting the values along a given diagonal the index into the diagonal
and the index into the row of  
 Specifying a positive offset: 
",">>> diags=torch.arange(9).reshape(3,3)
>>> diags
tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
>>> s=torch.sparse.spdiags(diags,torch.tensor([0,-1,-2]),(3,3))
>>> s
tensor(indices=tensor([[0, 1, 2, 1, 2, 2],
                       [0, 1, 2, 0, 1, 0]]),
       values=tensor([0, 1, 2, 3, 4, 6]),
       size=(3, 3), nnz=6, layout=torch.sparse_coo)
>>> s.to_dense()
tensor([[0, 0, 0],
        [3, 1, 0],
        [6, 4, 2]])
",">>> diags=torch.arange(9).reshape(3,3)
>>> diags
tensor([[0, 1, 2],[3, 4, 5], [6, 7, 8])
>>> s=torch.sparse.spdiags(diags,torch.tensor([0,-1,-2]),(3,3),layout=torch.sparse_csr)
>>> s
tensor(crow_indices=tensor([0, 1, 3, 6]),
       col_indices=tensor([0, 0, 1, 0, 1, 2]),
       values=tensor([0, 3, 1, 6, 4, 2]), size=(3, 3), nnz=6,
       layout=torch.sparse_csr)
>>> s.to_dense()
tensor([[0, 0, 0],
        [3, 1, 0],
        [6, 4, 2]])
",">>> diags=torch.tensor([[1,2],[3,4]])
>>> offsets=torch.tensor([0,-1])
>>> torch.sparse.spdiags(diags,offsets,(5,5)).to_dense()
tensor([[1, 0, 0, 0, 0],
        [3, 2, 0, 0, 0],
        [0, 4, 0, 0, 0],
        [0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0]])
",">>> diags=torch.tensor([[1,2,3],[1,2,3],[1,2,3]])
>>> torch.sparse.spdiags(diags,torch.tensor([0,1,2]),(5,5)).to_dense()
tensor([[1, 2, 3, 0, 0],
        [0, 2, 3, 0, 0],
        [0, 0, 3, 0, 0],
        [0, 0, 0, 0, 0],
        [0, 0, 0, 0, 0]])
"
